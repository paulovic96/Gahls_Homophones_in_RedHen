{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from english_contractions import ENGLISH_CONTRACTIONS\n",
    "import merging_dataframes\n",
    "import word_pronunciation_predictibility\n",
    "import celex_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_dict_file = \"Data/english/epw/epw.cd\" #\"/mnt/shared/corpora/Celex/english/epw/epw.cd\"\n",
    "filename = \"Data/2016_all_words_no_audio.pickle\" #\"/mnt/Restricted/Corpora/RedHen/2016_all_words_no_audio.pickle\"\n",
    "hom_filename = \"Data/hom.csv\" # \"/mnt/Restricted/Corpora/RedHen/hom.csv\"\n",
    "berndt_character_coding_file = \"Data/phonetic_character_code_berndt1987.csv\" # \"/mnt/Restricted/Corpora/RedHen/phonetic_character_code_berndt1987.csv\"\n",
    "berndt_conditional_probs_file = \"Data/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\" # \"/mnt/Restricted/Corpora/RedHen/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickled RedHen Dataframe \n",
    "## Preprocessing:\n",
    "- include pause information\n",
    "- word duration\n",
    "- word frequency\n",
    "- length in letter\n",
    "- contextual predictiaility given prev and next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dataframe from Data/2016_all_words_no_audio.pickle\n",
      "Preprocessing: extract pause information...\n",
      "Remove pauses from data!\n",
      "Preprocessing: apply word preprocessing...\n",
      "Preprocessing: calculate word duration...\n",
      "Preprocessing: calculate word frequency...\n",
      "Preprocessing: extract context information...\n",
      "Preprocessing: calculate length in letter...\n",
      "Preprocessing: calculate contextual predictability...\n",
      "(18864660, 25) RangeIndex(start=0, stop=18864660, step=1)\n"
     ]
    }
   ],
   "source": [
    "df = preprocessing.read_dataframe(filename, remove_pauses=True, remove_errors=True, preprocessing=True, drop_error_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = [\"2016-12-17_1330_US_KCET_Asia_Insight\", \"2016-10-25_2300_US_KABC_Eyewitness_News_4PM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[df[\"source_file\"].isin(source_files)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'length_in_letter', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gahls Homophones extracted from RedHen Dataframe\n",
    "## Preprocessing:\n",
    "- is_pair for indicating whether homophones found in data have a matching pair \n",
    "- is_max factor for indicating most frequent homophone of pair (if not a pair always 1)\n",
    "- pronunciation given by celex encoding and unbounded disc encoding (celexPhon)\n",
    "- add further celex information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read Gahls Homophone data from Data/hom.csv\n",
      "65 out of 412 homophones found in Data:\n",
      "Homophone Pairs found in Data: 6\n",
      "Homophones without Pair:  ['ads', 'bail', 'bear', 'blue', 'board', 'cell', 'chilly', 'course', 'crews', 'die', 'died', 'doe', 'due', 'fair', 'feet', 'fill', 'find', 'great', 'hall', 'higher', 'hold', 'jim', 'knows', 'made', 'meet', 'meets', 'morning', 'night', 'piece', 'poll', 'rain', 'right', 'rights', 'ring', 'road', 'roles', 'sales', 'scene', 'seem', 'seems', 'sees', 'sent', 'shoot', 'son', 'straight', 'tax', 'time', 'waiting', 'waste', 'way', 'ways', 'week', 'whole']\n",
      "Missing homophones: ['ad' 'add' 'adds' 'aid' 'aide' 'aides' 'aids' 'airs' 'allowed' 'aloud'\n",
      " 'baits' 'bald' 'bale' 'band' 'banned' 'bare' 'bates' 'bawled' 'beats'\n",
      " 'beets' 'bell' 'belle' 'berry' 'billed' 'blew' 'boar' 'bold' 'bore'\n",
      " 'bored' 'bowled' 'brakes' 'bread' 'breaks' 'bred' 'build' 'bury'\n",
      " 'callous' 'callus' 'capital' 'capitol' 'ceiling' 'cellar' 'cellars'\n",
      " 'cells' 'cent' 'cents' 'cereal' 'chews' 'chile' 'choose' 'chord' 'chords'\n",
      " 'chute' 'chutes' 'coarse' 'coco' 'cocoa' 'cord' 'cords' 'core' 'corps'\n",
      " 'council' 'counsel' 'cruise' 'dear' 'deer' 'dew' 'dies' 'doc' 'dock'\n",
      " 'dough' 'drier' 'dryer' 'dye' 'dyed' 'dyes' 'elicit' 'ensure' 'fare'\n",
      " 'feat' 'fiance' 'fiancee' 'fined' 'flair' 'flare' 'flea' 'flee' 'flew'\n",
      " 'flour' 'flours' 'flower' 'flowers' 'flu' 'franc' 'frank' 'grate'\n",
      " 'grisly' 'grizzly' 'guessed' 'guest' 'guise' 'guys' 'gym' 'halls' 'hart'\n",
      " 'haul' 'hauls' 'heal' 'heals' 'heard' 'heart' 'heel' 'heels' 'heirs'\n",
      " 'herd' 'hertz' 'hire' 'hoarse' 'hole' 'holed' 'holes' 'horse' 'hurts'\n",
      " 'illicit' 'insure' 'kneading' 'knight' 'knights' 'knit' 'lacks' 'lax'\n",
      " 'lea' 'leased' 'least' 'lee' 'lessen' 'lesson' 'levee' 'levy' 'loan'\n",
      " 'lone' 'lumbar' 'lumber' 'mac' 'mach' 'maid' 'mail' 'mails' 'male'\n",
      " 'males' 'mall' 'manner' 'manor' 'marks' 'marx' 'maul' 'meat' 'meats'\n",
      " 'missed' 'mist' 'mode' 'moose' 'mourning' 'mousse' 'mowed' 'naval'\n",
      " 'navel' 'needing' 'nights' 'nit' 'nose' 'paced' 'packed' 'pact' 'pain'\n",
      " 'pains' 'pair' 'pairs' 'pane' 'panes' 'paste' 'pause' 'paws' 'pea'\n",
      " 'peace' 'peak' 'peaked' 'pear' 'pears' 'pee' 'peek' 'peer' 'peers' 'phil'\n",
      " 'pi' 'pie' 'pier' 'piers' 'piqued' 'plain' 'plains' 'plane' 'planes'\n",
      " 'plum' 'plumb' 'pole' 'poles' 'polls' 'populace' 'populous' 'praise'\n",
      " 'pray' 'praying' 'prey' 'preying' 'preys' 'principal' 'principle' 'puts'\n",
      " 'putts' 'rack' 'rained' 'rains' 'rap' 'reeks' 'reigned' 'rein' 'reins'\n",
      " 'ringing' 'roam' 'rode' 'rolls' 'rome' 'rose' 'rote' 'rough' 'rows'\n",
      " 'ruff' 'sac' 'sack' 'sacks' 'sail' 'sails' 'sale' 'sax' 'scents'\n",
      " 'sealing' 'seam' 'seams' 'seas' 'seen' 'sell' 'seller' 'sellers' 'sells'\n",
      " 'serial' 'shear' 'sheer' 'shoots' 'sight' 'sighted' 'sights' 'sink'\n",
      " 'site' 'sited' 'sites' 'slay' 'sleigh' 'sole' 'soles' 'sons' 'soul'\n",
      " 'souls' 'spade' 'spayed' 'stake' 'stakes' 'steak' 'steaks' 'steal'\n",
      " 'steel' 'strait' 'suede' 'suites' 'sun' 'suns' 'swayed' 'sweets' 'sync'\n",
      " 'tacks' 'tail' 'tails' 'tale' 'tales' 'taught' 'taut' 'tea' 'teas'\n",
      " 'tease' 'tec' 'tech' 'tee' 'thai' 'thais' 'throes' 'throws' 'thyme' 'tic'\n",
      " 'tick' 'tide' 'tie' 'tied' 'ties' 'toe' 'tow' 'tracked' 'tract' 'wade'\n",
      " 'waist' 'waits' 'waive' 'war' 'warn' 'wave' 'wax' 'weak' 'weigh'\n",
      " 'weighed' 'weighs' 'weighting' 'weights' 'whacks' 'whine' 'whit' 'wholes'\n",
      " 'wine' 'wit' 'wore' 'worn' 'wrack' 'wrap' 'wreaks' 'wring' 'wringing'\n",
      " 'write' 'writes' 'wrote']\n"
     ]
    }
   ],
   "source": [
    "homophones_in_data, gahls_homophones, gahls_homophones_missing_in_data = preprocessing.read_and_extract_homophones(hom_filename, sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_dict = word_pronunciation_predictibility.get_english_phonology_from_celex(celex_dict_file)\n",
    "homophones_in_data_celex_merged = merging_dataframes.get_celex_transcription(homophones_in_data, celex_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'length_in_letter', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next', 'has_pair', 'pron', 'celexPhon',\n",
       "       'pron_frequency', 'is_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'length_in_letter', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next', 'has_pair', 'pron', 'celexPhon',\n",
       "       'pron_frequency', 'is_max', 'disc', 'clx', 'disc_no_bound',\n",
       "       'clx_no_bound'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load additional information\n",
    "- eaf files\n",
    "- seg files\n",
    "- gentle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EAF files\n",
    "- information about present gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and extract information from eaf files...\n"
     ]
    }
   ],
   "source": [
    "eaf_data = preprocessing.get_additional_data_from_files(sub_df, \"eaf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEG files\n",
    "- information about Part Of Speech\n",
    "- information about Phrase final marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and extract information from seg files...\n"
     ]
    }
   ],
   "source": [
    "seg_data = preprocessing.get_additional_data_from_files(sub_df, \"seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENTLE files\n",
    "- information about Phrase final marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and extract information from gentle files...\n"
     ]
    }
   ],
   "source": [
    "gentle_data = preprocessing.get_additional_data_from_files(sub_df, \"gentle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video files\n",
    "- information about entropy of situation in which the homophones was articulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and extract information from video files...\n"
     ]
    }
   ],
   "source": [
    "video_data = preprocessing.get_additional_data_from_files(homophones_in_data_celex_merged, \"video\") # only for homophones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'celex_files' from '/Users/paule/Desktop/Gahls_Homophones_in_RedHen/celex_files.py'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(celex_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_data = celex_files.get_syl_counts(celex_files.read_celex_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Pronunciation Predictability (Berndt et al. 1987)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Berndt's tables for Phoneme Equivalents and Conditional Probabilities for Grapheme-to-Phoneme Correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_character_code_df = pd.read_csv(berndt_character_coding_file, delimiter=\";\")\n",
    "berndt_conditional_probs = pd.read_csv(berndt_conditional_probs_file,delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPABET to corresponding Keyboard Compatible Phonemic (KCP) symbol dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_arpabet_phon_dict = word_pronunciation_predictibility.get_ARPABET_to_keyboard_phonetic_symbols_dict(berndt_character_code_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KCP to Grapheme Symbols and Probabilities dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonem_graphem_prob_dict = word_pronunciation_predictibility.get_keyboard_phonetic_symbols_to_grapheme_cond_prob_dict(berndt_conditional_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homophones with corresponding ARPABET transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_homophones = np.unique(homophones_in_data.word)\n",
    "hom_arpabet_words = word_pronunciation_predictibility.get_ARPAbet_phonetic_transcription(unique_homophones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homophones with corresponding KCP transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hom_kcp_word_tuples = []\n",
    "for i,arpabet_word in enumerate(hom_arpabet_words):\n",
    "    kcp_word = word_pronunciation_predictibility.get_keyboard_phonetic_symbols_for_ARPABET(arpabet_word, berndt_arpabet_phon_dict)\n",
    "    #print(unique_homophones[i],arpabet_word,kcp_word)\n",
    "    hom_kcp_word_tuples.append((unique_homophones[i],kcp_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get possible (valid) Grapheme strings and probs for each KCP encoded homophone \n",
    "Note: 6 homophones not captured \n",
    "- guessed: ['g', 'eh', 's', 't’] —> Grapheme 'GUE' as kcp 'g' but no mapping for Grapheme 'GU' as 'g' (silent U) \n",
    "- guest: ['g', 'eh', 's', ’t']\n",
    "- guise: ['g', 'ai', 'z‘]\n",
    "- thai: ['t', 'ai‘] —> KCP Symbol 'ai' not mapped to Grapheme 'AI' in Berndt'sconditional probs\n",
    "- thais: ['t', 'ai', 'z']\n",
    "- weighed: ['w', 'ay', 'd‘] —> Grapheme 'EIGH' as kcp 'ay' but not EIGH-E (silent E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_grapheme_strings, possible_prior_probs, possible_cond_probs, word_rests = word_pronunciation_predictibility.get_grapheme_string_with_conditional_prob_for_keyboard_phonetics(hom_kcp_word_tuples, \n",
    "phonem_graphem_prob_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homophones for which we have no valid grapheme string: \n",
    "#counter = 0 \n",
    "#for i,word_pron in enumerate(hom_kcp_word_tuples):\n",
    "#    word = word_pron[0] # word string\n",
    "#    pron = word_pron[1] # list of keyboard compatible phon characters\n",
    "#    if len(possible_grapheme_strings[i]) == 0:\n",
    "#        counter+=1\n",
    "#        print(word,pron)\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_word_rests,valid_grapheme_strings,valid_prior_probs, valid_cond_probs = word_pronunciation_predictibility.get_valid_grapheme_strings(hom_kcp_word_tuples, possible_grapheme_strings, word_rests,possible_prior_probs, possible_cond_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cond_prob_for_grapheme = word_pronunciation_predictibility.get_max_cond_prob_for_grapheme(berndt_conditional_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_score_data = word_pronunciation_predictibility.get_m_score_df(hom_kcp_word_tuples, valid_grapheme_strings,valid_cond_probs,max_cond_prob_for_grapheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'merging_dataframes' from '/Users/paule/Desktop/Gahls_Homophones_in_RedHen/merging_dataframes.py'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(merging_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging eaf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_eaf = merging_dataframes.merge_eaf_df_to_homophone_data(homophones_in_data_celex_merged, eaf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_eaf_video = merging_dataframes.merge_video_df_to_homophone_data(homophones_in_data_celex_eaf, video_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging gentle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_eaf_video_gentle = merging_dataframes.merge_gentle_df_to_homophone_data(homophones_in_data_celex_eaf_video, gentle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging seg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_eaf_video_gentle_seg = merging_dataframes.merge_seg_df_to_homophone_data(homophones_in_data_celex_eaf_video_gentle, seg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging m-scores data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_eaf_video_gentle_seg_m_scores = merging_dataframes.merge_m_scores_df_to_homophone_data(homophones_in_data_celex_eaf_video_gentle_seg,m_score_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging celex syllable counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_eaf_video_gentle_seg_m_scores_syll = merging_dataframes.merge_celex_syl_counts_df_to_homophone_data(homophones_in_data_celex_eaf_video_gentle_seg_m_scores,celex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'length_in_letter', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next', 'has_pair', 'pron', 'celexPhon',\n",
       "       'pron_frequency', 'is_max', 'disc', 'clx', 'disc_no_bound',\n",
       "       'clx_no_bound', 'gesture', 'HandMoving', 'PersonOnScreen',\n",
       "       'SpeakerOnScreen', 'HeadMoving/MovingVertically',\n",
       "       'ShoulderMoving/NotWithHead', 'HeadMoving/MovingHorizontally',\n",
       "       'ShoulderMoving/NoSlidingWindow', 'none',\n",
       "       'ShoulderMoving/SlidingWindow', 'is_gesture', 'video_snippet_size',\n",
       "       'gentle_prev_word', 'gentle_next_word', 'gentle_end_of_sentence',\n",
       "       'gentle_start_of_sentence', 'gentle_preceding_marker',\n",
       "       'gentle_subsequent_marker', 'gentle_merging', 'gentle_index',\n",
       "       'seg_prev_word', 'seg_next_word', 'seg_end_of_sentence',\n",
       "       'seg_start_of_sentence', 'seg_preceding_marker',\n",
       "       'seg_subsequent_marker', 'seg_merging', 'seg_index', 'pos', 'rel1',\n",
       "       'rel2', 'lemma', 'm_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_eaf_video_gentle_seg_m_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_confidence_homs = homophones_in_data_celex_eaf_video_gentle_seg_m_scores[np.logical_or(homophones_in_data_celex_eaf_video_gentle_seg_m_scores.seg_merging == \"low-confidence\",homophones_in_data_celex_eaf_video_gentle_seg_m_scores.gentle_merging == \"low-confidence\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prev_word</th>\n",
       "      <th>next_word</th>\n",
       "      <th>gentle_prev_word</th>\n",
       "      <th>gentle_next_word</th>\n",
       "      <th>seg_prev_word</th>\n",
       "      <th>seg_next_word</th>\n",
       "      <th>seg_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>preceding_pause</th>\n",
       "      <th>subsequent_pause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>see</td>\n",
       "      <td>let's</td>\n",
       "      <td>more</td>\n",
       "      <td>let's</td>\n",
       "      <td>if</td>\n",
       "      <td>us</td>\n",
       "      <td>if</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>time</td>\n",
       "      <td>the</td>\n",
       "      <td>been</td>\n",
       "      <td>the</td>\n",
       "      <td>they</td>\n",
       "      <td>the</td>\n",
       "      <td>they</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>time</td>\n",
       "      <td>this</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this</td>\n",
       "      <td></td>\n",
       "      <td>this</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bail</td>\n",
       "      <td>million</td>\n",
       "      <td>new</td>\n",
       "      <td>million</td>\n",
       "      <td>new</td>\n",
       "      <td>million</td>\n",
       "      <td>ellen</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>new</td>\n",
       "      <td>bail</td>\n",
       "      <td>developments</td>\n",
       "      <td>bail</td>\n",
       "      <td>developments</td>\n",
       "      <td>ellen</td>\n",
       "      <td>developments</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>new</td>\n",
       "      <td>phone</td>\n",
       "      <td>allegations</td>\n",
       "      <td>phone</td>\n",
       "      <td>allegations</td>\n",
       "      <td>ellen</td>\n",
       "      <td>allegations</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>new</td>\n",
       "      <td>is</td>\n",
       "      <td>push</td>\n",
       "      <td>a</td>\n",
       "      <td>push</td>\n",
       "      <td>a</td>\n",
       "      <td>push</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>here</td>\n",
       "      <td>were</td>\n",
       "      <td>waiting</td>\n",
       "      <td>standing</td>\n",
       "      <td>waiting</td>\n",
       "      <td>standing</td>\n",
       "      <td>waiting</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>here</td>\n",
       "      <td>down</td>\n",
       "      <td>dmv</td>\n",
       "      <td>down</td>\n",
       "      <td>dmv</td>\n",
       "      <td>down</td>\n",
       "      <td>eileen</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>here</td>\n",
       "      <td>way</td>\n",
       "      <td>is</td>\n",
       "      <td>way</td>\n",
       "      <td>is</td>\n",
       "      <td>david</td>\n",
       "      <td>is</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>rain</td>\n",
       "      <td>some</td>\n",
       "      <td>81</td>\n",
       "      <td>some</td>\n",
       "      <td>81</td>\n",
       "      <td>some</td>\n",
       "      <td>dallas</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rain</td>\n",
       "      <td>for</td>\n",
       "      <td>i</td>\n",
       "      <td>for</td>\n",
       "      <td>i</td>\n",
       "      <td>for</td>\n",
       "      <td>dallas</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>find</td>\n",
       "      <td>to</td>\n",
       "      <td>out</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>scene</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>error</td>\n",
       "      <td>the</td>\n",
       "      <td>error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>scene</td>\n",
       "      <td>the</td>\n",
       "      <td>more</td>\n",
       "      <td>the</td>\n",
       "      <td>more</td>\n",
       "      <td>the</td>\n",
       "      <td>marc</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>way</td>\n",
       "      <td>coming</td>\n",
       "      <td>hopefully</td>\n",
       "      <td>this</td>\n",
       "      <td>hopefully</td>\n",
       "      <td>this</td>\n",
       "      <td>hopefully</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>way</td>\n",
       "      <td>your</td>\n",
       "      <td>here</td>\n",
       "      <td>your</td>\n",
       "      <td>here</td>\n",
       "      <td>your</td>\n",
       "      <td>david</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>son</td>\n",
       "      <td>your</td>\n",
       "      <td>prop</td>\n",
       "      <td>your</td>\n",
       "      <td>prop</td>\n",
       "      <td>your</td>\n",
       "      <td>rob</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>weight</td>\n",
       "      <td>gunfire</td>\n",
       "      <td>finding</td>\n",
       "      <td>gunfire</td>\n",
       "      <td>--</td>\n",
       "      <td>gunfire</td>\n",
       "      <td>--</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>sea</td>\n",
       "      <td>to</td>\n",
       "      <td>a</td>\n",
       "      <td>to</td>\n",
       "      <td>--</td>\n",
       "      <td>to</td>\n",
       "      <td>david</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>roles</td>\n",
       "      <td>supporting</td>\n",
       "      <td>film</td>\n",
       "      <td>supporting</td>\n",
       "      <td>one</td>\n",
       "      <td>supporting</td>\n",
       "      <td>one</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word   prev_word     next_word gentle_prev_word gentle_next_word  \\\n",
       "19      see       let's          more            let's               if   \n",
       "22     time         the          been              the             they   \n",
       "28     time        this           NaN             this                    \n",
       "32     bail     million           new          million              new   \n",
       "33      new        bail  developments             bail     developments   \n",
       "37      new       phone   allegations            phone      allegations   \n",
       "47      new          is          push                a             push   \n",
       "58     here        were       waiting         standing          waiting   \n",
       "59     here        down           dmv             down              dmv   \n",
       "61     here         way            is              way               is   \n",
       "93     rain        some            81             some               81   \n",
       "94     rain         for             i              for                i   \n",
       "109    find          to           out               to              the   \n",
       "113   scene         the           the              the            error   \n",
       "114   scene         the          more              the             more   \n",
       "134     way      coming     hopefully             this        hopefully   \n",
       "135     way        your          here             your             here   \n",
       "166     son        your          prop             your             prop   \n",
       "169  weight     gunfire       finding          gunfire               --   \n",
       "187     sea          to             a               to               --   \n",
       "191   roles  supporting          film       supporting              one   \n",
       "\n",
       "    seg_prev_word seg_next_word seg_error eafgz_error  preceding_pause  \\\n",
       "19             us            if  no-error    no-error            False   \n",
       "22            the          they  no-error    no-error            False   \n",
       "28           this           NaN  no-error    no-error            False   \n",
       "32        million         ellen  no-error    no-error             True   \n",
       "33          ellen  developments  no-error    no-error             True   \n",
       "37          ellen   allegations  no-error    no-error            False   \n",
       "47              a          push  no-error    no-error            False   \n",
       "58       standing       waiting  no-error    no-error            False   \n",
       "59           down        eileen  no-error    no-error            False   \n",
       "61          david            is  no-error    no-error            False   \n",
       "93           some        dallas  no-error    no-error            False   \n",
       "94            for        dallas  no-error    no-error             True   \n",
       "109            to           the  no-error    no-error            False   \n",
       "113           the         error  no-error    no-error            False   \n",
       "114           the          marc  no-error    no-error            False   \n",
       "134          this     hopefully  no-error    no-error            False   \n",
       "135          your         david  no-error    no-error            False   \n",
       "166          your           rob  no-error    no-error            False   \n",
       "169       gunfire            --  no-error    no-error            False   \n",
       "187            to         david  no-error    no-error            False   \n",
       "191    supporting           one  no-error    no-error            False   \n",
       "\n",
       "     subsequent_pause  \n",
       "19              False  \n",
       "22              False  \n",
       "28              False  \n",
       "32               True  \n",
       "33              False  \n",
       "37              False  \n",
       "47              False  \n",
       "58               True  \n",
       "59               True  \n",
       "61              False  \n",
       "93               True  \n",
       "94              False  \n",
       "109             False  \n",
       "113             False  \n",
       "114             False  \n",
       "134             False  \n",
       "135             False  \n",
       "166             False  \n",
       "169             False  \n",
       "187              True  \n",
       "191             False  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_confidence_homs[[\"word\", 'prev_word', 'next_word', 'gentle_prev_word', 'gentle_next_word', 'seg_prev_word', 'seg_next_word',\"seg_error\",'eafgz_error','preceding_pause','subsequent_pause']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
