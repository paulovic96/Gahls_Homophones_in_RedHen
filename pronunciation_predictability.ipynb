{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from g2p_en import G2p # https://github.com/Kyubyong/g2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_dict_file = \"Data/epw.cd\"\n",
    "filename = \"Data/2016_all_words_no_audio.pickle\"\n",
    "hom_filename = \"Data/hom.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dataframe from Data/2016_all_words_no_audio.pickle\n",
      "Preprocessing: extract pause information...\n",
      "Remove pauses from data!\n",
      "Preprocessing: apply word preprocessing...\n",
      "Preprocessing: calculate word duration...\n",
      "Preprocessing: calculate word frequency...\n",
      "Preprocessing: extract context information...\n",
      "Preprocessing: calculate letter length...\n",
      "Preprocessing: calculate contextual predictability...\n",
      "(18864660, 25) RangeIndex(start=0, stop=18864660, step=1)\n"
     ]
    }
   ],
   "source": [
    "df = preprocessing.read_dataframe(filename, remove_pauses=True, remove_errors=True, preprocessing=True, drop_error_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = [\"2016-12-17_1330_US_KCET_Asia_Insight\", \"2016-10-25_2300_US_KABC_Eyewitness_News_4PM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_word_frequency</th>\n",
       "      <th>next_word</th>\n",
       "      <th>next_word_frequency</th>\n",
       "      <th>letter_length</th>\n",
       "      <th>prev_word_string</th>\n",
       "      <th>next_word_string</th>\n",
       "      <th>prev_word_string_frequency</th>\n",
       "      <th>next_word_string_frequency</th>\n",
       "      <th>cond_pred_prev</th>\n",
       "      <th>cond_pred_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14828820</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>police</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>don't</td>\n",
       "      <td>32647.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police-don't</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828821</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>don't</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.21</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>18598.0</td>\n",
       "      <td>believe</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>5</td>\n",
       "      <td>police-don't</td>\n",
       "      <td>don't-believe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.054839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828822</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>believe</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.33</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>32647.0</td>\n",
       "      <td>the</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>7</td>\n",
       "      <td>don't-believe</td>\n",
       "      <td>believe-the</td>\n",
       "      <td>540.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828823</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>the</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.18</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>mother</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>3</td>\n",
       "      <td>believe-the</td>\n",
       "      <td>the-mother</td>\n",
       "      <td>793.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.143822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828824</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>mother</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.39</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>or</td>\n",
       "      <td>57737.0</td>\n",
       "      <td>6</td>\n",
       "      <td>the-mother</td>\n",
       "      <td>mother-or</td>\n",
       "      <td>490.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805800</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>2017</td>\n",
       "      <td>1657.55</td>\n",
       "      <td>1657.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>335519.0</td>\n",
       "      <td>as</td>\n",
       "      <td>89095.0</td>\n",
       "      <td>4</td>\n",
       "      <td>in-2017</td>\n",
       "      <td>2017-as</td>\n",
       "      <td>151.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805801</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>as</td>\n",
       "      <td>1659.25</td>\n",
       "      <td>1659.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>597.0</td>\n",
       "      <td>the</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-as</td>\n",
       "      <td>as-the</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805802</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>the</td>\n",
       "      <td>1659.50</td>\n",
       "      <td>1659.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>89095.0</td>\n",
       "      <td>world's</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>3</td>\n",
       "      <td>as-the</td>\n",
       "      <td>the-world's</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.077546</td>\n",
       "      <td>0.794099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805803</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>world's</td>\n",
       "      <td>1659.65</td>\n",
       "      <td>1660.25</td>\n",
       "      <td>0.60</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>largest</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>7</td>\n",
       "      <td>the-world's</td>\n",
       "      <td>world's-largest</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.110604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805804</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>largest</td>\n",
       "      <td>1660.25</td>\n",
       "      <td>1660.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>world's-largest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7435 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file     word    start  \\\n",
       "14828820  2016-10-25_2300_US_KABC_Eyewitness_News_4PM   police     0.29   \n",
       "14828821  2016-10-25_2300_US_KABC_Eyewitness_News_4PM    don't     0.67   \n",
       "14828822  2016-10-25_2300_US_KABC_Eyewitness_News_4PM  believe     0.88   \n",
       "14828823  2016-10-25_2300_US_KABC_Eyewitness_News_4PM      the     1.22   \n",
       "14828824  2016-10-25_2300_US_KABC_Eyewitness_News_4PM   mother     1.40   \n",
       "...                                               ...      ...      ...   \n",
       "17805800         2016-12-17_1330_US_KCET_Asia_Insight     2017  1657.55   \n",
       "17805801         2016-12-17_1330_US_KCET_Asia_Insight       as  1659.25   \n",
       "17805802         2016-12-17_1330_US_KCET_Asia_Insight      the  1659.50   \n",
       "17805803         2016-12-17_1330_US_KCET_Asia_Insight  world's  1659.65   \n",
       "17805804         2016-12-17_1330_US_KCET_Asia_Insight  largest  1660.25   \n",
       "\n",
       "              end  duration       label_type mp4_error aac_error  \\\n",
       "14828820     0.67      0.38  high-confidence  no-error  no-error   \n",
       "14828821     0.88      0.21  high-confidence  no-error  no-error   \n",
       "14828822     1.21      0.33  high-confidence  no-error  no-error   \n",
       "14828823     1.40      0.18  high-confidence  no-error  no-error   \n",
       "14828824     1.79      0.39  high-confidence  no-error  no-error   \n",
       "...           ...       ...              ...       ...       ...   \n",
       "17805800  1657.71      0.16  high-confidence  no-error  no-error   \n",
       "17805801  1659.49      0.24  high-confidence  no-error  no-error   \n",
       "17805802  1659.65      0.15  high-confidence  no-error  no-error   \n",
       "17805803  1660.25      0.60  high-confidence  no-error  no-error   \n",
       "17805804  1660.82      0.57  high-confidence  no-error  no-error   \n",
       "\n",
       "         aac2wav_error eafgz_error  ... prev_word_frequency  next_word  \\\n",
       "14828820      no-error    no-error  ...                 NaN      don't   \n",
       "14828821      no-error    no-error  ...             18598.0    believe   \n",
       "14828822      no-error    no-error  ...             32647.0        the   \n",
       "14828823      no-error    no-error  ...              9847.0     mother   \n",
       "14828824      no-error    no-error  ...            932396.0         or   \n",
       "...                ...         ...  ...                 ...        ...   \n",
       "17805800      no-error    no-error  ...            335519.0         as   \n",
       "17805801      no-error    no-error  ...               597.0        the   \n",
       "17805802      no-error    no-error  ...             89095.0    world's   \n",
       "17805803      no-error    no-error  ...            932396.0    largest   \n",
       "17805804      no-error    no-error  ...              1593.0        NaN   \n",
       "\n",
       "          next_word_frequency  letter_length prev_word_string  \\\n",
       "14828820              32647.0              6              NaN   \n",
       "14828821               9847.0              5     police-don't   \n",
       "14828822             932396.0              7    don't-believe   \n",
       "14828823               3407.0              3      believe-the   \n",
       "14828824              57737.0              6       the-mother   \n",
       "...                       ...            ...              ...   \n",
       "17805800              89095.0              4          in-2017   \n",
       "17805801             932396.0              2          2017-as   \n",
       "17805802               1593.0              3           as-the   \n",
       "17805803               1971.0              7      the-world's   \n",
       "17805804                  NaN              7  world's-largest   \n",
       "\n",
       "          next_word_string prev_word_string_frequency  \\\n",
       "14828820      police-don't                        NaN   \n",
       "14828821     don't-believe                       37.0   \n",
       "14828822       believe-the                      540.0   \n",
       "14828823        the-mother                      793.0   \n",
       "14828824         mother-or                      490.0   \n",
       "...                    ...                        ...   \n",
       "17805800           2017-as                      151.0   \n",
       "17805801            as-the                       15.0   \n",
       "17805802       the-world's                     6909.0   \n",
       "17805803   world's-largest                     1265.0   \n",
       "17805804               NaN                      218.0   \n",
       "\n",
       "          next_word_string_frequency  cond_pred_prev cond_pred_next  \n",
       "14828820                        37.0             NaN       0.001133  \n",
       "14828821                       540.0        0.001989       0.054839  \n",
       "14828822                       793.0        0.016541       0.000850  \n",
       "14828823                       490.0        0.080532       0.143822  \n",
       "14828824                        21.0        0.000526       0.000364  \n",
       "...                              ...             ...            ...  \n",
       "17805800                        15.0        0.000450       0.000168  \n",
       "17805801                      6909.0        0.025126       0.007410  \n",
       "17805802                      1265.0        0.077546       0.794099  \n",
       "17805803                       218.0        0.001357       0.110604  \n",
       "17805804                         NaN        0.136849            NaN  \n",
       "\n",
       "[7435 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(\"sub_df.csv\", index_col=\"Unnamed: 0\")\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read Gahls Homophone data from Data/hom.csv\n",
      "406 out of 412 homophones found in Data:\n",
      "Homophone Pairs found in Data: 200\n",
      "Homophones without Pair:  ['flowers', 'holes', 'moose', 'naval', 'pairs', 'taught']\n",
      "Missing homophones: ['flours' 'mousse' 'navel' 'pears' 'taut' 'wholes']\n"
     ]
    }
   ],
   "source": [
    "homophones_in_data, gahls_homophones, gahls_homophones_missing_in_data = preprocessing.read_and_extract_homophones(hom_filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>next_word_string</th>\n",
       "      <th>prev_word_string_frequency</th>\n",
       "      <th>next_word_string_frequency</th>\n",
       "      <th>cond_pred_prev</th>\n",
       "      <th>cond_pred_next</th>\n",
       "      <th>has_pair</th>\n",
       "      <th>pron</th>\n",
       "      <th>celexPhon</th>\n",
       "      <th>pron_frequency</th>\n",
       "      <th>is_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>14.940000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-when</td>\n",
       "      <td>490.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>297.990000</td>\n",
       "      <td>298.300000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-and</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.194462</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>737.299999</td>\n",
       "      <td>737.609999</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-he</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.194462</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1187.000000</td>\n",
       "      <td>1187.520000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-making</td>\n",
       "      <td>347.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.129914</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1195.000000</td>\n",
       "      <td>1195.350000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-early</td>\n",
       "      <td>347.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.129914</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1260.480000</td>\n",
       "      <td>1260.780000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>passed-a</td>\n",
       "      <td>81.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1264.710000</td>\n",
       "      <td>1264.750000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>passed-and</td>\n",
       "      <td>81.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>higher</td>\n",
       "      <td>1307.420000</td>\n",
       "      <td>1307.800000</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>higher-than</td>\n",
       "      <td>32.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>False</td>\n",
       "      <td>h2_TR</td>\n",
       "      <td>h2@R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>waste</td>\n",
       "      <td>1384.379999</td>\n",
       "      <td>1384.669999</td>\n",
       "      <td>0.29</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>waste-one</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>False</td>\n",
       "      <td>w1st</td>\n",
       "      <td>w1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>chilly</td>\n",
       "      <td>1403.240000</td>\n",
       "      <td>1403.650000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>chilly-weather</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>False</td>\n",
       "      <td>JI_lI</td>\n",
       "      <td>JIlI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source_file    word        start  \\\n",
       "0    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night    14.540000   \n",
       "1    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   297.990000   \n",
       "2    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   737.299999   \n",
       "3    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1187.000000   \n",
       "4    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1195.000000   \n",
       "..                                           ...     ...          ...   \n",
       "200         2016-12-17_1330_US_KCET_Asia_Insight  passed  1260.480000   \n",
       "201         2016-12-17_1330_US_KCET_Asia_Insight  passed  1264.710000   \n",
       "202         2016-12-17_1330_US_KCET_Asia_Insight  higher  1307.420000   \n",
       "203         2016-12-17_1330_US_KCET_Asia_Insight   waste  1384.379999   \n",
       "204         2016-12-17_1330_US_KCET_Asia_Insight  chilly  1403.240000   \n",
       "\n",
       "             end  duration       label_type mp4_error aac_error aac2wav_error  \\\n",
       "0      14.940000      0.40  high-confidence  no-error  no-error      no-error   \n",
       "1     298.300000      0.31  high-confidence  no-error  no-error      no-error   \n",
       "2     737.609999      0.31  high-confidence  no-error  no-error      no-error   \n",
       "3    1187.520000      0.52  high-confidence  no-error  no-error      no-error   \n",
       "4    1195.350000      0.35   low-confidence  no-error  no-error      no-error   \n",
       "..           ...       ...              ...       ...       ...           ...   \n",
       "200  1260.780000      0.30  high-confidence  no-error  no-error      no-error   \n",
       "201  1264.750000      0.04   low-confidence  no-error  no-error      no-error   \n",
       "202  1307.800000      0.38  high-confidence  no-error  no-error      no-error   \n",
       "203  1384.669999      0.29  high-confidence  no-error  no-error      no-error   \n",
       "204  1403.650000      0.41  high-confidence  no-error  no-error      no-error   \n",
       "\n",
       "    eafgz_error  ... next_word_string  prev_word_string_frequency  \\\n",
       "0      no-error  ...       night-when                       490.0   \n",
       "1      no-error  ...        night-and                      4410.0   \n",
       "2      no-error  ...         night-he                      4410.0   \n",
       "3      no-error  ...     night-making                       347.0   \n",
       "4      no-error  ...      night-early                       347.0   \n",
       "..          ...  ...              ...                         ...   \n",
       "200    no-error  ...         passed-a                        81.0   \n",
       "201    no-error  ...       passed-and                        81.0   \n",
       "202    no-error  ...      higher-than                        32.0   \n",
       "203    no-error  ...        waste-one                        41.0   \n",
       "204    no-error  ...   chilly-weather                        30.0   \n",
       "\n",
       "     next_word_string_frequency  cond_pred_prev cond_pred_next  has_pair  \\\n",
       "0                         244.0        0.005139       0.005493     False   \n",
       "1                         754.0        0.194462       0.001763     False   \n",
       "2                         268.0        0.194462       0.002229     False   \n",
       "3                           6.0        0.129914       0.000725     False   \n",
       "4                           6.0        0.129914       0.001257     False   \n",
       "..                          ...             ...            ...       ...   \n",
       "200                       107.0        0.000674       0.000250      True   \n",
       "201                        36.0        0.000674       0.000084      True   \n",
       "202                       291.0        0.004683       0.010053     False   \n",
       "203                         3.0        0.000076       0.000051     False   \n",
       "204                        11.0        0.000032       0.002680     False   \n",
       "\n",
       "      pron  celexPhon  pron_frequency is_max  \n",
       "0      n2t        n2t              11      1  \n",
       "1      n2t        n2t              11      1  \n",
       "2      n2t        n2t              11      1  \n",
       "3      n2t        n2t              11      1  \n",
       "4      n2t        n2t              11      1  \n",
       "..     ...        ...             ...    ...  \n",
       "200   pBst       p#st               6      1  \n",
       "201   pBst       p#st               6      1  \n",
       "202  h2_TR       h2@R               1      1  \n",
       "203   w1st       w1st               1      1  \n",
       "204  JI_lI       JIlI               1      1  \n",
       "\n",
       "[205 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARPAbet_phonetic_transcription(word_list):\n",
    "    g2p = G2p()\n",
    "    arpabet_word_list = []\n",
    "    for word in word_list:\n",
    "        transcription = g2p(word)\n",
    "        arpabet_word_list.append(transcription)\n",
    "\n",
    "    return arpabet_word_list\n",
    "\n",
    "\n",
    "def get_english_phonology_from_celex(filename):\n",
    "    phonology_dict = {\"word\":[], \"disc\":[], \"clx\":[]}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\\\\")\n",
    "            word = line[1] # the word\n",
    "            phonology_dict[\"word\"].append(word)\n",
    "            disc = line[6] # pronunciation in DISC notation, hyphens to mark syllable boundaries, inverted comma for primary stress and double quote for secondary stress (PhonStrsDISC)\n",
    "            phonology_dict[\"disc\"].append(disc)\n",
    "            clx = line[8] # pronunciation in CELEX notation, with brackets (PhonSylBCLX)\n",
    "            phonology_dict[\"clx\"].append(clx)\n",
    "\n",
    "    celex_phonology_dict = pd.DataFrame.from_dict(phonology_dict).drop_duplicates()\n",
    "    celex_phonology_dict[\"disc_no_bound\"] = celex_phonology_dict[\"disc\"].apply(\n",
    "        lambda x: x.replace(\"'\", \"\").replace(\"-\", \"\"))\n",
    "    celex_phonology_dict[\"clx_no_bound\"] = celex_phonology_dict[\"clx\"].apply(\n",
    "        lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    return celex_phonology_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_celex_transcription(df, celex_phonology_dict):\n",
    "\n",
    "    return df.merge(celex_phonology_dict[[\"word\", \"disc\", \"clx\", \"disc_no_bound\", \"clx_no_bound\"]], how = \"left\", left_on=[\"word\", \"celexPhon\"], right_on=[\"word\",\"disc_no_bound\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_phonology_dict = get_english_phonology_from_celex(celex_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>'1</td>\n",
       "      <td>[eI]</td>\n",
       "      <td>1</td>\n",
       "      <td>eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>'1</td>\n",
       "      <td>[eI]</td>\n",
       "      <td>1</td>\n",
       "      <td>eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA</td>\n",
       "      <td>\"1-'1</td>\n",
       "      <td>[eI][eI]</td>\n",
       "      <td>\"11</td>\n",
       "      <td>eIeI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAs</td>\n",
       "      <td>\"1-'1z</td>\n",
       "      <td>[eI][eIz]</td>\n",
       "      <td>\"11z</td>\n",
       "      <td>eIeIz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abaci</td>\n",
       "      <td>'{-b@-s2</td>\n",
       "      <td>[&amp;][b@][saI]</td>\n",
       "      <td>{b@s2</td>\n",
       "      <td>&amp;b@saI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100620</th>\n",
       "      <td>Zouave</td>\n",
       "      <td>zu-'#v</td>\n",
       "      <td>[zu:][A:v]</td>\n",
       "      <td>zu#v</td>\n",
       "      <td>zu:A:v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100621</th>\n",
       "      <td>Zouaves</td>\n",
       "      <td>zu-'#vz</td>\n",
       "      <td>[zu:][A:vz]</td>\n",
       "      <td>zu#vz</td>\n",
       "      <td>zu:A:vz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100622</th>\n",
       "      <td>z's</td>\n",
       "      <td>'zEdz</td>\n",
       "      <td>[zEdz]</td>\n",
       "      <td>zEdz</td>\n",
       "      <td>zEdz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100623</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>zU-'ki-nI</td>\n",
       "      <td>[zU][ki:][nI]</td>\n",
       "      <td>zUkinI</td>\n",
       "      <td>zUki:nI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100624</th>\n",
       "      <td>zucchinis</td>\n",
       "      <td>zU-'ki-nIz</td>\n",
       "      <td>[zU][ki:][nIz]</td>\n",
       "      <td>zUkinIz</td>\n",
       "      <td>zUki:nIz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90401 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word        disc             clx disc_no_bound clx_no_bound\n",
       "0               a          '1            [eI]             1           eI\n",
       "2               A          '1            [eI]             1           eI\n",
       "4              AA       \"1-'1        [eI][eI]           \"11         eIeI\n",
       "6             AAs      \"1-'1z       [eI][eIz]          \"11z        eIeIz\n",
       "7           abaci    '{-b@-s2    [&][b@][saI]         {b@s2       &b@saI\n",
       "...           ...         ...             ...           ...          ...\n",
       "100620     Zouave      zu-'#v      [zu:][A:v]          zu#v       zu:A:v\n",
       "100621    Zouaves     zu-'#vz     [zu:][A:vz]         zu#vz      zu:A:vz\n",
       "100622        z's       'zEdz          [zEdz]          zEdz         zEdz\n",
       "100623   zucchini   zU-'ki-nI   [zU][ki:][nI]        zUkinI      zUki:nI\n",
       "100624  zucchinis  zU-'ki-nIz  [zU][ki:][nIz]       zUkinIz     zUki:nIz\n",
       "\n",
       "[90401 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celex_phonology_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_mapped = get_celex_transcription(homophones_in_data,celex_phonology_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>cond_pred_next</th>\n",
       "      <th>has_pair</th>\n",
       "      <th>pron</th>\n",
       "      <th>celexPhon</th>\n",
       "      <th>pron_frequency</th>\n",
       "      <th>is_max</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>14.940000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>297.990000</td>\n",
       "      <td>298.300000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>737.299999</td>\n",
       "      <td>737.609999</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1187.000000</td>\n",
       "      <td>1187.520000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1195.000000</td>\n",
       "      <td>1195.350000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1260.480000</td>\n",
       "      <td>1260.780000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>'p#st</td>\n",
       "      <td>[pA:st]</td>\n",
       "      <td>p#st</td>\n",
       "      <td>pA:st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1264.710000</td>\n",
       "      <td>1264.750000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>'p#st</td>\n",
       "      <td>[pA:st]</td>\n",
       "      <td>p#st</td>\n",
       "      <td>pA:st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>higher</td>\n",
       "      <td>1307.420000</td>\n",
       "      <td>1307.800000</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>False</td>\n",
       "      <td>h2_TR</td>\n",
       "      <td>h2@R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'h2-@R</td>\n",
       "      <td>[haI][@r*]</td>\n",
       "      <td>h2@R</td>\n",
       "      <td>haI@r*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>waste</td>\n",
       "      <td>1384.379999</td>\n",
       "      <td>1384.669999</td>\n",
       "      <td>0.29</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>False</td>\n",
       "      <td>w1st</td>\n",
       "      <td>w1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'w1st</td>\n",
       "      <td>[weIst]</td>\n",
       "      <td>w1st</td>\n",
       "      <td>weIst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>chilly</td>\n",
       "      <td>1403.240000</td>\n",
       "      <td>1403.650000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>False</td>\n",
       "      <td>JI_lI</td>\n",
       "      <td>JIlI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'JI-lI</td>\n",
       "      <td>[tSI][lI]</td>\n",
       "      <td>JIlI</td>\n",
       "      <td>tSIlI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source_file    word        start  \\\n",
       "0    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night    14.540000   \n",
       "1    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   297.990000   \n",
       "2    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   737.299999   \n",
       "3    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1187.000000   \n",
       "4    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1195.000000   \n",
       "..                                           ...     ...          ...   \n",
       "200         2016-12-17_1330_US_KCET_Asia_Insight  passed  1260.480000   \n",
       "201         2016-12-17_1330_US_KCET_Asia_Insight  passed  1264.710000   \n",
       "202         2016-12-17_1330_US_KCET_Asia_Insight  higher  1307.420000   \n",
       "203         2016-12-17_1330_US_KCET_Asia_Insight   waste  1384.379999   \n",
       "204         2016-12-17_1330_US_KCET_Asia_Insight  chilly  1403.240000   \n",
       "\n",
       "             end  duration       label_type mp4_error aac_error aac2wav_error  \\\n",
       "0      14.940000      0.40  high-confidence  no-error  no-error      no-error   \n",
       "1     298.300000      0.31  high-confidence  no-error  no-error      no-error   \n",
       "2     737.609999      0.31  high-confidence  no-error  no-error      no-error   \n",
       "3    1187.520000      0.52  high-confidence  no-error  no-error      no-error   \n",
       "4    1195.350000      0.35   low-confidence  no-error  no-error      no-error   \n",
       "..           ...       ...              ...       ...       ...           ...   \n",
       "200  1260.780000      0.30  high-confidence  no-error  no-error      no-error   \n",
       "201  1264.750000      0.04   low-confidence  no-error  no-error      no-error   \n",
       "202  1307.800000      0.38  high-confidence  no-error  no-error      no-error   \n",
       "203  1384.669999      0.29  high-confidence  no-error  no-error      no-error   \n",
       "204  1403.650000      0.41  high-confidence  no-error  no-error      no-error   \n",
       "\n",
       "    eafgz_error  ... cond_pred_next  has_pair   pron  celexPhon  \\\n",
       "0      no-error  ...       0.005493     False    n2t        n2t   \n",
       "1      no-error  ...       0.001763     False    n2t        n2t   \n",
       "2      no-error  ...       0.002229     False    n2t        n2t   \n",
       "3      no-error  ...       0.000725     False    n2t        n2t   \n",
       "4      no-error  ...       0.001257     False    n2t        n2t   \n",
       "..          ...  ...            ...       ...    ...        ...   \n",
       "200    no-error  ...       0.000250      True   pBst       p#st   \n",
       "201    no-error  ...       0.000084      True   pBst       p#st   \n",
       "202    no-error  ...       0.010053     False  h2_TR       h2@R   \n",
       "203    no-error  ...       0.000051     False   w1st       w1st   \n",
       "204    no-error  ...       0.002680     False  JI_lI       JIlI   \n",
       "\n",
       "    pron_frequency  is_max    disc         clx  disc_no_bound clx_no_bound  \n",
       "0               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "1               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "2               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "3               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "4               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "..             ...     ...     ...         ...            ...          ...  \n",
       "200              6       1   'p#st     [pA:st]           p#st        pA:st  \n",
       "201              6       1   'p#st     [pA:st]           p#st        pA:st  \n",
       "202              1       1  'h2-@R  [haI][@r*]           h2@R       haI@r*  \n",
       "203              1       1   'w1st     [weIst]           w1st        weIst  \n",
       "204              1       1  'JI-lI   [tSI][lI]           JIlI        tSIlI  \n",
       "\n",
       "[205 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_character_code = pd.read_csv(\"Data/celex_phonetic_character_code_berndt1987.csv\", delimiter=\";\")\n",
    "berndt_conditional_probs = pd.read_csv(\"Data/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyboard_compatible_phonetic_symbol</th>\n",
       "      <th>CELEX</th>\n",
       "      <th>g2p(ARPAbet)</th>\n",
       "      <th>DISC</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ay</td>\n",
       "      <td>eI</td>\n",
       "      <td>EY1</td>\n",
       "      <td>1</td>\n",
       "      <td>ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>AE1</td>\n",
       "      <td>{</td>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee</td>\n",
       "      <td>i:</td>\n",
       "      <td>IY1</td>\n",
       "      <td>i</td>\n",
       "      <td>bee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eh</td>\n",
       "      <td>E</td>\n",
       "      <td>EH1</td>\n",
       "      <td>E</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>er</td>\n",
       "      <td>@r*</td>\n",
       "      <td>ER0</td>\n",
       "      <td>@R</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>aI</td>\n",
       "      <td>AY1</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ih</td>\n",
       "      <td>I</td>\n",
       "      <td>IH1</td>\n",
       "      <td>I</td>\n",
       "      <td>bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>@U</td>\n",
       "      <td>OW1</td>\n",
       "      <td>5</td>\n",
       "      <td>boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ah</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1</td>\n",
       "      <td>Q</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aw</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1</td>\n",
       "      <td>Q</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oo</td>\n",
       "      <td>u:</td>\n",
       "      <td>UW1</td>\n",
       "      <td>u</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u</td>\n",
       "      <td>U</td>\n",
       "      <td>UH1</td>\n",
       "      <td>U</td>\n",
       "      <td>hook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yu</td>\n",
       "      <td>ju:</td>\n",
       "      <td>YUW1</td>\n",
       "      <td>ju</td>\n",
       "      <td>unite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>uh+</td>\n",
       "      <td>V</td>\n",
       "      <td>AH1</td>\n",
       "      <td>V</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oy</td>\n",
       "      <td>OI</td>\n",
       "      <td>OY1</td>\n",
       "      <td>4</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>au</td>\n",
       "      <td>aU</td>\n",
       "      <td>AW1</td>\n",
       "      <td>6</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>uh-</td>\n",
       "      <td>@</td>\n",
       "      <td>AH0</td>\n",
       "      <td>@</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>d</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>G</td>\n",
       "      <td>g</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>HH</td>\n",
       "      <td>h</td>\n",
       "      <td>hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dj</td>\n",
       "      <td>dZ</td>\n",
       "      <td>JH</td>\n",
       "      <td>_</td>\n",
       "      <td>joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>K</td>\n",
       "      <td>k</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>L</td>\n",
       "      <td>l</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>M</td>\n",
       "      <td>m</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>n</td>\n",
       "      <td>nod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>P</td>\n",
       "      <td>p</td>\n",
       "      <td>pen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>r</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>sue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>t</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>V</td>\n",
       "      <td>v</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>y</td>\n",
       "      <td>j</td>\n",
       "      <td>Y</td>\n",
       "      <td>j</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>z</td>\n",
       "      <td>z</td>\n",
       "      <td>Z</td>\n",
       "      <td>z</td>\n",
       "      <td>zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tch</td>\n",
       "      <td>tS</td>\n",
       "      <td>CH</td>\n",
       "      <td>J</td>\n",
       "      <td>chin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ks</td>\n",
       "      <td>ks</td>\n",
       "      <td>KS</td>\n",
       "      <td>ks</td>\n",
       "      <td>ox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gz</td>\n",
       "      <td>gz</td>\n",
       "      <td>GZ</td>\n",
       "      <td>gz</td>\n",
       "      <td>exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kw</td>\n",
       "      <td>kw</td>\n",
       "      <td>KW</td>\n",
       "      <td>kw</td>\n",
       "      <td>quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ul</td>\n",
       "      <td>l,</td>\n",
       "      <td>AH0L</td>\n",
       "      <td>P</td>\n",
       "      <td>puddle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>um</td>\n",
       "      <td>@m</td>\n",
       "      <td>AH0M</td>\n",
       "      <td>@m</td>\n",
       "      <td>chasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>un</td>\n",
       "      <td>n,</td>\n",
       "      <td>AH0N</td>\n",
       "      <td>H</td>\n",
       "      <td>pardon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ng</td>\n",
       "      <td>N</td>\n",
       "      <td>NG</td>\n",
       "      <td>N</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sh</td>\n",
       "      <td>S</td>\n",
       "      <td>SH</td>\n",
       "      <td>S</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>th-</td>\n",
       "      <td>T</td>\n",
       "      <td>TH</td>\n",
       "      <td>T</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>th+</td>\n",
       "      <td>D</td>\n",
       "      <td>DH</td>\n",
       "      <td>D</td>\n",
       "      <td>then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>zh</td>\n",
       "      <td>Z</td>\n",
       "      <td>ZH</td>\n",
       "      <td>Z</td>\n",
       "      <td>rouge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>honest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyboard_compatible_phonetic_symbol CELEX g2p(ARPAbet) DISC Example\n",
       "0                                   ay    eI          EY1    1     ale\n",
       "1                                   ae     &          AE1    {     add\n",
       "2                                   ee    i:          IY1    i     bee\n",
       "3                                   eh     E          EH1    E     end\n",
       "4                                   er   @r*          ER0   @R  father\n",
       "5                                   ai    aI          AY1    2    high\n",
       "6                                   ih     I          IH1    I     bin\n",
       "7                                    o    @U          OW1    5    boat\n",
       "8                                   ah     O          AA1    Q     cot\n",
       "9                                   aw     O          AA1    Q    soft\n",
       "10                                  oo    u:          UW1    u    food\n",
       "11                                   u     U          UH1    U    hook\n",
       "12                                  yu   ju:         YUW1   ju   unite\n",
       "13                                 uh+     V          AH1    V      up\n",
       "14                                  oy    OI          OY1    4     boy\n",
       "15                                  au    aU          AW1    6     out\n",
       "16                                 uh-     @          AH0    @   about\n",
       "17                                   b     b            B    b     but\n",
       "18                                   d     d            D    d     day\n",
       "19                                   f     f            F    f     fan\n",
       "20                                   g     g            G    g      go\n",
       "21                                   h     h           HH    h     hat\n",
       "22                                  dj    dZ           JH    _    joke\n",
       "23                                   k     k            K    k    keep\n",
       "24                                   l     l            L    l    late\n",
       "25                                   m     m            M    m     man\n",
       "26                                   n     n            N    n     nod\n",
       "27                                   p     p            P    p     pen\n",
       "28                                   r     r            R    r     rat\n",
       "29                                   s     s            S    s     sue\n",
       "30                                   t     t            T    t     two\n",
       "31                                   v     v            V    v     van\n",
       "32                                   w     w            W    w    wait\n",
       "33                                   y     j            Y    j     yet\n",
       "34                                   z     z            Z    z    zone\n",
       "35                                 tch    tS           CH    J    chin\n",
       "36                                  ks    ks           KS   ks      ox\n",
       "37                                  gz    gz           GZ   gz   exist\n",
       "38                                  kw    kw           KW   kw    quit\n",
       "39                                  ul    l,         AH0L    P  puddle\n",
       "40                                  um    @m         AH0M   @m   chasm\n",
       "41                                  un    n,         AH0N    H  pardon\n",
       "42                                  ng     N           NG    N    sing\n",
       "43                                  sh     S           SH    S     she\n",
       "44                                 th-     T           TH    T    thin\n",
       "45                                 th+     D           DH    D    then\n",
       "46                                  zh     Z           ZH    Z   rouge\n",
       "47                                  nl   NaN          NaN  NaN  honest"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_character_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'letter_length', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next', 'has_pair', 'pron', 'celexPhon',\n",
       "       'pron_frequency', 'is_max', 'disc', 'clx', 'disc_no_bound',\n",
       "       'clx_no_bound'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_mapped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39337</th>\n",
       "      <td>gym</td>\n",
       "      <td>'_Im</td>\n",
       "      <td>[dZIm]</td>\n",
       "      <td>_Im</td>\n",
       "      <td>dZIm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  disc     clx disc_no_bound clx_no_bound\n",
       "39337  gym  '_Im  [dZIm]           _Im         dZIm"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celex_phonology_dict[celex_phonology_dict.word == \"gym\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet_encoded_words = get_ARPAbet_phonetic_transcription(homophones_in_data_celex_mapped.word)\n",
    "arpabet_used_in_data = set(sum(arpabet_encoded_words,[]))\n",
    "\n",
    "#disc_encoded_words = list(homophones_in_data_celex_mapped.disc[pd.notnull(homophones_in_data_celex_mapped.disc)].str.replace(\"'\",\"\").str.split(\"-\"))\n",
    "#disc_used_in_data = set(sum(disc_encoded_words,[]))\n",
    "\n",
    "#clx_encoded_words = list(homophones_in_data_celex_mapped.clx[pd.notnull(homophones_in_data_celex_mapped.clx)].str.replace(\"[\",\"\").str.split(\"]\"))\n",
    "#clx_used_in_data = set(filter(lambda x: x != \"\",sum(clx_encoded_words,[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'AO1', 'EH0', 'ER1', 'EY2', 'IH0', 'IY0', 'OW0', 'OW2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpabet_used_in_data - set(berndt_character_code[\"g2p(ARPAbet)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_characters_used_in_data = set(''.join(list(disc_used_in_data)))\n",
    "disc_characters_for_berndts_encoding = set(''.join([str(i) for i in list(set(berndt_character_code.DISC))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_characters_used_in_data = set(''.join(list(clx_used_in_data)))\n",
    "clx_characters_for_berndts_encoding = set(''.join([str(i) for i in list(set(berndt_character_code.CELEX))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#', '$', '7', '8'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_characters_used_in_data - disc_characters_for_berndts_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clx_characters_used_in_data - clx_characters_for_berndts_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: b8R ['b8R'] bear\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: f8R ['f8R'] fair\n",
      "Missing: h$l ['h$l'] hall\n",
      "Missing: p#st ['p#st'] passed\n",
      "Missing: p#st ['p#st'] passed\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(disc_encoded_words):\n",
    "    for j in word:\n",
    "        if any(x in j for x in ['#', '$', '7', '8']):\n",
    "            print(\"Missing:\", j, word, homophones_in_data_celex_mapped.word[pd.notnull(homophones_in_data_celex_mapped.disc)].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] passed\n",
      "Missing: pA:st ['pA:st', ''] passed\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(clx_encoded_words):\n",
    "    for j in word:\n",
    "        if any(x in j for x in ['A']):\n",
    "            print(\"Missing:\", j, word, homophones_in_data_celex_mapped.word[pd.notnull(homophones_in_data_celex_mapped.clx)].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(arpabet_encoded_words):\n",
    "    for j in word:\n",
    "        if j in [\"EY2\"]:\n",
    "            print(\"Missing:\", j, word, homophones_in_data.word.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'AO1', 'EH0', 'ER1', 'EY2', 'IY0', 'OW0', 'OW2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ER1: heard, hurts\n",
    "EH0: ensure\n",
    "EY2: fiance\n",
    "AA2: lumbar\n",
    "OW0 : cocoa\n",
    "OW2: coco\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EY1', 'L'],\n",
       " ['AE1', 'D'],\n",
       " ['B', 'IY1'],\n",
       " ['EH1', 'N', 'D'],\n",
       " ['F', 'AA1', 'DH', 'ER0'],\n",
       " ['HH', 'AY1'],\n",
       " ['B', 'IH1', 'N'],\n",
       " ['B', 'OW1', 'T'],\n",
       " ['K', 'AA1', 'T'],\n",
       " ['S', 'AA1', 'F', 'T'],\n",
       " ['F', 'UW1', 'D'],\n",
       " ['HH', 'UH1', 'K'],\n",
       " ['Y', 'UW1', 'N', 'AY2', 'T'],\n",
       " ['AH1', 'P'],\n",
       " ['B', 'OY1'],\n",
       " ['AW1', 'T'],\n",
       " ['AH0', 'B', 'AW1', 'T'],\n",
       " ['B', 'AH1', 'T'],\n",
       " ['D', 'EY1'],\n",
       " ['F', 'AE1', 'N'],\n",
       " ['G', 'OW1'],\n",
       " ['HH', 'AE1', 'T'],\n",
       " ['JH', 'OW1', 'K'],\n",
       " ['K', 'IY1', 'P'],\n",
       " ['L', 'EY1', 'T'],\n",
       " ['M', 'AE1', 'N'],\n",
       " ['N', 'AA1', 'D'],\n",
       " ['P', 'EH1', 'N'],\n",
       " ['R', 'AE1', 'T'],\n",
       " ['S', 'UW1'],\n",
       " ['T', 'UW1'],\n",
       " ['V', 'AE1', 'N'],\n",
       " ['W', 'EY1', 'T'],\n",
       " ['Y', 'EH1', 'T'],\n",
       " ['Z', 'OW1', 'N'],\n",
       " ['CH', 'IH1', 'N'],\n",
       " ['AA1', 'K', 'S'],\n",
       " ['IH0', 'G', 'Z', 'IH1', 'S', 'T'],\n",
       " ['K', 'W', 'IH1', 'T'],\n",
       " ['P', 'AH1', 'D', 'AH0', 'L'],\n",
       " ['K', 'AE1', 'Z', 'AH0', 'M'],\n",
       " ['P', 'AA1', 'R', 'D', 'AH0', 'N'],\n",
       " ['S', 'IH1', 'NG'],\n",
       " ['SH', 'IY1'],\n",
       " ['TH', 'IH1', 'N'],\n",
       " ['DH', 'EH1', 'N'],\n",
       " ['R', 'UW1', 'ZH'],\n",
       " ['AA1', 'N', 'AH0', 'S', 'T']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ARPAbet_phonetic_transcription(berndt_character_code.Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IH0', 'G', 'Z', 'IH1', 'S', 'T'] exist\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(get_ARPAbet_phonetic_transcription(berndt_character_code.Example)):\n",
    "    for j in word:\n",
    "        if j in ['IH0']:\n",
    "            print(word, berndt_character_code.Example[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R', 'IH1', 'NG', 'IH0', 'NG']]\n",
      "[['B', 'IH1', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"ringing\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bin\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'IY1']]\n",
      "[['CH', 'IH1', 'L', 'IY0']]\n",
      "[['G', 'R', 'IY1', 'D', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"bee\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"chilly\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"greedy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', 'AA1', 'F', 'T']]\n",
      "[['B', 'AO1', 'R', 'D']]\n",
      "[['K', 'AO1', 'R', 'S']]\n",
      "[['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"soft\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"board\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"course\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"extraordinary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EH0', 'N', 'SH', 'UH1', 'R']]\n",
      "[['EH1', 'N', 'D', 'ER0', 'AH0', 'N', 'S']]\n",
      "[['EH0', 'N', 'G', 'EY1', 'JH']]\n",
      "[['EH0', 'N', 'EY1', 'B', 'AH0', 'L']]\n",
      "[['EH1', 'N', 'D']]\n",
      "[['EH1', 'JH']]\n",
      "[['EH1', 'N', 'T', 'ER0']]\n",
      "[['EH0', 'N', 'R', 'UW1', 'T', 'UW2', 'D']]\n",
      "[['AA1', 'N', 'K', 'AO2', 'R']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"ensure\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"endurance\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"engage\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enable\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"end\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"edge\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enter\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enrooted\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"encore\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ER1', 'N']]\n",
      "[['F', 'AA1', 'DH', 'ER0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"earn\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"father\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F', 'IY0', 'AA1', 'N', 'S', 'EY2']]\n",
      "[['EH1', 'JH', 'AH0', 'K', 'EY2', 'T']]\n",
      "[['IH0', 'G', 'Z', 'AE1', 'JH', 'ER0', 'EY2', 'T']]\n",
      "[['S', 'ER1', 'V', 'EY2']]\n",
      "[['B', 'EY1']]\n",
      "[['K', 'AH0', 'N', 'V', 'EY1']]\n",
      "[['P', 'R', 'EY1']]\n",
      "[['G', 'R', 'EY1']]\n",
      "[['P', 'ER0', 'V', 'EY1']]\n",
      "[['TH', 'ER1', 'Z', 'D', 'EY2']]\n",
      "[['D', 'EY1']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"fiance\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"educate\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"exaggerate\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"survey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bay\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"convey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"prey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"gray\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"purvey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"thursday\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"day\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F', 'AA1', 'L', 'OW0', 'IH0', 'NG']]\n",
      "[['B', 'Y', 'UH1', 'R', 'OW0']]\n",
      "[['CH', 'EH1', 'L', 'OW0']]\n",
      "[['AO1', 'L', 'S', 'OW0']]\n",
      "[['K', 'R', 'IH0', 'SH', 'EH1', 'N', 'D', 'OW0']]\n",
      "[['G', 'OW1', 'T']]\n",
      "[['K', 'OW1', 'K', 'OW2']]\n",
      "[['B', 'OW1', 'T']]\n",
      "[['AW1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"following\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bureau\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cello\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"also\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"crescendo\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"goat\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"coco\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"boat\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"out\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L', 'AH1', 'M', 'B', 'AA2', 'R']]\n",
      "[['L', 'AA1', 'R', 'JH']]\n",
      "[['F', 'AA1', 'DH', 'ER0']]\n",
      "[['K', 'AA1', 'T']]\n",
      "[['K', 'AA1', 'M', 'AH0']]\n",
      "[['K', 'AA1', 'M', 'AH0']]\n",
      "[['B', 'AA1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"lumbar\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"large\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"father\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cot\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"comma\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"comma\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bot\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', 'AA1', 'F', 'T']]\n",
      "[['K', 'AA1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"soft\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cot\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(get_ARPAbet_phonetic_transcription(berndt_character_code.Example)):\n",
    "    for j in word:\n",
    "        if j in ['IH0']:\n",
    "            print(word, berndt_character_code.Example[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_conditional_probs_words = get_ARPAbet_phonetic_transcription(berndt_conditional_probs.Example)\n",
    "arpabet_used_in_bernd_examples = set(sum(berndt_conditional_probs_words,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 AO1 ['AO1', 'L', 'S', 'OW0'] also\n",
      "11 AO1 ['AO1', 'R', 'AH0', 'N', 'JH'] orange\n",
      "13 AO1 ['F', 'AO1', 'L', 'S'] false\n",
      "27 AO1 ['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0'] extraordinary\n",
      "28 AO1 ['F', 'AO1', 'S', 'AH0', 'T'] faucet\n",
      "30 AO1 ['T', 'AO1', 'P'] taupe \n",
      "31 AO1 ['IH0', 'P', 'AO1', 'L', 'AH0', 'T'] epaulet\n",
      "33 AO1 ['M', 'AO1', 'V'] mauve\n",
      "36 AO1 ['L', 'AO1'] law\n",
      "73 AO1 ['F', 'AO1', 'R', 'F', 'IH0', 'T'] forfeit\n",
      "127 AO1 ['AO1', 'F'] off\n",
      "137 AO1 ['G', 'AO1', 'N'] gone\n",
      "142 AO1 ['B', 'R', 'AO1', 'D'] broad\n",
      "143 AO1 ['K', 'AO1', 'R', 'S'] coarse\n",
      "150 AO1 ['T', 'AO1', 'R', 'T', 'AH0', 'S'] tortoise\n",
      "153 AO1 ['D', 'AO1', 'R'] door\n",
      "155 AO1 ['IH0', 'N', 'AO1', 'R', 'M', 'AH0', 'S'] enormous\n",
      "158 AO1 ['F', 'AO1', 'R'] four\n",
      "164 AO1 ['K', 'AO1', 'R', 'S'] course\n",
      "203 AO1 ['S', 'T', 'AO1', 'R', 'IY0'] story\n",
      "223 AO1 ['K', 'AO1', 'R', 'AH0', 'S'] chorus\n",
      "237 AO1 ['K', 'AO1', 'R', 'JH', 'AH0', 'L'] cordial\n",
      "241 AO1 ['SH', 'AO1', 'R', 'T', 'AH0', 'N'] shorten\n",
      "246 AO1 ['AO1', 'F', 'AH0', 'N'] often\n",
      "269 AO1 ['T', 'AO1', 'K'] talk\n",
      "270 AO1 ['AO1', 'L'] all\n",
      "319 AO1 ['S', 'AO1', 'R', 'D'] sword\n",
      "324 AO1 ['M', 'AO1', 'R', 'G', 'AH0', 'JH'] mortgage\n",
      "325 AO1 ['TH', 'AO1'] thaw\n",
      "341 AO1 ['W', 'AO1', 'L', 'T', 'S'] waltz\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(berndt_conditional_probs_words):\n",
    "    for j in word:\n",
    "        if j in [\"AO1\"]:\n",
    "            print(i,j, word, berndt_conditional_probs.Example.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'OW2'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpabet_used_in_data - arpabet_used_in_bernd_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Keyboard compatible phonetic symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_character_code = pd.read_csv(\"Data/celex_phonetic_character_code_berndt1987.csv\", delimiter=\";\")\n",
    "berndt_conditional_probs = pd.read_csv(\"Data/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_conditional_probs_words = get_ARPAbet_phonetic_transcription(berndt_conditional_probs.Example)\n",
    "arpabet_used_in_bernd_examples = set(sum(berndt_conditional_probs_words,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyboard_compatible_phonetic_symbol</th>\n",
       "      <th>CELEX</th>\n",
       "      <th>g2p(ARPAbet)</th>\n",
       "      <th>DISC</th>\n",
       "      <th>Example</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ay</td>\n",
       "      <td>eI</td>\n",
       "      <td>EY1,EY2</td>\n",
       "      <td>1</td>\n",
       "      <td>ale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>AE0,AE1,AE2</td>\n",
       "      <td>{</td>\n",
       "      <td>add</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee</td>\n",
       "      <td>i:</td>\n",
       "      <td>IY0, IY1</td>\n",
       "      <td>i</td>\n",
       "      <td>bee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eh</td>\n",
       "      <td>E</td>\n",
       "      <td>EH0,EH1,EH2</td>\n",
       "      <td>E</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>er</td>\n",
       "      <td>@r*</td>\n",
       "      <td>ER0,ER1,ER2</td>\n",
       "      <td>@R</td>\n",
       "      <td>father</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>aI</td>\n",
       "      <td>AY0,AY1,AY2</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ih</td>\n",
       "      <td>I</td>\n",
       "      <td>IH0,IH1,IH2</td>\n",
       "      <td>I</td>\n",
       "      <td>bin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>@U</td>\n",
       "      <td>OW0,OW1,OW2</td>\n",
       "      <td>5</td>\n",
       "      <td>boat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ah</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1,AA2</td>\n",
       "      <td>Q</td>\n",
       "      <td>cot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aw</td>\n",
       "      <td>O</td>\n",
       "      <td>AO1,AO2</td>\n",
       "      <td>Q</td>\n",
       "      <td>soft</td>\n",
       "      <td>AA1 in soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oo</td>\n",
       "      <td>u:</td>\n",
       "      <td>UW0,UW1</td>\n",
       "      <td>u</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u</td>\n",
       "      <td>U</td>\n",
       "      <td>UH1</td>\n",
       "      <td>U</td>\n",
       "      <td>hook</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yu</td>\n",
       "      <td>ju:</td>\n",
       "      <td>YUW1</td>\n",
       "      <td>ju</td>\n",
       "      <td>unite</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>uh+</td>\n",
       "      <td>V</td>\n",
       "      <td>AH1</td>\n",
       "      <td>V</td>\n",
       "      <td>up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oy</td>\n",
       "      <td>OI</td>\n",
       "      <td>OY1,OY2</td>\n",
       "      <td>4</td>\n",
       "      <td>boy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>au</td>\n",
       "      <td>aU</td>\n",
       "      <td>AW0,AW1</td>\n",
       "      <td>6</td>\n",
       "      <td>out</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>uh-</td>\n",
       "      <td>@</td>\n",
       "      <td>AH0</td>\n",
       "      <td>@</td>\n",
       "      <td>about</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>but</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>d</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>fan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>G</td>\n",
       "      <td>g</td>\n",
       "      <td>go</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>HH</td>\n",
       "      <td>h</td>\n",
       "      <td>hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dj</td>\n",
       "      <td>dZ</td>\n",
       "      <td>JH</td>\n",
       "      <td>_</td>\n",
       "      <td>joke</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>K</td>\n",
       "      <td>k</td>\n",
       "      <td>keep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>L</td>\n",
       "      <td>l</td>\n",
       "      <td>late</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>M</td>\n",
       "      <td>m</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>n</td>\n",
       "      <td>nod</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>P</td>\n",
       "      <td>p</td>\n",
       "      <td>pen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>r</td>\n",
       "      <td>rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>sue</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>t</td>\n",
       "      <td>two</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>V</td>\n",
       "      <td>v</td>\n",
       "      <td>van</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "      <td>wait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>y</td>\n",
       "      <td>j</td>\n",
       "      <td>Y</td>\n",
       "      <td>j</td>\n",
       "      <td>yet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>z</td>\n",
       "      <td>z</td>\n",
       "      <td>Z</td>\n",
       "      <td>z</td>\n",
       "      <td>zone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tch</td>\n",
       "      <td>tS</td>\n",
       "      <td>CH</td>\n",
       "      <td>J</td>\n",
       "      <td>chin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ks</td>\n",
       "      <td>ks</td>\n",
       "      <td>KS</td>\n",
       "      <td>ks</td>\n",
       "      <td>ox</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gz</td>\n",
       "      <td>gz</td>\n",
       "      <td>GZ</td>\n",
       "      <td>gz</td>\n",
       "      <td>exist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kw</td>\n",
       "      <td>kw</td>\n",
       "      <td>KW</td>\n",
       "      <td>kw</td>\n",
       "      <td>quit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ul</td>\n",
       "      <td>l,</td>\n",
       "      <td>AH0-L</td>\n",
       "      <td>P</td>\n",
       "      <td>puddle</td>\n",
       "      <td>AH0-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>um</td>\n",
       "      <td>@m</td>\n",
       "      <td>AH0-M</td>\n",
       "      <td>@m</td>\n",
       "      <td>chasm</td>\n",
       "      <td>AHO-M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>un</td>\n",
       "      <td>n,</td>\n",
       "      <td>AH0-N</td>\n",
       "      <td>H</td>\n",
       "      <td>pardon</td>\n",
       "      <td>AHO-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ng</td>\n",
       "      <td>N</td>\n",
       "      <td>NG</td>\n",
       "      <td>N</td>\n",
       "      <td>sing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sh</td>\n",
       "      <td>S</td>\n",
       "      <td>SH</td>\n",
       "      <td>S</td>\n",
       "      <td>she</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>th-</td>\n",
       "      <td>T</td>\n",
       "      <td>TH</td>\n",
       "      <td>T</td>\n",
       "      <td>thin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>th+</td>\n",
       "      <td>D</td>\n",
       "      <td>DH</td>\n",
       "      <td>D</td>\n",
       "      <td>then</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>zh</td>\n",
       "      <td>Z</td>\n",
       "      <td>ZH</td>\n",
       "      <td>Z</td>\n",
       "      <td>rouge</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>honest</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyboard_compatible_phonetic_symbol CELEX g2p(ARPAbet) DISC Example  \\\n",
       "0                                   ay    eI      EY1,EY2    1     ale   \n",
       "1                                   ae     &  AE0,AE1,AE2    {     add   \n",
       "2                                   ee    i:     IY0, IY1    i     bee   \n",
       "3                                   eh     E  EH0,EH1,EH2    E     end   \n",
       "4                                   er   @r*  ER0,ER1,ER2   @R  father   \n",
       "5                                   ai    aI  AY0,AY1,AY2    2    high   \n",
       "6                                   ih     I  IH0,IH1,IH2    I     bin   \n",
       "7                                    o    @U  OW0,OW1,OW2    5    boat   \n",
       "8                                   ah     O      AA1,AA2    Q     cot   \n",
       "9                                   aw     O      AO1,AO2    Q    soft   \n",
       "10                                  oo    u:      UW0,UW1    u    food   \n",
       "11                                   u     U          UH1    U    hook   \n",
       "12                                  yu   ju:         YUW1   ju   unite   \n",
       "13                                 uh+     V          AH1    V      up   \n",
       "14                                  oy    OI      OY1,OY2    4     boy   \n",
       "15                                  au    aU      AW0,AW1    6     out   \n",
       "16                                 uh-     @          AH0    @   about   \n",
       "17                                   b     b            B    b     but   \n",
       "18                                   d     d            D    d     day   \n",
       "19                                   f     f            F    f     fan   \n",
       "20                                   g     g            G    g      go   \n",
       "21                                   h     h           HH    h     hat   \n",
       "22                                  dj    dZ           JH    _    joke   \n",
       "23                                   k     k            K    k    keep   \n",
       "24                                   l     l            L    l    late   \n",
       "25                                   m     m            M    m     man   \n",
       "26                                   n     n            N    n     nod   \n",
       "27                                   p     p            P    p     pen   \n",
       "28                                   r     r            R    r     rat   \n",
       "29                                   s     s            S    s     sue   \n",
       "30                                   t     t            T    t     two   \n",
       "31                                   v     v            V    v     van   \n",
       "32                                   w     w            W    w    wait   \n",
       "33                                   y     j            Y    j     yet   \n",
       "34                                   z     z            Z    z    zone   \n",
       "35                                 tch    tS           CH    J    chin   \n",
       "36                                  ks    ks           KS   ks      ox   \n",
       "37                                  gz    gz           GZ   gz   exist   \n",
       "38                                  kw    kw           KW   kw    quit   \n",
       "39                                  ul    l,        AH0-L    P  puddle   \n",
       "40                                  um    @m        AH0-M   @m   chasm   \n",
       "41                                  un    n,        AH0-N    H  pardon   \n",
       "42                                  ng     N           NG    N    sing   \n",
       "43                                  sh     S           SH    S     she   \n",
       "44                                 th-     T           TH    T    thin   \n",
       "45                                 th+     D           DH    D    then   \n",
       "46                                  zh     Z           ZH    Z   rouge   \n",
       "47                                  nl   NaN          NaN  NaN  honest   \n",
       "\n",
       "           Note  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9   AA1 in soft  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  \n",
       "18          NaN  \n",
       "19          NaN  \n",
       "20          NaN  \n",
       "21          NaN  \n",
       "22          NaN  \n",
       "23          NaN  \n",
       "24          NaN  \n",
       "25          NaN  \n",
       "26          NaN  \n",
       "27          NaN  \n",
       "28          NaN  \n",
       "29          NaN  \n",
       "30          NaN  \n",
       "31          NaN  \n",
       "32          NaN  \n",
       "33          NaN  \n",
       "34          NaN  \n",
       "35          NaN  \n",
       "36          NaN  \n",
       "37          NaN  \n",
       "38          NaN  \n",
       "39        AH0-L  \n",
       "40        AHO-M  \n",
       "41        AHO-N  \n",
       "42          NaN  \n",
       "43          NaN  \n",
       "44          NaN  \n",
       "45          NaN  \n",
       "46          NaN  \n",
       "47          NaN  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_character_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_arpabbet_dict = {}\n",
    "for i,p in enumerate(berndt_character_code[\"g2p(ARPAbet)\"]):\n",
    "    if not p is np.nan:\n",
    "        p = p.replace(\" \",\"\").split(\",\")       \n",
    "        if len(p) > 1:\n",
    "            for p_i in p:\n",
    "                \"\"\"\n",
    "                if p_i in berndt_arpabbet_dict:\n",
    "                    value_list = berndt_arpabbet_dict[p_i]\n",
    "                    if isinstance(value_list, list): \n",
    "                        value_list += [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                    else:\n",
    "                        value_list = [value_list] + [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                    \n",
    "                    berndt_arpabbet_dict[p_i] = value_list\n",
    "                else:\n",
    "                \"\"\"\n",
    "                berndt_arpabbet_dict[p_i] = berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]\n",
    "        else:\n",
    "            \"\"\"\n",
    "            if p[0] in berndt_arpabbet_dict:\n",
    "                value_list = berndt_arpabbet_dict[p[0]]\n",
    "                if isinstance(value_list, list): \n",
    "                    value_list += [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                else:\n",
    "                    value_list = [value_list] + [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                    \n",
    "                berndt_arpabbet_dict[p[0]] = value_list\n",
    "            else:   \n",
    "            \"\"\"\n",
    "            berndt_arpabbet_dict[p[0]] = berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EY1': 'ay',\n",
       " 'EY2': 'ay',\n",
       " 'AE0': 'ae',\n",
       " 'AE1': 'ae',\n",
       " 'AE2': 'ae',\n",
       " 'IY0': 'ee',\n",
       " 'IY1': 'ee',\n",
       " 'EH0': 'eh',\n",
       " 'EH1': 'eh',\n",
       " 'EH2': 'eh',\n",
       " 'ER0': 'er',\n",
       " 'ER1': 'er',\n",
       " 'ER2': 'er',\n",
       " 'AY0': 'ai',\n",
       " 'AY1': 'ai',\n",
       " 'AY2': 'ai',\n",
       " 'IH0': 'ih',\n",
       " 'IH1': 'ih',\n",
       " 'IH2': 'ih',\n",
       " 'OW0': 'o',\n",
       " 'OW1': 'o',\n",
       " 'OW2': 'o',\n",
       " 'AA1': 'ah',\n",
       " 'AA2': 'ah',\n",
       " 'AO1': 'aw',\n",
       " 'AO2': 'aw',\n",
       " 'UW0': 'oo',\n",
       " 'UW1': 'oo',\n",
       " 'UH1': 'u',\n",
       " 'YUW1': 'yu',\n",
       " 'AH1': 'uh+',\n",
       " 'OY1': 'oy',\n",
       " 'OY2': 'oy',\n",
       " 'AW0': 'au',\n",
       " 'AW1': 'au',\n",
       " 'AH0': 'uh-',\n",
       " 'B': 'b',\n",
       " 'D': 'd',\n",
       " 'F': 'f',\n",
       " 'G': 'g',\n",
       " 'HH': 'h',\n",
       " 'JH': 'dj',\n",
       " 'K': 'k',\n",
       " 'L': 'l',\n",
       " 'M': 'm',\n",
       " 'N': 'n',\n",
       " 'P': 'p',\n",
       " 'R': 'r',\n",
       " 'S': 's',\n",
       " 'T': 't',\n",
       " 'V': 'v',\n",
       " 'W': 'w',\n",
       " 'Y': 'y',\n",
       " 'Z': 'z',\n",
       " 'CH': 'tch',\n",
       " 'KS': 'ks',\n",
       " 'GZ': 'gz',\n",
       " 'KW': 'kw',\n",
       " 'AH0-L': 'ul',\n",
       " 'AH0-M': 'um',\n",
       " 'AH0-N': 'un',\n",
       " 'NG': 'ng',\n",
       " 'SH': 'sh',\n",
       " 'TH': 'th-',\n",
       " 'DH': 'th+',\n",
       " 'ZH': 'zh'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_arpabbet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyboard_phonetic_symbols(arpabet_word, dictionary):\n",
    "    skip_word = False\n",
    "    keyboard_encoding = []\n",
    "    for i,p in enumerate(arpabet_word):\n",
    "        if skip_word == True:\n",
    "            skip_word = False\n",
    "        else:\n",
    "            if p.startswith('AH0'):\n",
    "                if i<len(arpabet_word)-1:\n",
    "                    if arpabet_word[i+1] == \"L\":\n",
    "                        keyboard_encoding.append(dictionary[p + \"-\" + \"L\"])\n",
    "                        skip_word = True\n",
    "                    elif arpabet_word[i+1] == \"M\":\n",
    "                        keyboard_encoding.append(dictionary[p + \"-\" + \"M\"])\n",
    "                        skip_word = True\n",
    "                    elif arpabet_word[i+1] == \"N\":\n",
    "                        keyboard_encoding.append(dictionary[p + \"-\" + \"N\"])\n",
    "                        skip_word = True\n",
    "                    else:\n",
    "                        keyboard_encoding.append(dictionary[p])\n",
    "            else:\n",
    "                keyboard_encoding.append(dictionary[p])\n",
    "    return keyboard_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'AE1', 'B'] cab\n",
      "['k', 'ae', 'b']\n",
      "['K', 'AH0', 'N', 'AE1', 'L'] canal\n",
      "['k', 'un', 'ae', 'l']\n",
      "['EY1', 'N', 'JH', 'AH0', 'L'] angel\n",
      "['ay', 'n', 'dj', 'ul']\n",
      "['W', 'AA1', 'D'] wad\n",
      "['w', ['ah', 'aw'], 'd']\n",
      "['AO1', 'L', 'S', 'OW0'] also\n",
      "['aw', 'l', 's', 'o']\n",
      "['K', 'AW1', 'ER0', 'D'] coward\n",
      "['k', 'au', 'er', 'd']\n",
      "['M', 'EH1', 'N', 'IY0'] many\n",
      "['m', 'eh', 'n', 'ee']\n",
      "['S', 'P', 'IH1', 'N', 'AH0', 'CH'] spinach\n",
      "['s', 'p', 'ih', 'n', 'uh-', 'tch']\n",
      "['EY1', 'T'] ate\n",
      "['ay', 't']\n",
      "['S', 'EH1', 'N', 'AH0', 'T'] senate\n",
      "['s', 'eh', 'n', 'uh-', 't']\n",
      "['M', 'AE1', 'D', 'AH0', 'M'] madame\n",
      "['m', 'ae', 'd', 'um']\n",
      "['AO1', 'R', 'AH0', 'N', 'JH'] orange\n",
      "['aw', 'r', 'un', 'dj']\n",
      "['AA1', 'R'] are\n",
      "[['ah', 'aw'], 'r']\n",
      "['F', 'AO1', 'L', 'S'] false\n",
      "['f', 'aw', 'l', 's']\n",
      "['P', 'AY1', 'R', 'AH0', 'T'] pirate\n",
      "['p', 'ai', 'r', 'uh-', 't']\n",
      "['AE1', 'L', 'JH', 'IY0'] algae\n",
      "['ae', 'l', 'dj', 'ee']\n",
      "['EH0', 'S', 'TH', 'EH1', 'T', 'IH0', 'K'] aesthetic\n",
      "['eh', 's', 'th-', 'eh', 't', 'ih', 'k']\n",
      "['D', 'AE1', 'L', 'Y', 'AH0'] dahlia\n",
      "['d', 'ae', 'l', 'y']\n",
      "['EY1', 'D'] aid \n",
      "['ay', 'd']\n",
      "['S', 'EH1', 'D'] said\n",
      "['s', 'eh', 'd']\n",
      "['K', 'AE1', 'P', 'T', 'AH0', 'N'] captain\n",
      "['k', 'ae', 'p', 't', 'un']\n",
      "['V', 'IH1', 'L', 'AH0', 'N'] villain\n",
      "['v', 'ih', 'l', 'un']\n",
      "['P', 'L', 'AE1', 'D'] plaid\n",
      "['p', 'l', 'ae', 'd']\n",
      "['EY1', 'D'] aide\n",
      "['ay', 'd']\n",
      "['M', 'IH2', 'L', 'Y', 'AH0', 'N', 'EH1', 'R'] millionaire\n",
      "['m', 'ih', 'l', 'y', 'un', 'eh', 'r']\n",
      "['AY1', 'L'] aisle\n",
      "['ai', 'l']\n",
      "['S', 'T', 'R', 'EY1', 'T'] straight\n",
      "['s', 't', 'r', 'ay', 't']\n",
      "['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0'] extraordinary\n",
      "['ih', 'k', 's', 't', 'r', 'aw', 'r', 'd', 'un', 'eh', 'r', 'ee']\n",
      "['F', 'AO1', 'S', 'AH0', 'T'] faucet\n",
      "['f', 'aw', 's', 'uh-', 't']\n",
      "['AE1', 'N', 'T'] aunt\n",
      "['ae', 'n', 't']\n",
      "['T', 'AO1', 'P'] taupe \n",
      "['t', 'aw', 'p']\n",
      "['IH0', 'P', 'AO1', 'L', 'AH0', 'T'] epaulet\n",
      "['ih', 'p', 'aw', 'l', 'uh-', 't']\n",
      "['K', 'AA1', 'Z'] cause\n",
      "['k', ['ah', 'aw'], 'z']\n",
      "['M', 'AO1', 'V'] mauve\n",
      "['m', 'aw', 'v']\n",
      "['G', 'EY1', 'JH'] gauge\n",
      "['g', 'ay', 'dj']\n",
      "['K', 'AA1', 'T'] caught\n",
      "['k', ['ah', 'aw'], 't']\n",
      "['L', 'AO1'] law\n",
      "['l', 'aw']\n",
      "['AA1'] awe\n",
      "[['ah', 'aw']]\n",
      "['W', 'EY1'] way\n",
      "['w', 'ay']\n",
      "['K', 'AY1', 'AE0', 'K'] kayak \n",
      "['k', 'ai', 'ae', 'k']\n",
      "['S', 'EH1', 'Z'] says\n",
      "['s', 'eh', 'z']\n",
      "['AY1'] aye \n",
      "['ai']\n",
      "['EH1', 'N', 'D'] end\n",
      "['eh', 'n', 'd']\n",
      "['B', 'EY1', 'K', 'ER0'] baker\n",
      "['b', 'ay', 'k', 'er']\n",
      "['S', 'IY1', 'N', 'Y', 'ER0'] senior\n",
      "['s', 'ee', 'n', 'y', 'er']\n",
      "['R', 'IH0', 'B', 'EH1', 'L'] rebel\n",
      "['r', 'ih', 'b', 'eh', 'l']\n",
      "['K', 'AH0', 'F', 'EY1'] cafe \n",
      "['k', 'uh-', 'f', 'ay']\n",
      "['AA1', 'N', 'K', 'AO2', 'R'] encore\n",
      "[['ah', 'aw'], 'n', 'k', 'aw', 'r']\n",
      "['P', 'R', 'IH1', 'T', 'IY0'] pretty\n",
      "['p', 'r', 'ih', 't', 'ee']\n",
      "['AH0', 'Z', 'EY1', 'L', 'Y', 'AH0'] azalea\n",
      "['uh-', 'z', 'ay', 'l', 'y']\n",
      "['EH1', 'JH'] edge\n",
      "['eh', 'dj']\n",
      "['S', 'AY1', 'AH0', 'N', 'S'] science\n",
      "['s', 'ai', 'un', 's']\n",
      "['IY1', 'V'] eve\n",
      "['ee', 'v']\n",
      "['T', 'R', 'AE1', 'V', 'ER0', 'S'] traverse\n",
      "['t', 'r', 'ae', 'v', 'er', 's']\n",
      "['F', 'EY1', 'T'] fete\n",
      "['f', 'ay', 't']\n",
      "['P', 'R', 'IH1', 'V', 'L', 'AH0', 'JH'] privilege\n",
      "['p', 'r', 'ih', 'v', 'l', 'uh-', 'dj']\n",
      "['IY1', 'T'] eat\n",
      "['ee', 't']\n",
      "['HH', 'EH1', 'D'] head\n",
      "['h', 'eh', 'd']\n",
      "['ER1', 'N'] earn\n",
      "['er', 'n']\n",
      "['HH', 'AA1', 'R', 'T'] heart\n",
      "['h', ['ah', 'aw'], 'r', 't']\n",
      "['B', 'R', 'EY1', 'K'] break\n",
      "['b', 'r', 'ay', 'k']\n",
      "['P', 'AE1', 'JH', 'AH0', 'N', 'T'] pageant\n",
      "['p', 'ae', 'dj', 'un', 't']\n",
      "['IY1', 'Z'] ease\n",
      "['ee', 'z']\n",
      "['HH', 'ER1', 'S'] hearse\n",
      "['h', 'er', 's']\n",
      "['M', 'AY1', 'L', 'AH0', 'JH'] mileage\n",
      "['m', 'ai', 'l', 'uh-', 'dj']\n",
      "['K', 'L', 'EH1', 'N', 'Z'] cleanse\n",
      "['k', 'l', 'eh', 'n', 'z']\n",
      "['B', 'OW1'] beau\n",
      "['b', 'o']\n",
      "['B', 'Y', 'UW1', 'T', 'IY0'] beauty\n",
      "['b', 'y', 'oo', 't', 'ee']\n",
      "['B', 'IY1'] bee\n",
      "['b', 'ee']\n",
      "['B', 'IH1', 'N'] been\n",
      "['b', 'ih', 'n']\n",
      "['G', 'IY1', 'S'] geese\n",
      "['g', 'ee', 's']\n",
      "['S', 'IY1', 'L', 'IH0', 'NG'] ceiling\n",
      "['s', 'ee', 'l', 'ih', 'ng']\n",
      "['V', 'EY1', 'N'] vein\n",
      "['v', 'ay', 'n']\n",
      "['F', 'AO1', 'R', 'F', 'IH0', 'T'] forfeit\n",
      "['f', 'aw', 'r', 'f', 'ih', 't']\n",
      "['S', 'T', 'AY1', 'N'] stein\n",
      "['s', 't', 'ai', 'n']\n",
      "['HH', 'AY1', 'F', 'ER0'] heifer\n",
      "['h', 'ai', 'f', 'er']\n",
      "['S', 'AA1', 'V', 'R', 'AH0', 'N'] sovereign\n",
      "['s', ['ah', 'aw'], 'v', 'r', 'un']\n",
      "['S', 'IY1', 'Z'] seize\n",
      "['s', 'ee', 'z']\n",
      "['S', 'EY1', 'N', 'IY0'] seine\n",
      "['s', 'ay', 'n', 'ee']\n",
      "['EY1', 'T'] eight\n",
      "['ay', 't']\n",
      "['HH', 'AY1', 'T'] height\n",
      "['h', 'ai', 't']\n",
      "['P', 'IH1', 'JH', 'AH0', 'N'] pigeon\n",
      "['p', 'ih', 'dj', 'un']\n",
      "['L', 'EH1', 'P', 'ER0', 'D'] leopard\n",
      "['l', 'eh', 'p', 'er', 'd']\n",
      "['P', 'IY1', 'P', 'AH0', 'L'] people\n",
      "['p', 'ee', 'p', 'ul']\n",
      "['K', 'ER0', 'EY1', 'JH', 'AH0', 'S'] courageous\n",
      "['k', 'er', 'ay', 'dj', 'uh-', 's']\n",
      "['B', 'EH1', 'R', 'AH0', 'T'] beret\n",
      "['b', 'eh', 'r', 'uh-', 't']\n",
      "['F', 'Y', 'UW1', 'D'] feud\n",
      "['f', 'y', 'oo', 'd']\n",
      "['AE1', 'M', 'AH0', 'T', 'ER2'] amateur\n",
      "['ae', 'm', 'uh-', 't', 'er']\n",
      "['S', 'L', 'UW1', 'TH'] sleuth\n",
      "['s', 'l', 'oo', 'th-']\n",
      "['P', 'L', 'UH1', 'R', 'AH0', 'S', 'IY0'] pleurisy\n",
      "['p', 'l', 'u', 'r', 'uh-', 's', 'ee']\n",
      "['D', 'UW1', 'S'] deuce\n",
      "['d', 'oo', 's']\n",
      "['N', 'UW1', 'Z'] news\n",
      "['n', 'oo', 'z']\n",
      "['SH', 'R', 'UW1', 'D'] shrewd\n",
      "['sh', 'r', 'oo', 'd']\n",
      "['S', 'OW1'] sew\n",
      "['s', 'o']\n",
      "['Y', 'UW1'] ewe\n",
      "['y', 'oo']\n",
      "['K', 'IY1'] key\n",
      "['k', 'ee']\n",
      "['DH', 'EY1'] they \n",
      "['th+', 'ay']\n",
      "['G', 'AY1', 'Z', 'ER0'] geyser\n",
      "['g', 'ai', 'z', 'er']\n",
      "['EH1', 'R', 'IY0'] eyrie\n",
      "['eh', 'r', 'ee']\n",
      "['AY1'] eye \n",
      "['ai']\n",
      "['IH0', 'N'] in\n",
      "['ih', 'n']\n",
      "['S', 'IH1', 'V', 'AH0', 'L'] civil\n",
      "['s', 'ih', 'v', 'ul']\n",
      "['F', 'AY1', 'N', 'D'] find\n",
      "['f', 'ai', 'n', 'd']\n",
      "['AH0', 'F', 'ER1', 'M'] affirm \n",
      "['uh-', 'f', 'er', 'm']\n",
      "['S', 'IY1', 'N', 'Y', 'ER0'] senior\n",
      "['s', 'ee', 'n', 'y', 'er']\n",
      "['S', 'K', 'IY1'] ski\n",
      "['s', 'k', 'ee']\n",
      "['AY1', 'S'] ice\n",
      "['ai', 's']\n",
      "['G', 'IH1', 'V'] give\n",
      "['g', 'ih', 'v']\n",
      "['IH0', 'L', 'IY1', 'T'] elite\n",
      "['ih', 'l', 'ee', 't']\n",
      "['F', 'R', 'AE1', 'JH', 'AH0', 'L'] fragile \n",
      "['f', 'r', 'ae', 'dj', 'ul']\n",
      "['D', 'ER1', 'JH'] dirge\n",
      "['d', 'er', 'dj']\n",
      "['P', 'AA1', 'R', 'L', 'AH0', 'M', 'AH0', 'N', 'T'] parliament\n",
      "['p', ['ah', 'aw'], 'r', 'l', 'um', 'un', 't']\n",
      "['M', 'EH1', 'R', 'IH0', 'JH'] marriage\n",
      "['m', 'eh', 'r', 'ih', 'dj']\n",
      "['CH', 'IY1', 'F'] chief\n",
      "['tch', 'ee', 'f']\n",
      "['T', 'R', 'AY1', 'D'] tried\n",
      "['t', 'r', 'ai', 'd']\n",
      "['EY1', 'N', 'CH', 'AH0', 'N', 'T'] ancient\n",
      "['ay', 'n', 'tch', 'un', 't']\n",
      "['M', 'IH1', 'S', 'CH', 'AH0', 'F'] mischief\n",
      "['m', 'ih', 's', 'tch', 'uh-', 'f']\n",
      "['F', 'R', 'EH1', 'N', 'D'] friend\n",
      "['f', 'r', 'eh', 'n', 'd']\n",
      "['P', 'IY1', 'S'] piece\n",
      "['p', 'ee', 's']\n",
      "['P', 'EY1', 'SH', 'AH0', 'N', 'S'] patience\n",
      "['p', 'ay', 'sh', 'un', 's']\n",
      "['S', 'IH1', 'V'] sieve\n",
      "['s', 'ih', 'v']\n",
      "['L', 'UW1'] lieu\n",
      "['l', 'oo']\n",
      "['V', 'Y', 'UW1'] view\n",
      "['v', 'y', 'oo']\n",
      "['N', 'AY1', 'T'] night\n",
      "['n', 'ai', 't']\n",
      "['OW1', 'N', 'L', 'IY0'] only\n",
      "['o', 'n', 'l', 'ee']\n",
      "['K', 'AA1', 'R', 'T', 'AH0', 'N'] carton\n",
      "['k', ['ah', 'aw'], 'r', 't', 'un']\n",
      "['AA1', 'D'] odd\n",
      "[['ah', 'aw'], 'd']\n",
      "['AO1', 'F'] off\n",
      "['aw', 'f']\n",
      "['AA1', 'N', 'ER0'] honor \n",
      "[['ah', 'aw'], 'n', 'er']\n",
      "['AH1', 'V', 'AH0', 'N'] oven\n",
      "['uh+', 'v', 'un']\n",
      "['HH', 'UW1'] who\n",
      "['h', 'oo']\n",
      "['T', 'AH0', 'D', 'EY1'] today\n",
      "['t', 'uh-', 'd', 'ay']\n",
      "['W', 'IH1', 'M', 'AH0', 'N'] women\n",
      "['w', 'ih', 'm', 'un']\n",
      "['CH', 'UW1', 'Z'] choose\n",
      "['tch', 'oo', 'z']\n",
      "['K', 'OW1', 'D'] code\n",
      "['k', 'o', 'd']\n",
      "['K', 'AH1', 'M'] come\n",
      "['k', 'uh+', 'm']\n",
      "['W', 'EH1', 'L', 'K', 'AH0', 'M'] welcome\n",
      "['w', 'eh', 'l', 'k', 'um']\n",
      "['G', 'AO1', 'N'] gone\n",
      "['g', 'aw', 'n']\n",
      "['D', 'AA1', 'JH'] dodge\n",
      "['d', ['ah', 'aw'], 'dj']\n",
      "['L', 'UW1', 'Z'] lose\n",
      "['l', 'oo', 'z']\n",
      "['W', 'ER1', 'S'] worse\n",
      "['w', 'er', 's']\n",
      "['K', 'OW1', 'T'] coat\n",
      "['k', 'o', 't']\n",
      "['B', 'R', 'AO1', 'D'] broad\n",
      "['b', 'r', 'aw', 'd']\n",
      "['K', 'AO1', 'R', 'S'] coarse\n",
      "['k', 'aw', 'r', 's']\n",
      "['D', 'OW1'] doe\n",
      "['d', 'o']\n",
      "['AH0', 'M', 'IY1', 'B', 'AH0']  amoeba\n",
      "['um', 'ee', 'b']\n",
      "['K', 'AH0', 'N', 'UW1'] canoe \n",
      "['k', 'un', 'oo']\n",
      "['OW1', 'M'] ohm\n",
      "['o', 'm']\n",
      "['K', 'OY1', 'L'] coil\n",
      "['k', 'oy', 'l']\n",
      "['V', 'OY1', 'S'] voice\n",
      "['v', 'oy', 's']\n",
      "['T', 'AO1', 'R', 'T', 'AH0', 'S'] tortoise\n",
      "['t', 'aw', 'r', 't', 'uh-', 's']\n",
      "['B', 'UW1', 'T'] boot\n",
      "['b', 'oo', 't']\n",
      "['W', 'UH1', 'D'] wood\n",
      "['w', 'u', 'd']\n",
      "['D', 'AO1', 'R'] door\n",
      "['d', 'aw', 'r']\n",
      "['B', 'L', 'AH1', 'D'] blood\n",
      "['b', 'l', 'uh+', 'd']\n",
      "['IH0', 'N', 'AO1', 'R', 'M', 'AH0', 'S'] enormous\n",
      "['ih', 'n', 'aw', 'r', 'm', 'uh-', 's']\n",
      "['AW1', 'T'] out\n",
      "['au', 't']\n",
      "['T', 'AH1', 'CH'] touch\n",
      "['t', 'uh+', 'tch']\n",
      "['F', 'AO1', 'R'] four\n",
      "['f', 'aw', 'r']\n",
      "['Y', 'UW1'] you\n",
      "['y', 'oo']\n",
      "['K', 'UH1', 'D'] could\n",
      "['k', 'u', 'd']\n",
      "['G', 'L', 'AE1', 'M', 'ER0'] glamour\n",
      "['g', 'l', 'ae', 'm', 'er']\n",
      "['B', 'IH1', 'V', 'W', 'AE0', 'K'] bivouac \n",
      "['b', 'ih', 'v', 'w', 'ae', 'k']\n",
      "['AW1', 'N', 'S'] ounce\n",
      "['au', 'n', 's']\n",
      "['K', 'AO1', 'R', 'S'] course\n",
      "['k', 'aw', 'r', 's']\n",
      "['R', 'UW1', 'T'] route\n",
      "['r', 'oo', 't']\n",
      "['S', 'K', 'ER1', 'JH'] scourge\n",
      "['s', 'k', 'er', 'dj']\n",
      "['B', 'AA1', 'T'] bought \n",
      "['b', ['ah', 'aw'], 't']\n",
      "['D', 'OW1'] dough\n",
      "['d', 'o']\n",
      "['D', 'R', 'AW1', 'T'] drought\n",
      "['d', 'r', 'au', 't']\n",
      "['TH', 'R', 'UW1'] through\n",
      "['th-', 'r', 'oo']\n",
      "['OW1', 'N'] own\n",
      "['o', 'n']\n",
      "['T', 'AW1', 'AH0', 'L'] towel\n",
      "['t', 'au', 'ul']\n",
      "['N', 'AA1', 'L', 'AH0', 'JH'] knowledge\n",
      "['n', ['ah', 'aw'], 'l', 'uh-', 'dj']\n",
      "['B', 'R', 'AW1', 'Z'] browse\n",
      "['b', 'r', 'au', 'z']\n",
      "['OW1'] owe\n",
      "['o']\n",
      "['B', 'OY1'] boy\n",
      "['b', 'oy']\n",
      "['K', 'AY0', 'OW1', 'T', 'IY0'] coyote\n",
      "['k', 'ai', 'o', 't', 'ee']\n",
      "['G', 'AA1', 'R', 'G', 'OY2', 'L'] gargoyle\n",
      "['g', ['ah', 'aw'], 'r', 'g', 'oy', 'l']\n",
      "['AH1', 'P'] up\n",
      "['uh+', 'p']\n",
      "['Y', 'UW1', 'N', 'Y', 'AH0', 'N'] union\n",
      "['y', 'oo', 'n', 'y', 'un']\n",
      "['M', 'IY1', 'D', 'IY0', 'AH0', 'M'] medium\n",
      "['m', 'ee', 'd', 'ee', 'um']\n",
      "['S', 'ER1', 'V', 'EY2'] survey\n",
      "['s', 'er', 'v', 'ay']\n",
      "['P', 'UH1', 'T'] put\n",
      "['p', 'u', 't']\n",
      "['T', 'R', 'UW1', 'TH'] truth\n",
      "['t', 'r', 'oo', 'th-']\n",
      "['L', 'IH1', 'K', 'W', 'AH0', 'D'] liquid\n",
      "['l', 'ih', 'k', 'w', 'uh-', 'd']\n",
      "['B', 'EH1', 'R', 'IY0'] bury\n",
      "['b', 'eh', 'r', 'ee']\n",
      "['B', 'IH1', 'Z', 'IY0'] busy\n",
      "['b', 'ih', 'z', 'ee']\n",
      "['Y', 'UW1', 'S'] use\n",
      "['y', 'oo', 's']\n",
      "['R', 'UW1', 'D'] rude\n",
      "['r', 'oo', 'd']\n",
      "['M', 'EH1', 'ZH', 'ER0'] measure\n",
      "['m', 'eh', 'zh', 'er']\n",
      "['B', 'AH1', 'JH'] budge\n",
      "['b', 'uh+', 'dj']\n",
      "['SH', 'UH1', 'R'] sure\n",
      "['sh', 'u', 'r']\n",
      "['F', 'EH1', 'R', 'AH0', 'L'] ferrule\n",
      "['f', 'eh', 'r', 'ul']\n",
      "['M', 'IH1', 'N', 'AH0', 'T'] minute\n",
      "['m', 'ih', 'n', 'uh-', 't']\n",
      "['K', 'Y', 'UW1'] cue\n",
      "['k', 'y', 'oo']\n",
      "['B', 'L', 'UW1'] blue\n",
      "['b', 'l', 'oo']\n",
      "['B', 'IH1', 'L', 'D'] build\n",
      "['b', 'ih', 'l', 'd']\n",
      "['S', 'UW1', 'T'] suit\n",
      "['s', 'oo', 't']\n",
      "['F', 'R', 'UW1', 'T'] fruit\n",
      "['f', 'r', 'oo', 't']\n",
      "['JH', 'UW1', 'S'] juice\n",
      "['dj', 'oo', 's']\n",
      "['B', 'OY1', 'AH0', 'N', 'T'] buoyant\n",
      "['b', 'oy', 'un', 't']\n",
      "['B', 'AY1'] buy\n",
      "['b', 'ai']\n",
      "['S', 'T', 'AO1', 'R', 'IY0'] story\n",
      "['s', 't', 'aw', 'r', 'ee']\n",
      "['T', 'AY1', 'P', 'IH0', 'S', 'T'] typist\n",
      "['t', 'ai', 'p', 'ih', 's', 't']\n",
      "['M', 'IH1', 'TH'] myth\n",
      "['m', 'ih', 'th-']\n",
      "['Y', 'EH1', 'S'] yes\n",
      "['y', 'eh', 's']\n",
      "['EH1', 'TH', 'AH0', 'L'] ethyl\n",
      "['eh', 'th-', 'ul']\n",
      "['S', 'AE1', 'T', 'ER0'] satyr\n",
      "['s', 'ae', 't', 'er']\n",
      "['T', 'AY1', 'P'] type\n",
      "['t', 'ai', 'p']\n",
      "['AH0', 'P', 'AA1', 'K', 'AH0', 'L', 'IH2', 'P', 'S'] apocalypse\n",
      "['uh-', 'p', ['ah', 'aw'], 'k', 'ul', 'ih', 'p', 's']\n",
      "['M', 'EH1', 'D', 'AH0', 'L'] medal\n",
      "['m', 'eh', 'd', 'ul']\n",
      "['B', 'AE1', 'D'] bad\n",
      "['b', 'ae', 'd']\n",
      "['EH1', 'B'] ebb \n",
      "['eh', 'b']\n",
      "['D', 'EH1', 'T'] debt\n",
      "['d', 'eh', 't']\n",
      "['K', 'AE1', 'B'] cab\n",
      "['k', 'ae', 'b']\n",
      "['S', 'EH1', 'N', 'T'] cent\n",
      "['s', 'eh', 'n', 't']\n",
      "['OW1', 'SH', 'AH0', 'N'] ocean \n",
      "['o', 'sh', 'un']\n",
      "['CH', 'EH1', 'L', 'OW0'] cello\n",
      "['tch', 'eh', 'l', 'o']\n",
      "['AA1', 'K', 'Y', 'AH0', 'P', 'AY2'] occupy\n",
      "[['ah', 'aw'], 'k', 'y', 'uh-', 'p', 'ai']\n",
      "['S', 'AE1', 'K', 'ER0', 'AH0', 'N'] saccharin\n",
      "['s', 'ae', 'k', 'er', 'un']\n",
      "['OW1', 'SH', 'AH0', 'N'] ocean\n",
      "['o', 'sh', 'un']\n",
      "['CH', 'AA1', 'R', 'T'] chart\n",
      "['tch', ['ah', 'aw'], 'r', 't']\n",
      "['K', 'AO1', 'R', 'AH0', 'S'] chorus\n",
      "['k', 'aw', 'r', 'uh-', 's']\n",
      "['SH', 'EH1', 'F'] chef\n",
      "['sh', 'eh', 'f']\n",
      "['Y', 'AA1', 'T'] yacht\n",
      "['y', ['ah', 'aw'], 't']\n",
      "['S', 'OW1', 'SH', 'AH0', 'L'] social\n",
      "['s', 'o', 'sh', 'ul']\n",
      "['K', 'R', 'AE1', 'K', 'T'] cracked\n",
      "['k', 'r', 'ae', 'k', 't']\n",
      "['AE2', 'K', 'W', 'IY0', 'EH1', 'S'] acquiesce\n",
      "['ae', 'k', 'w', 'ee', 'eh', 's']\n",
      "['AH0', 'K', 'W', 'EY1', 'N', 'T'] acquaint\n",
      "['uh-', 'k', 'w', 'ay', 'n', 't']\n",
      "['EH1', 'TH', 'IH0', 'K', 'S'] ethics\n",
      "['eh', 'th-', 'ih', 'k', 's']\n",
      "['IH0', 'N', 'D', 'AY1', 'T'] indict\n",
      "['ih', 'n', 'd', 'ai', 't']\n",
      "['Z', 'AA1', 'R'] czar\n",
      "['z', ['ah', 'aw'], 'r']\n",
      "['D', 'AE1', 'D'] dad\n",
      "['d', 'ae', 'd']\n",
      "['EH1', 'JH', 'AH0', 'K', 'EY2', 'T'] educate\n",
      "['eh', 'dj', 'uh-', 'k', 'ay', 't']\n",
      "['AE1', 'D'] add\n",
      "['ae', 'd']\n",
      "['B', 'AH1', 'JH', 'IH0', 'T'] budget\n",
      "['b', 'uh+', 'dj', 'ih', 't']\n",
      "['K', 'AO1', 'R', 'JH', 'AH0', 'L'] cordial\n",
      "['k', 'aw', 'r', 'dj', 'ul']\n",
      "['AH0', 'JH', 'AH1', 'S', 'T'] adjust\n",
      "['uh-', 'dj', 'uh+', 's', 't']\n",
      "['P', 'EY1', 'S', 'T'] paced\n",
      "['p', 'ay', 's', 't']\n",
      "['IY1', 'Z', 'AH0', 'L'] easel\n",
      "['ee', 'z', 'ul']\n",
      "['SH', 'AO1', 'R', 'T', 'AH0', 'N'] shorten\n",
      "['sh', 'aw', 'r', 't', 'un']\n",
      "['G', 'OW1', 'Z'] goes\n",
      "['g', 'o', 'z']\n",
      "['F', 'AA1', 'R', 'M'] farm\n",
      "['f', ['ah', 'aw'], 'r', 'm']\n",
      "['AH1', 'V'] of\n",
      "['uh+', 'v']\n",
      "['K', 'AH1', 'F'] cuff\n",
      "['k', 'uh+', 'f']\n",
      "['AO1', 'F', 'AH0', 'N'] often\n",
      "['aw', 'f', 'un']\n",
      "['G', 'AE1', 'P'] gap\n",
      "['g', 'ae', 'p']\n",
      "['JH', 'EH1', 'M'] gem\n",
      "['dj', 'eh', 'm']\n",
      "['R', 'AH0', 'ZH', 'IY1', 'M'] regime\n",
      "['r', 'uh-', 'zh', 'ee', 'm']\n",
      "['EH1', 'G'] egg\n",
      "['eh', 'g']\n",
      "['IH0', 'G', 'Z', 'AE1', 'JH', 'ER0', 'EY2', 'T'] exaggerate\n",
      "['ih', 'g', 'z', 'ae', 'dj', 'er', 'ay', 't']\n",
      "['G', 'OW1', 'S', 'T'] ghost\n",
      "['g', 'o', 's', 't']\n",
      "['R', 'AH1', 'F'] rough\n",
      "['r', 'uh+', 'f']\n",
      "['R', 'IY1', 'JH', 'AH0', 'N'] region\n",
      "['r', 'ee', 'dj', 'un']\n",
      "['F', 'L', 'EH1', 'G', 'M'] phlegm \n",
      "['f', 'l', 'eh', 'g', 'm']\n",
      "['N', 'AE1', 'T'] gnat \n",
      "['n', 'ae', 't']\n",
      "['R', 'OW1', 'G'] rogue \n",
      "['r', 'o', 'g']\n",
      "['HH', 'AA1', 'T'] hot\n",
      "['h', ['ah', 'aw'], 't']\n",
      "['IY1', 'V', 'AH0', 'L'] evil\n",
      "['ee', 'v', 'ul']\n",
      "['B', 'EY1', 'S', 'AH0', 'N'] basin\n",
      "['b', 'ay', 's', 'un']\n",
      "['JH', 'AE1', 'M'] jam\n",
      "['dj', 'ae', 'm']\n",
      "['K', 'IY1', 'P'] keep\n",
      "['k', 'ee', 'p']\n",
      "['K', 'AA1', 'K', 'IY0'] khaki\n",
      "['k', ['ah', 'aw'], 'k', 'ee']\n",
      "['N', 'IY1'] knee\n",
      "['n', 'ee']\n",
      "['L', 'AE1', 'D'] lad\n",
      "['l', 'ae', 'd']\n",
      "['K', 'UH1', 'D'] could\n",
      "['k', 'u', 'd']\n",
      "['EY1', 'B', 'AH0', 'L'] able\n",
      "['ay', 'b', 'ul']\n",
      "['K', 'AE1', 'F'] calf\n",
      "['k', 'ae', 'f']\n",
      "['T', 'AO1', 'K'] talk\n",
      "['t', 'aw', 'k']\n",
      "['AO1', 'L'] all\n",
      "['aw', 'l']\n",
      "['K', 'AA1', 'M'] calm\n",
      "['k', ['ah', 'aw'], 'm']\n",
      "['K', 'AE1', 'V', 'Z'] calves\n",
      "['k', 'ae', 'v', 'z']\n",
      "['M', 'AE1', 'N'] man\n",
      "['m', 'ae', 'n']\n",
      "['K', 'AE1', 'Z', 'AH0', 'M'] chasm\n",
      "['k', 'ae', 'z', 'um']\n",
      "['L', 'AE1', 'M'] lamb\n",
      "['l', 'ae', 'm']\n",
      "['M', 'AH1', 'M', 'IY0'] mummy\n",
      "['m', 'uh+', 'm', 'ee']\n",
      "['HH', 'IH1', 'M'] hymn\n",
      "['h', 'ih', 'm']\n",
      "['N', 'IH0', 'M', 'AA1', 'N', 'IH0', 'K', 'S'] mnemonics\n",
      "['n', 'ih', 'm', ['ah', 'aw'], 'n', 'ih', 'k', 's']\n",
      "['N', 'AE1', 'P'] nap\n",
      "['n', 'ae', 'p']\n",
      "['B', 'AE1', 'NG', 'K'] bank\n",
      "['b', 'ae', 'ng', 'k']\n",
      "['L', 'EH1', 'NG', 'K', 'TH'] length \n",
      "['l', 'eh', 'ng', 'k', 'th-']\n",
      "['T', 'AH1', 'NG'] tongue\n",
      "['t', 'uh+', 'ng']\n",
      "['IH1', 'N'] inn\n",
      "['ih', 'n']\n",
      "['P', 'IH1', 'S', 'T', 'AH0', 'L'] pistol\n",
      "['p', 'ih', 's', 't', 'ul']\n",
      "['P', 'AA1', 'R', 'D', 'AH0', 'N'] pardon\n",
      "['p', ['ah', 'aw'], 'r', 'd', 'un']\n",
      "['P', 'AE1', 'D'] pad\n",
      "['p', 'ae', 'd']\n",
      "['R', 'AE1', 'Z', 'B', 'EH2', 'R', 'IY0'] raspberry\n",
      "['r', 'ae', 'z', 'b', 'eh', 'r', 'ee']\n",
      "['G', 'R', 'AE1', 'F'] graph\n",
      "['g', 'r', 'ae', 'f']\n",
      "['N', 'UW0', 'M', 'OW1', 'N', 'Y', 'AH0'] pneumonia\n",
      "['n', 'oo', 'm', 'o', 'n', 'y']\n",
      "['AE1', 'P', 'AH0', 'L'] apple\n",
      "['ae', 'p', 'ul']\n",
      "['S', 'AA1', 'L', 'M'] psalm \n",
      "['s', ['ah', 'aw'], 'l', 'm']\n",
      "['R', 'IH0', 'S', 'IY1', 'T'] receipt\n",
      "['r', 'ih', 's', 'ee', 't']\n",
      "['L', 'IH1', 'K', 'W', 'AH0', 'D'] liquid\n",
      "['l', 'ih', 'k', 'w', 'uh-', 'd']\n",
      "['K', 'W', 'IH1', 'L', 'T'] quilt\n",
      "['k', 'w', 'ih', 'l', 't']\n",
      "['B', 'UW0', 'K', 'EY1'] bouquet \n",
      "['b', 'oo', 'k', 'ay']\n",
      "['R', 'AE1', 'P'] rap\n",
      "['r', 'ae', 'p']\n",
      "['R', 'AY1', 'M'] rhyme \n",
      "['r', 'ai', 'm']\n",
      "['P', 'ER1'] purr \n",
      "['p', 'er']\n",
      "['S', 'IH1', 'T'] sit\n",
      "['s', 'ih', 't']\n",
      "['D', 'IH0', 'Z', 'AY1', 'N'] design\n",
      "['d', 'ih', 'z', 'ai', 'n']\n",
      "['Y', 'UW1', 'ZH', 'AH0', 'W', 'AH0', 'L'] usual\n",
      "['y', 'oo', 'zh', 'uh-', 'w', 'ul']\n",
      "['SH', 'UH1', 'G', 'ER0'] sugar\n",
      "['sh', 'u', 'g', 'er']\n",
      "['S', 'IY1', 'N'] scene\n",
      "['s', 'ee', 'n']\n",
      "['K', 'R', 'IH0', 'SH', 'EH1', 'N', 'D', 'OW0'] crescendo\n",
      "['k', 'r', 'ih', 'sh', 'eh', 'n', 'd', 'o']\n",
      "['D', 'IH0', 'S', 'ER1', 'N'] discern\n",
      "['d', 'ih', 's', 'er', 'n']\n",
      "['V', 'IH1', 'S', 'K', 'AW0', 'N', 'T'] viscount\n",
      "['v', 'ih', 's', 'k', 'au', 'n', 't']\n",
      "['S', 'K', 'IH1', 'Z', 'AH0', 'M'] schism\n",
      "['s', 'k', 'ih', 'z', 'um']\n",
      "['SH', 'W', 'AA1'] schwa\n",
      "['sh', 'w', ['ah', 'aw']]\n",
      "['K', 'AA1', 'N', 'SH', 'AH0', 'S'] conscious\n",
      "['k', ['ah', 'aw'], 'n', 'sh', 'uh-', 's']\n",
      "['SH', 'IH1', 'P'] ship\n",
      "['sh', 'ih', 'p']\n",
      "['F', 'Y', 'UW1', 'ZH', 'AH0', 'N'] fusion\n",
      "['f', 'y', 'oo', 'zh', 'un']\n",
      "['P', 'EH1', 'N', 'SH', 'AH0', 'N'] pension\n",
      "['p', 'eh', 'n', 'sh', 'un']\n",
      "['AY1', 'L', 'AH0', 'N', 'D'] island\n",
      "['ai', 'l', 'un', 'd']\n",
      "['B', 'AA1', 'S'] boss\n",
      "['b', ['ah', 'aw'], 's']\n",
      "['D', 'IH0', 'Z', 'ER1', 'T'] dessert\n",
      "['d', 'ih', 'z', 'er', 't']\n",
      "['P', 'R', 'EH1', 'SH', 'ER0'] pressure\n",
      "['p', 'r', 'eh', 'sh', 'er']\n",
      "['M', 'IH1', 'SH', 'AH0', 'N'] mission\n",
      "['m', 'ih', 'sh', 'un']\n",
      "['L', 'IH1', 'S', 'AH0', 'N'] listen\n",
      "['l', 'ih', 's', 'un']\n",
      "['S', 'AO1', 'R', 'D'] sword\n",
      "['s', 'aw', 'r', 'd']\n",
      "['T', 'AE1', 'B'] tab\n",
      "['t', 'ae', 'b']\n",
      "['K', 'AH1', 'L', 'CH', 'ER0'] culture\n",
      "['k', 'uh+', 'l', 'tch', 'er']\n",
      "['IH2', 'N', 'IH1', 'SH', 'IY0', 'AH0', 'T'] initiate\n",
      "['ih', 'n', 'ih', 'sh', 'ee', 'uh-', 't']\n",
      "['W', 'AA1', 'CH'] watch\n",
      "['w', ['ah', 'aw'], 'tch']\n",
      "['M', 'AO1', 'R', 'G', 'AH0', 'JH'] mortgage\n",
      "['m', 'aw', 'r', 'g', 'uh-', 'dj']\n",
      "['TH', 'AO1'] thaw\n",
      "['th-', 'aw']\n",
      "['DH', 'AH0'] the\n",
      "['th+']\n",
      "['TH', 'AY1', 'M'] thyme\n",
      "['th-', 'ai', 'm']\n",
      "['AE1', 'K', 'SH', 'AH0', 'N'] action\n",
      "['ae', 'k', 'sh', 'un']\n",
      "['K', 'W', 'EH1', 'S', 'CH', 'AH0', 'N'] question\n",
      "['k', 'w', 'eh', 's', 'tch', 'un']\n",
      "['IH0', 'K', 'W', 'EY1', 'ZH', 'AH0', 'N'] equation\n",
      "['ih', 'k', 'w', 'ay', 'zh', 'un']\n",
      "['P', 'AH1', 'T'] putt\n",
      "['p', 'uh+', 't']\n",
      "['T', 'UW1'] two\n",
      "['t', 'oo']\n",
      "['V', 'AE1', 'T'] vat\n",
      "['v', 'ae', 't']\n",
      "['W', 'IY1'] we\n",
      "['w', 'ee']\n",
      "['W', 'AH1', 'T'] what\n",
      "['w', 'uh+', 't']\n",
      "['HH', 'UW1'] who\n",
      "['h', 'oo']\n",
      "['R', 'AE1', 'P'] wrap\n",
      "['r', 'ae', 'p']\n",
      "['AA1', 'K', 'S'] ox\n",
      "[['ah', 'aw'], 'k', 's']\n",
      "['IH0', 'G', 'Z', 'IH1', 'S', 'T'] exist\n",
      "['ih', 'g', 'z', 'ih', 's', 't']\n",
      "['Z', 'UW1'] zoo\n",
      "['z', 'oo']\n",
      "['W', 'AO1', 'L', 'T', 'S'] waltz\n",
      "['w', 'aw', 'l', 't', 's']\n",
      "['AE1', 'ZH', 'ER0'] azure\n",
      "['ae', 'zh', 'er']\n",
      "['B', 'AH1', 'Z'] buzz\n",
      "['b', 'uh+', 'z']\n",
      "['EH1', 'R'] heir\n",
      "['eh', 'r']\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(berndt_conditional_probs_words):\n",
    "    print(word,berndt_conditional_probs.Example.iloc[i])\n",
    "    print(get_keyboard_phonetic_symbols(word, berndt_arpabbet_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ae', 'p', 'ul']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keyboard_phonetic_symbols(get_ARPAbet_phonetic_transcription([\"apple\"])[0], berndt_arpabbet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grapheme</th>\n",
       "      <th>Prior_Probability</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>Conditional_Probability</th>\n",
       "      <th>Example</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>ae</td>\n",
       "      <td>0.542</td>\n",
       "      <td>cab</td>\n",
       "      <td>vowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>uh-</td>\n",
       "      <td>0.186</td>\n",
       "      <td>canal</td>\n",
       "      <td>vowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>ay</td>\n",
       "      <td>0.129</td>\n",
       "      <td>angel</td>\n",
       "      <td>vowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>ah</td>\n",
       "      <td>0.077</td>\n",
       "      <td>wad</td>\n",
       "      <td>vowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>aw</td>\n",
       "      <td>0.021</td>\n",
       "      <td>also</td>\n",
       "      <td>vowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>z</td>\n",
       "      <td>0.996</td>\n",
       "      <td>zoo</td>\n",
       "      <td>consonant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>s</td>\n",
       "      <td>0.025</td>\n",
       "      <td>waltz</td>\n",
       "      <td>consonant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>zh</td>\n",
       "      <td>0.008</td>\n",
       "      <td>azure</td>\n",
       "      <td>consonant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>ZZ</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>z</td>\n",
       "      <td>1.000</td>\n",
       "      <td>buzz</td>\n",
       "      <td>consonant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>$H</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>heir</td>\n",
       "      <td>consonant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Grapheme  Prior_Probability Phoneme  Conditional_Probability Example  \\\n",
       "0          A             0.0712      ae                    0.542     cab   \n",
       "1          A             0.0712     uh-                    0.186   canal   \n",
       "2          A             0.0712      ay                    0.129   angel   \n",
       "3          A             0.0712      ah                    0.077     wad   \n",
       "4          A             0.0712      aw                    0.021    also   \n",
       "..       ...                ...     ...                      ...     ...   \n",
       "340        Z             0.0021       z                    0.996     zoo   \n",
       "341        Z             0.0021       s                    0.025   waltz   \n",
       "342        Z             0.0021      zh                    0.008   azure   \n",
       "343       ZZ             0.0002       z                    1.000    buzz   \n",
       "344       $H             0.0003     NaN                    1.000    heir   \n",
       "\n",
       "    Unnamed: 5  \n",
       "0        vowel  \n",
       "1        vowel  \n",
       "2        vowel  \n",
       "3        vowel  \n",
       "4        vowel  \n",
       "..         ...  \n",
       "340  consonant  \n",
       "341  consonant  \n",
       "342  consonant  \n",
       "343  consonant  \n",
       "344  consonant  \n",
       "\n",
       "[345 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_conditional_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_computer_phonem_graph_prob_dict = {}\n",
    "for phoneme in berndt_conditional_probs.Phoneme.unique():\n",
    "    berndt_computer_phonem_graph_prob_dict[phoneme] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in berndt_conditional_probs.iterrows():\n",
    "    grapheme_prior_cond = (row[\"Grapheme\"], row['Prior_Probability'], row[\"Conditional_Probability\"])\n",
    "    berndt_computer_phonem_graph_prob_dict[row[\"Phoneme\"]].append(grapheme_prior_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ae': [('A', 0.0712, 0.542), ('A-E', 0.0111, 0.121), ('Al', 0.0026, 0.003)],\n",
       " 'uh-': [('A', 0.0712, 0.18600000000000003),\n",
       "  ('A-E', 0.0111, 0.002),\n",
       "  ('Al', 0.0026, 0.031),\n",
       "  ('AU', 0.0014, 0.006),\n",
       "  ('E', 0.073, 0.096),\n",
       "  ('E-E', 0.0032, 0.28600000000000003),\n",
       "  ('EA', 0.0047, 0.005),\n",
       "  ('El', 0.0005, 0.035),\n",
       "  ('EO', 0.0001, 0.6659999999999999),\n",
       "  ('EOU', 7e-05, 1.0),\n",
       "  ('EY-E', 0.0688, 0.18),\n",
       "  ('I-E', 0.0086, 6.0),\n",
       "  ('IA', 1e-05, 1.0),\n",
       "  ('IE', 0.0011, 0.171),\n",
       "  ('IE-E', 0.0002, 0.129),\n",
       "  ('O', 0.055, 0.26899999999999996),\n",
       "  ('O-E', 0.0043, 0.044000000000000004),\n",
       "  ('OI-E', 9e-05, 0.2),\n",
       "  ('OU', 0.0064, 0.48),\n",
       "  ('U', 0.0267, 0.102),\n",
       "  ('U-E', 0.0033, 0.01),\n",
       "  ('Y', 0.0193, 0.01)],\n",
       " 'ay': [('A', 0.0712, 0.129),\n",
       "  ('A-E', 0.0111, 0.6509999999999999),\n",
       "  ('Al', 0.0026, 0.7340000000000001),\n",
       "  ('Al-E', 0.0002, 0.818),\n",
       "  ('AIGH', 2.9999999999999997e-05, 1.0),\n",
       "  ('AU-E', 0.0001, 0.083),\n",
       "  ('AY', 0.0012, 0.97),\n",
       "  ('AY-E', 9e-06, 1.0),\n",
       "  ('E', 0.073, 0.002),\n",
       "  ('E-E', 0.0032, 0.017),\n",
       "  ('EA', 0.0047, 0.027000000000000003),\n",
       "  ('El', 0.0005, 0.245),\n",
       "  ('El-E', 7e-05, 0.25),\n",
       "  ('EIGH', 0.0001, 0.857),\n",
       "  ('ET', 8e-05, 1.0),\n",
       "  ('EY', 0.0005, 0.225)],\n",
       " 'ah': [('A', 0.0712, 0.077),\n",
       "  ('A-E', 0.0111, 0.025),\n",
       "  ('AH', 2.9999999999999997e-05, 1.0),\n",
       "  ('AU', 0.0014, 0.025),\n",
       "  ('E', 0.073, 0.0006),\n",
       "  ('EA', 0.0047, 0.035),\n",
       "  ('O', 0.055, 0.261),\n",
       "  ('O-E', 0.0043, 0.042),\n",
       "  ('OW', 0.0022, 0.016)],\n",
       " 'aw': [('A', 0.0712, 0.021),\n",
       "  ('A-E', 0.0111, 0.002),\n",
       "  ('AO', 1e-05, 1.0),\n",
       "  ('AU', 0.0014, 0.948),\n",
       "  ('AU-E', 0.0001, 0.75),\n",
       "  ('AUGH', 0.0001, 1.0),\n",
       "  ('AW', 0.0006, 1.0),\n",
       "  ('AW-E', 1e-05, 1.0),\n",
       "  ('O', 0.055, 0.07200000000000001),\n",
       "  ('O-E', 0.0043, 0.044000000000000004),\n",
       "  ('OA', 0.0012, 0.066),\n",
       "  ('OUGH', 0.0002, 0.517),\n",
       "  ('OW', 0.0022, 0.48100000000000004)],\n",
       " 'er': [('A', 0.0712, 0.021),\n",
       "  ('E', 0.073, 0.249),\n",
       "  ('E-E', 0.0032, 0.11900000000000001),\n",
       "  ('EA', 0.0047, 0.055999999999999994),\n",
       "  ('EA-E', 0.0003, 0.057999999999999996),\n",
       "  ('EU', 0.0003, 0.153),\n",
       "  ('EY-E', 0.0688, 0.015),\n",
       "  ('I-E', 0.0086, 1.0),\n",
       "  ('O', 0.055, 0.053),\n",
       "  ('O-E', 0.0043, 0.002),\n",
       "  ('OU', 0.0064, 0.031),\n",
       "  ('OU-E', 0.0006, 0.013999999999999999),\n",
       "  ('U', 0.0267, 0.08),\n",
       "  ('U-E', 0.0033, 0.09),\n",
       "  ('Y', 0.0193, 0.002)],\n",
       " 'eh': [('A', 0.0712, 0.02),\n",
       "  ('A-E', 0.0111, 0.042),\n",
       "  ('AE', 5e-05, 0.166),\n",
       "  ('Al', 0.0026, 0.17600000000000002),\n",
       "  ('Al-E', 0.0002, 0.136),\n",
       "  ('AY', 0.0012, 0.006999999999999999),\n",
       "  ('E', 0.073, 0.419),\n",
       "  ('E-E', 0.0032, 0.321),\n",
       "  ('EA', 0.0047, 0.298),\n",
       "  ('EA-E', 0.0003, 0.028999999999999998),\n",
       "  ('El', 0.0005, 0.105),\n",
       "  ('EO', 0.0001, 0.2),\n",
       "  ('EY', 0.0005, 0.016),\n",
       "  ('IE', 0.0011, 0.031),\n",
       "  ('U', 0.0267, 0.0006)],\n",
       " 'ih': [('A', 0.0712, 0.0005),\n",
       "  ('A-E', 0.0111, 0.154),\n",
       "  ('Al', 0.0026, 0.053),\n",
       "  ('E', 0.073, 0.0006),\n",
       "  ('E-E', 0.0032, 0.002),\n",
       "  ('EA-E', 0.0003, 0.028999999999999998),\n",
       "  ('EE', 0.0026, 0.02),\n",
       "  ('El', 0.0005, 0.192),\n",
       "  ('EY-E', 0.0688, 0.716),\n",
       "  ('I-E', 0.0086, 0.35600000000000004),\n",
       "  ('IA-E', 2e-05, 1.0),\n",
       "  ('IE', 0.0011, 0.10099999999999999),\n",
       "  ('IE-E', 0.0002, 0.032),\n",
       "  ('O', 0.055, 0.0001),\n",
       "  ('U', 0.0267, 0.001),\n",
       "  ('U-E', 0.0033, 0.008),\n",
       "  ('UI', 0.0002, 0.5329999999999999),\n",
       "  ('Y', 0.0193, 0.073),\n",
       "  ('Y-E', 0.0002, 0.040999999999999995)],\n",
       " 'ee': [('AE', 5e-05, 0.833),\n",
       "  ('E', 0.073, 0.23),\n",
       "  ('E-E', 0.0032, 0.252),\n",
       "  ('EA', 0.0047, 0.5760000000000001),\n",
       "  ('EA-E', 0.0003, 0.882),\n",
       "  ('EE', 0.0026, 0.9790000000000001),\n",
       "  ('EE-E', 8e-05, 1.0),\n",
       "  ('El', 0.0005, 0.315),\n",
       "  ('El-E', 7e-05, 0.75),\n",
       "  ('EO', 0.0001, 0.133),\n",
       "  ('EY', 0.0005, 0.741),\n",
       "  ('EY-E', 0.0688, 0.005),\n",
       "  ('I-E', 0.0086, 46.0),\n",
       "  ('IE', 0.0011, 0.49200000000000005),\n",
       "  ('IE-E', 0.0002, 0.838),\n",
       "  ('OE', 0.0002, 0.22699999999999998),\n",
       "  ('Y', 0.0193, 0.7859999999999999)],\n",
       " 'ai': [('Al-E', 0.0002, 0.045),\n",
       "  ('AY', 0.0012, 0.022000000000000002),\n",
       "  ('El', 0.0005, 0.105),\n",
       "  ('EIGH', 0.0001, 0.142),\n",
       "  ('EY', 0.0005, 0.016),\n",
       "  ('EY-E', 5.9999999999999995e-05, 1.0),\n",
       "  ('EY-E', 0.0688, 0.07400000000000001),\n",
       "  ('I-E', 0.0086, 0.589),\n",
       "  ('IE', 0.0011, 0.203),\n",
       "  ('IGH', 0.0008, 1.0),\n",
       "  ('OY', 0.0004, 0.02),\n",
       "  ('UY', 2e-05, 1.0),\n",
       "  ('Y', 0.0193, 0.1),\n",
       "  ('Y-E', 0.0002, 0.958)],\n",
       " 'o': [('AU', 0.0014, 0.019),\n",
       "  ('AU-E', 0.0001, 0.166),\n",
       "  ('EAU', 0.0001, 0.545),\n",
       "  ('EW', 0.0005, 0.047),\n",
       "  ('O', 0.055, 0.314),\n",
       "  ('O-E', 0.0043, 0.785),\n",
       "  ('OA', 0.0012, 0.9329999999999999),\n",
       "  ('OA-E', 2e-05, 1.0),\n",
       "  ('OE', 0.0002, 0.59),\n",
       "  ('OH', 2.9999999999999997e-05, 1.0),\n",
       "  ('OO', 0.0027, 0.028999999999999998),\n",
       "  ('OU', 0.0064, 0.040999999999999995),\n",
       "  ('OU-E', 0.0006, 0.147),\n",
       "  ('OUGH', 0.0002, 0.275),\n",
       "  ('OW', 0.0022, 0.502),\n",
       "  ('OW-E', 2e-05, 0.33299999999999996)],\n",
       " 'y': [('E', 0.073, 0.0001), ('EY-E', 0.0688, 0.008), ('Y', 0.0193, 0.025)],\n",
       " 'yu': [('EAU', 0.0001, 0.45399999999999996),\n",
       "  ('EU', 0.0003, 0.7170000000000001),\n",
       "  ('EU-E', 9e-06, 1.0),\n",
       "  ('EW', 0.0005, 0.603),\n",
       "  ('EW-E', 9e-06, 1.0),\n",
       "  ('IEU', 2.9999999999999997e-05, 1.0),\n",
       "  ('IEW', 5e-05, 1.0),\n",
       "  ('U', 0.0267, 0.28),\n",
       "  ('U-E', 0.0033, 0.703),\n",
       "  ('UE', 0.0003, 0.627),\n",
       "  ('UI', 0.0002, 0.266)],\n",
       " 'oo': [('EU', 0.0003, 0.102),\n",
       "  ('EW', 0.0005, 0.349),\n",
       "  ('O', 0.055, 0.006),\n",
       "  ('OO-E', 0.0001, 1.0),\n",
       "  ('O-E', 0.0043, 0.025),\n",
       "  ('OE', 0.0002, 0.18100000000000002),\n",
       "  ('OO', 0.0027, 0.57),\n",
       "  ('OU', 0.0064, 0.040999999999999995),\n",
       "  ('OU-E', 0.0006, 0.044000000000000004),\n",
       "  ('OUGH', 0.0002, 0.068),\n",
       "  ('U', 0.0267, 0.032),\n",
       "  ('U-E', 0.0033, 0.09300000000000001),\n",
       "  ('UE', 0.0003, 0.37200000000000005),\n",
       "  ('UI', 0.0002, 0.2),\n",
       "  ('Ul-E', 2.9999999999999997e-05, 1.0),\n",
       "  ('UO', 1e-05, 1.0)],\n",
       " 'u': [('EU', 0.0003, 0.025),\n",
       "  ('O', 0.055, 0.002),\n",
       "  ('OO', 0.0027, 0.376),\n",
       "  ('OU', 0.0064, 0.035),\n",
       "  ('U', 0.0267, 0.068),\n",
       "  ('U-E', 0.0033, 0.03)],\n",
       " 'uh+': [('O', 0.055, 0.018000000000000002),\n",
       "  ('O-E', 0.0043, 0.055),\n",
       "  ('OO', 0.0027, 0.023),\n",
       "  ('OU', 0.0064, 0.042),\n",
       "  ('U', 0.0267, 0.41700000000000004),\n",
       "  ('U-E', 0.0033, 0.063)],\n",
       " 'oy': [('OI', 0.0008, 1.0),\n",
       "  ('OI-E', 9e-05, 0.8),\n",
       "  ('OY', 0.0004, 0.972),\n",
       "  ('OY-E', 9e-06, 1.0)],\n",
       " 'au': [('OU', 0.0064, 0.324),\n",
       "  ('OU-E', 0.0006, 0.794),\n",
       "  ('OUGH', 0.0002, 0.13699999999999998),\n",
       "  ('OW-E', 2e-05, 0.6659999999999999)],\n",
       " 'w': [('OU', 0.0064, 0.001),\n",
       "  ('U', 0.0267, 0.016),\n",
       "  ('W', 0.0053, 1.0),\n",
       "  ('WH', 0.0009, 0.847)],\n",
       " 'ul': [('AL', 2.9999999999999997e-05, 1.0),\n",
       "  ('EL', 0.0001, 1.0),\n",
       "  ('IL', 5.9999999999999995e-05, 1.0),\n",
       "  ('LE', 0.0057, 1.0),\n",
       "  ('OL', 9e-06, 1.0)],\n",
       " 'b': [('B', 0.0206, 1.0), ('BB', 0.0005, 1.0), ('PB', 9e-06, 1.0)],\n",
       " 't': [('BT', 0.0001, 1.0),\n",
       "  ('CHT', 1e-05, 1.0),\n",
       "  ('CT', 1e-05, 1.0),\n",
       "  ('ED', 0.0002, 1.0),\n",
       "  ('PT', 1e-05, 1.0),\n",
       "  ('T', 0.0713, 0.973),\n",
       "  ('TH', 0.0051, 0.001),\n",
       "  ('TT', 0.0019, 1.0),\n",
       "  ('TW', 2e-05, 1.0)],\n",
       " 'k': [('C', 0.042, 0.757),\n",
       "  ('CCH', 0.0007, 1.0),\n",
       "  ('CCH', 9e-06, 1.0),\n",
       "  ('CH', 0.0045, 0.29),\n",
       "  ('CK', 0.0026, 1.0),\n",
       "  ('CQ', 2e-05, 1.0),\n",
       "  ('K', 0.0055, 1.0),\n",
       "  ('KH', 2e-05, 1.0),\n",
       "  ('Lk', 0.0001, 1.0),\n",
       "  ('Q', 0.0001, 1.0),\n",
       "  ('QU', 0.002, 0.12300000000000001),\n",
       "  ('SC', 0.0008, 0.033)],\n",
       " 's': [('C', 0.042, 0.23399999999999999),\n",
       "  ('PS', 0.0001, 1.0),\n",
       "  ('S', 0.0488, 0.868),\n",
       "  ('SC', 0.0008, 0.865),\n",
       "  ('SCH', 2.9999999999999997e-05, 0.5),\n",
       "  ('SS', 0.0042, 0.9520000000000001),\n",
       "  ('ST', 0.0003, 1.0),\n",
       "  ('SW', 2.9999999999999997e-05, 1.0),\n",
       "  ('Z', 0.0021, 0.025)],\n",
       " 'sh': [('C', 0.042, 0.008),\n",
       "  ('CE', 1e-05, 1.0),\n",
       "  ('CH', 0.0045, 0.069),\n",
       "  ('Cl', 0.0007, 1.0),\n",
       "  ('S', 0.0488, 0.003),\n",
       "  ('SC', 0.0008, 0.067),\n",
       "  ('SCH', 2.9999999999999997e-05, 0.5),\n",
       "  ('SCI', 4e-05, 1.0),\n",
       "  ('SH', 0.0036, 1.0),\n",
       "  ('Sl', 0.0008, 0.431),\n",
       "  ('SS', 0.0042, 0.019),\n",
       "  ('SSI', 0.0004, 1.0),\n",
       "  ('T', 0.0713, 0.003),\n",
       "  ('Tl', 0.0076, 0.983)],\n",
       " 'tch': [('C', 0.042, 0.0004),\n",
       "  ('CH', 0.0045, 0.64),\n",
       "  ('T', 0.0713, 0.022000000000000002),\n",
       "  ('TCH', 0.0005, 1.0),\n",
       "  ('Tl', 0.0076, 0.015)],\n",
       " 'kw': [('CQU', 4e-05, 1.0), ('QU', 0.002, 0.8759999999999999)],\n",
       " 'ks': [('CS', 0.0002, 1.0), ('X', 0.0033, 0.885)],\n",
       " 'z': [('CZ', 9e-06, 1.0),\n",
       "  ('ES', 0.0004, 1.0),\n",
       "  ('S', 0.0488, 0.12),\n",
       "  ('SC', 0.0008, 0.033),\n",
       "  ('SS', 0.0042, 0.027999999999999997),\n",
       "  ('Z', 0.0021, 0.996),\n",
       "  ('ZZ', 0.0002, 1.0)],\n",
       " 'd': [('D', 0.0336, 0.991), ('DD', 0.0006, 1.0), ('LD', 5e-05, 1.0)],\n",
       " 'dj': [('D', 0.0336, 0.008),\n",
       "  ('DG', 0.0004, 1.0),\n",
       "  ('DI', 1e-05, 1.0),\n",
       "  ('DJ', 0.0001, 1.0),\n",
       "  ('G', 0.0169, 0.35100000000000003),\n",
       "  ('GG', 0.0006, 0.027999999999999997),\n",
       "  ('Gl', 0.0001, 1.0),\n",
       "  ('J', 0.002, 1.0)],\n",
       " 'un': [('EN', 0.0007, 1.0), ('IN', 0.0003, 1.0), ('ON', 2e-05, 1.0)],\n",
       " 'f': [('F', 0.0146, 0.998),\n",
       "  ('FF', 0.0016, 1.0),\n",
       "  ('FT', 2e-05, 1.0),\n",
       "  ('GH', 0.0001, 0.444),\n",
       "  ('LF', 8e-05, 1.0),\n",
       "  ('PH', 0.0022, 1.0)],\n",
       " 'v': [('F', 0.0146, 0.001),\n",
       "  ('LV', 2.9999999999999997e-05, 1.0),\n",
       "  ('V', 0.0136, 1.0)],\n",
       " 'g': [('G', 0.0169, 0.64),\n",
       "  ('GG', 0.0006, 0.971),\n",
       "  ('GH', 0.0001, 0.555),\n",
       "  ('GUE', 0.0001, 1.0),\n",
       "  ('TG', 9e-06, 1.0)],\n",
       " 'zh': [('G', 0.0169, 0.008),\n",
       "  ('S', 0.0488, 0.006),\n",
       "  ('Sl', 0.0008, 0.568),\n",
       "  ('Tl', 0.0076, 0.001),\n",
       "  ('Z', 0.0021, 0.008)],\n",
       " 'm': [('GM', 7e-05, 1.0),\n",
       "  ('LM', 0.0001, 1.0),\n",
       "  ('M', 0.0313, 0.971),\n",
       "  ('MB', 0.0002, 1.0),\n",
       "  ('MM', 0.0012, 1.0),\n",
       "  ('MN', 7e-05, 0.875)],\n",
       " 'n': [('GN', 0.0002, 1.0),\n",
       "  ('KN', 0.0003, 1.0),\n",
       "  ('MN', 7e-05, 0.125),\n",
       "  ('N', 0.071, 0.9670000000000001),\n",
       "  ('NN', 0.0011, 1.0),\n",
       "  ('PN', 2e-05, 1.0)],\n",
       " 'h': [('H', 0.007, 1.0), ('WH', 0.0009, 0.152)],\n",
       " 'l': [('L', 0.0451, 1.0), ('LL', 0.0045, 1.0), ('SL', 4e-05, 1.0)],\n",
       " 'um': [('M', 0.0313, 0.027999999999999997)],\n",
       " 'ng': [('N', 0.071, 0.032), ('NG', 0.0033, 1.0), ('NGUE', 1e-05, 1.0)],\n",
       " 'p': [('P', 0.0304, 1.0), ('PP', 0.0014, 1.0)],\n",
       " 'r': [('R', 0.0841, 1.0),\n",
       "  ('RH', 0.0001, 1.0),\n",
       "  ('RR', 0.0019, 1.0),\n",
       "  ('WR', 0.0004, 1.0)],\n",
       " 'th-': [('TH', 0.0051, 0.732)],\n",
       " 'th+': [('TH', 0.0051, 0.265)],\n",
       " 'gz': [('X', 0.0033, 0.114)],\n",
       " nan: [('$H', 0.0003, 1.0)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_computer_phonem_graph_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'AE1', 'B'] cab\n",
      "['k', 'ae', 'b']\n",
      "['K', 'AH0', 'N', 'AE1', 'L'] canal\n",
      "['k', 'uh-', 'n', 'ae', 'l']\n",
      "['EY1', 'N', 'JH', 'AH0', 'L'] angel\n",
      "['ay', 'n', 'dj', 'uh-', 'l']\n",
      "['W', 'AA1', 'D'] wad\n",
      "['w', 'aw', 'd']\n",
      "['AO1', 'L', 'S', 'OW0'] also\n",
      "['aw', 'l', 's', 'o']\n",
      "['K', 'AW1', 'ER0', 'D'] coward\n",
      "['k', 'au', 'er', 'd']\n",
      "['M', 'EH1', 'N', 'IY0'] many\n",
      "['m', 'eh', 'n', 'ee']\n",
      "['S', 'P', 'IH1', 'N', 'AH0', 'CH'] spinach\n",
      "['s', 'p', 'ih', 'n', 'uh-', 'tch']\n",
      "['EY1', 'T'] ate\n",
      "['ay', 't']\n",
      "['S', 'EH1', 'N', 'AH0', 'T'] senate\n",
      "['s', 'eh', 'n', 'uh-', 't']\n"
     ]
    }
   ],
   "source": [
    "test_words = []\n",
    "for i,word in enumerate(berndt_conditional_probs_words[0:10]):\n",
    "    print(word,berndt_conditional_probs.Example.iloc[i])\n",
    "    print(get_keyboard_phonetic_symbols(word, berndt_arpabbet_dict))\n",
    "    test_words.append((berndt_conditional_probs.Example.iloc[i],get_keyboard_phonetic_symbols(word, berndt_arpabbet_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft ['s', 'ah', 'f', 't']\n",
      "[['S']]\n",
      "['OFT']\n",
      "[['S', 'O']]\n",
      "['FT']\n",
      "[['S', 'O', 'F'], ['S', 'O', 'FT']]\n",
      "['T', '']\n",
      "[['S', 'O', 'F', 'T']]\n",
      "['']\n",
      "[['S', 'O', 'F', 'T']]\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "test_words = [(\"soft\", get_keyboard_phonetic_symbols(get_ARPAbet_phonetic_transcription([\"soft\"])[0], berndt_arpabbet_dict))]\n",
    "\n",
    "possible_grapheme_strings = [] # list for each word\n",
    "possible_prior_probs = [] # list for each word\n",
    "possible_cond_probs = [] # list for each word\n",
    "word_rests = [] # list for each word\n",
    "\n",
    "\n",
    "\n",
    "for i,word_pron in enumerate(test_words):\n",
    "    word = word_pron[0]\n",
    "    pron = word_pron[1]\n",
    "    print(word,pron)\n",
    "    possible_grapheme_strings_i = [[]]\n",
    "    possible_prior_probs_i = [[]]\n",
    "    possible_cond_probs_i = [[]]\n",
    "    word_rests_i = [word.upper()]\n",
    "    \n",
    "    for j,p in enumerate(pron):  \n",
    "        new_word_rests_i = []\n",
    "        new_possible_grapheme_strings_i = []\n",
    "        for possible_grapheme in berndt_computer_phonem_graph_prob_dict[p]:\n",
    "            grapheme = possible_grapheme[0].split(\"-\")\n",
    "            prior = possible_grapheme[1]\n",
    "            cond = possible_grapheme[2]\n",
    "            \n",
    "            for k,word_rest in enumerate(word_rests_i): \n",
    "                if len(grapheme)>1:\n",
    "                    if word_rest.startswith(grapheme[0]) and word_rest.endswith(grapheme[1]):\n",
    "                        new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]])\n",
    "                        new_word_rests_i.append(word_rest[len(grapheme[0]):-1])\n",
    "                            \n",
    "                else:\n",
    "                    if word_rest.startswith(grapheme[0]):\n",
    "                        new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]])\n",
    "                        new_word_rests_i.append(word_rest[len(grapheme[0]):])\n",
    "                \n",
    "        print(new_possible_grapheme_strings_i)\n",
    "        print(new_word_rests_i)\n",
    "        word_rests_i = new_word_rests_i\n",
    "        possible_grapheme_strings_i = new_possible_grapheme_strings_i\n",
    "    print(possible_grapheme_strings_i)\n",
    "    print(word_rests_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0.0712, 0.18600000000000003), ('A-E', 0.0111, 0.002), ('Al', 0.0026, 0.031), ('AU', 0.0014, 0.006), ('E', 0.073, 0.096), ('E-E', 0.0032, 0.28600000000000003), ('EA', 0.0047, 0.005), ('El', 0.0005, 0.035), ('EO', 0.0001, 0.6659999999999999), ('EOU', 7e-05, 1.0), ('EY-E', 0.0688, 0.18), ('I-E', 0.0086, 6.0), ('IA', 1e-05, 1.0), ('IE', 0.0011, 0.171), ('IE-E', 0.0002, 0.129), ('O', 0.055, 0.26899999999999996), ('O-E', 0.0043, 0.044000000000000004), ('OI-E', 9e-05, 0.2), ('OU', 0.0064, 0.48), ('U', 0.0267, 0.102), ('U-E', 0.0033, 0.01), ('Y', 0.0193, 0.01)]\n"
     ]
    }
   ],
   "source": [
    "print(berndt_computer_phonem_graph_prob_dict['uh-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EY1', 'B', 'AH0', 'L']]\n",
      "[['P', 'AH1', 'D', 'AH0', 'L']]\n",
      "[['K', 'AE1', 'Z', 'AH0', 'M']]\n",
      "[['P', 'AA1', 'R', 'D', 'AH0', 'N']]\n",
      "[['S', 'AA1', 'F', 'T']]\n",
      "[['K', 'AA1', 'T']]\n",
      "[['AO1', 'F']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"able\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"puddle\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"chasm\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"pardon\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"soft\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cot\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"off\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
