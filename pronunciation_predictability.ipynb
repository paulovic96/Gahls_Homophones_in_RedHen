{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from g2p_en import G2p # https://github.com/Kyubyong/g2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_dict_file = \"Data/epw.cd\"\n",
    "filename = \"Data/2016_all_words_no_audio.pickle\"\n",
    "hom_filename = \"Data/hom.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dataframe from Data/2016_all_words_no_audio.pickle\n",
      "Preprocessing: extract pause information...\n",
      "Remove pauses from data!\n",
      "Preprocessing: apply word preprocessing...\n",
      "Preprocessing: calculate word duration...\n",
      "Preprocessing: calculate word frequency...\n",
      "Preprocessing: extract context information...\n",
      "Preprocessing: calculate letter length...\n",
      "Preprocessing: calculate contextual predictability...\n",
      "(18864660, 25) RangeIndex(start=0, stop=18864660, step=1)\n"
     ]
    }
   ],
   "source": [
    "df = preprocessing.read_dataframe(filename, remove_pauses=True, remove_errors=True, preprocessing=True, drop_error_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mtable_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                 \u001b[0mrender_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             )\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, line_width, max_rows, min_rows, max_cols, show_dimensions, decimal, table_id, render_links, bold_rows, escape)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chk_truncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_adjustment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_chk_truncate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0mcol_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_cols_adj\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 frame = concat(\n\u001b[0;32m--> 680\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m                 )\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# truncate formatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2014\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_uniform_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m             b = join_units[0].block.concat_same_type(\n\u001b[1;32m   2018\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mis_uniform_join_units\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;31m# unless we're an extension dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;31m# unless we're an extension dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mis_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mchunk_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_len\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    150\u001b[0m         ),\n\u001b[1;32m    151\u001b[0m     ):\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bon17/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# object array of non-strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnaobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = [\"2016-12-17_1330_US_KCET_Asia_Insight\", \"2016-10-25_2300_US_KABC_Eyewitness_News_4PM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_word_frequency</th>\n",
       "      <th>next_word</th>\n",
       "      <th>next_word_frequency</th>\n",
       "      <th>letter_length</th>\n",
       "      <th>prev_word_string</th>\n",
       "      <th>next_word_string</th>\n",
       "      <th>prev_word_string_frequency</th>\n",
       "      <th>next_word_string_frequency</th>\n",
       "      <th>cond_pred_prev</th>\n",
       "      <th>cond_pred_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14828820</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>police</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>don't</td>\n",
       "      <td>32647.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police-don't</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828821</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>don't</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.21</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>18598.0</td>\n",
       "      <td>believe</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>5</td>\n",
       "      <td>police-don't</td>\n",
       "      <td>don't-believe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.054839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828822</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>believe</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.33</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>32647.0</td>\n",
       "      <td>the</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>7</td>\n",
       "      <td>don't-believe</td>\n",
       "      <td>believe-the</td>\n",
       "      <td>540.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828823</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>the</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.18</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>mother</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>3</td>\n",
       "      <td>believe-the</td>\n",
       "      <td>the-mother</td>\n",
       "      <td>793.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.143822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828824</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>mother</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.39</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>or</td>\n",
       "      <td>57737.0</td>\n",
       "      <td>6</td>\n",
       "      <td>the-mother</td>\n",
       "      <td>mother-or</td>\n",
       "      <td>490.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805800</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>2017</td>\n",
       "      <td>1657.55</td>\n",
       "      <td>1657.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>335519.0</td>\n",
       "      <td>as</td>\n",
       "      <td>89095.0</td>\n",
       "      <td>4</td>\n",
       "      <td>in-2017</td>\n",
       "      <td>2017-as</td>\n",
       "      <td>151.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805801</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>as</td>\n",
       "      <td>1659.25</td>\n",
       "      <td>1659.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>597.0</td>\n",
       "      <td>the</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-as</td>\n",
       "      <td>as-the</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805802</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>the</td>\n",
       "      <td>1659.50</td>\n",
       "      <td>1659.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>89095.0</td>\n",
       "      <td>world's</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>3</td>\n",
       "      <td>as-the</td>\n",
       "      <td>the-world's</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.077546</td>\n",
       "      <td>0.794099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805803</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>world's</td>\n",
       "      <td>1659.65</td>\n",
       "      <td>1660.25</td>\n",
       "      <td>0.60</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>largest</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>7</td>\n",
       "      <td>the-world's</td>\n",
       "      <td>world's-largest</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.110604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805804</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>largest</td>\n",
       "      <td>1660.25</td>\n",
       "      <td>1660.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>world's-largest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7435 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file     word    start  \\\n",
       "14828820  2016-10-25_2300_US_KABC_Eyewitness_News_4PM   police     0.29   \n",
       "14828821  2016-10-25_2300_US_KABC_Eyewitness_News_4PM    don't     0.67   \n",
       "14828822  2016-10-25_2300_US_KABC_Eyewitness_News_4PM  believe     0.88   \n",
       "14828823  2016-10-25_2300_US_KABC_Eyewitness_News_4PM      the     1.22   \n",
       "14828824  2016-10-25_2300_US_KABC_Eyewitness_News_4PM   mother     1.40   \n",
       "...                                               ...      ...      ...   \n",
       "17805800         2016-12-17_1330_US_KCET_Asia_Insight     2017  1657.55   \n",
       "17805801         2016-12-17_1330_US_KCET_Asia_Insight       as  1659.25   \n",
       "17805802         2016-12-17_1330_US_KCET_Asia_Insight      the  1659.50   \n",
       "17805803         2016-12-17_1330_US_KCET_Asia_Insight  world's  1659.65   \n",
       "17805804         2016-12-17_1330_US_KCET_Asia_Insight  largest  1660.25   \n",
       "\n",
       "              end  duration       label_type mp4_error aac_error  \\\n",
       "14828820     0.67      0.38  high-confidence  no-error  no-error   \n",
       "14828821     0.88      0.21  high-confidence  no-error  no-error   \n",
       "14828822     1.21      0.33  high-confidence  no-error  no-error   \n",
       "14828823     1.40      0.18  high-confidence  no-error  no-error   \n",
       "14828824     1.79      0.39  high-confidence  no-error  no-error   \n",
       "...           ...       ...              ...       ...       ...   \n",
       "17805800  1657.71      0.16  high-confidence  no-error  no-error   \n",
       "17805801  1659.49      0.24  high-confidence  no-error  no-error   \n",
       "17805802  1659.65      0.15  high-confidence  no-error  no-error   \n",
       "17805803  1660.25      0.60  high-confidence  no-error  no-error   \n",
       "17805804  1660.82      0.57  high-confidence  no-error  no-error   \n",
       "\n",
       "         aac2wav_error eafgz_error  ... prev_word_frequency  next_word  \\\n",
       "14828820      no-error    no-error  ...                 NaN      don't   \n",
       "14828821      no-error    no-error  ...             18598.0    believe   \n",
       "14828822      no-error    no-error  ...             32647.0        the   \n",
       "14828823      no-error    no-error  ...              9847.0     mother   \n",
       "14828824      no-error    no-error  ...            932396.0         or   \n",
       "...                ...         ...  ...                 ...        ...   \n",
       "17805800      no-error    no-error  ...            335519.0         as   \n",
       "17805801      no-error    no-error  ...               597.0        the   \n",
       "17805802      no-error    no-error  ...             89095.0    world's   \n",
       "17805803      no-error    no-error  ...            932396.0    largest   \n",
       "17805804      no-error    no-error  ...              1593.0        NaN   \n",
       "\n",
       "          next_word_frequency  letter_length prev_word_string  \\\n",
       "14828820              32647.0              6              NaN   \n",
       "14828821               9847.0              5     police-don't   \n",
       "14828822             932396.0              7    don't-believe   \n",
       "14828823               3407.0              3      believe-the   \n",
       "14828824              57737.0              6       the-mother   \n",
       "...                       ...            ...              ...   \n",
       "17805800              89095.0              4          in-2017   \n",
       "17805801             932396.0              2          2017-as   \n",
       "17805802               1593.0              3           as-the   \n",
       "17805803               1971.0              7      the-world's   \n",
       "17805804                  NaN              7  world's-largest   \n",
       "\n",
       "          next_word_string prev_word_string_frequency  \\\n",
       "14828820      police-don't                        NaN   \n",
       "14828821     don't-believe                       37.0   \n",
       "14828822       believe-the                      540.0   \n",
       "14828823        the-mother                      793.0   \n",
       "14828824         mother-or                      490.0   \n",
       "...                    ...                        ...   \n",
       "17805800           2017-as                      151.0   \n",
       "17805801            as-the                       15.0   \n",
       "17805802       the-world's                     6909.0   \n",
       "17805803   world's-largest                     1265.0   \n",
       "17805804               NaN                      218.0   \n",
       "\n",
       "          next_word_string_frequency  cond_pred_prev cond_pred_next  \n",
       "14828820                        37.0             NaN       0.001133  \n",
       "14828821                       540.0        0.001989       0.054839  \n",
       "14828822                       793.0        0.016541       0.000850  \n",
       "14828823                       490.0        0.080532       0.143822  \n",
       "14828824                        21.0        0.000526       0.000364  \n",
       "...                              ...             ...            ...  \n",
       "17805800                        15.0        0.000450       0.000168  \n",
       "17805801                      6909.0        0.025126       0.007410  \n",
       "17805802                      1265.0        0.077546       0.794099  \n",
       "17805803                       218.0        0.001357       0.110604  \n",
       "17805804                         NaN        0.136849            NaN  \n",
       "\n",
       "[7435 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(\"sub_df.csv\", index_col=\"Unnamed: 0\")\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read Gahls Homophone data from Data/hom.csv\n",
      "406 out of 412 homophones found in Data:\n",
      "Homophone Pairs found in Data: 200\n",
      "Homophones without Pair:  ['flowers', 'holes', 'moose', 'naval', 'pairs', 'taught']\n",
      "Missing homophones: ['flours' 'mousse' 'navel' 'pears' 'taut' 'wholes']\n"
     ]
    }
   ],
   "source": [
    "homophones_in_data, gahls_homophones, gahls_homophones_missing_in_data = preprocessing.read_and_extract_homophones(hom_filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>next_word_string</th>\n",
       "      <th>prev_word_string_frequency</th>\n",
       "      <th>next_word_string_frequency</th>\n",
       "      <th>cond_pred_prev</th>\n",
       "      <th>cond_pred_next</th>\n",
       "      <th>has_pair</th>\n",
       "      <th>pron</th>\n",
       "      <th>celexPhon</th>\n",
       "      <th>pron_frequency</th>\n",
       "      <th>is_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>14.940000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-when</td>\n",
       "      <td>490.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>297.990000</td>\n",
       "      <td>298.300000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-and</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.194462</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>737.299999</td>\n",
       "      <td>737.609999</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-he</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.194462</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1187.000000</td>\n",
       "      <td>1187.520000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-making</td>\n",
       "      <td>347.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.129914</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1195.000000</td>\n",
       "      <td>1195.350000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>night-early</td>\n",
       "      <td>347.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.129914</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1260.480000</td>\n",
       "      <td>1260.780000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>passed-a</td>\n",
       "      <td>81.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1264.710000</td>\n",
       "      <td>1264.750000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>passed-and</td>\n",
       "      <td>81.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>higher</td>\n",
       "      <td>1307.420000</td>\n",
       "      <td>1307.800000</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>higher-than</td>\n",
       "      <td>32.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>False</td>\n",
       "      <td>h2_TR</td>\n",
       "      <td>h2@R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>waste</td>\n",
       "      <td>1384.379999</td>\n",
       "      <td>1384.669999</td>\n",
       "      <td>0.29</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>waste-one</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>False</td>\n",
       "      <td>w1st</td>\n",
       "      <td>w1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>chilly</td>\n",
       "      <td>1403.240000</td>\n",
       "      <td>1403.650000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>chilly-weather</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>False</td>\n",
       "      <td>JI_lI</td>\n",
       "      <td>JIlI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source_file    word        start  \\\n",
       "0    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night    14.540000   \n",
       "1    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   297.990000   \n",
       "2    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   737.299999   \n",
       "3    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1187.000000   \n",
       "4    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1195.000000   \n",
       "..                                           ...     ...          ...   \n",
       "200         2016-12-17_1330_US_KCET_Asia_Insight  passed  1260.480000   \n",
       "201         2016-12-17_1330_US_KCET_Asia_Insight  passed  1264.710000   \n",
       "202         2016-12-17_1330_US_KCET_Asia_Insight  higher  1307.420000   \n",
       "203         2016-12-17_1330_US_KCET_Asia_Insight   waste  1384.379999   \n",
       "204         2016-12-17_1330_US_KCET_Asia_Insight  chilly  1403.240000   \n",
       "\n",
       "             end  duration       label_type mp4_error aac_error aac2wav_error  \\\n",
       "0      14.940000      0.40  high-confidence  no-error  no-error      no-error   \n",
       "1     298.300000      0.31  high-confidence  no-error  no-error      no-error   \n",
       "2     737.609999      0.31  high-confidence  no-error  no-error      no-error   \n",
       "3    1187.520000      0.52  high-confidence  no-error  no-error      no-error   \n",
       "4    1195.350000      0.35   low-confidence  no-error  no-error      no-error   \n",
       "..           ...       ...              ...       ...       ...           ...   \n",
       "200  1260.780000      0.30  high-confidence  no-error  no-error      no-error   \n",
       "201  1264.750000      0.04   low-confidence  no-error  no-error      no-error   \n",
       "202  1307.800000      0.38  high-confidence  no-error  no-error      no-error   \n",
       "203  1384.669999      0.29  high-confidence  no-error  no-error      no-error   \n",
       "204  1403.650000      0.41  high-confidence  no-error  no-error      no-error   \n",
       "\n",
       "    eafgz_error  ... next_word_string  prev_word_string_frequency  \\\n",
       "0      no-error  ...       night-when                       490.0   \n",
       "1      no-error  ...        night-and                      4410.0   \n",
       "2      no-error  ...         night-he                      4410.0   \n",
       "3      no-error  ...     night-making                       347.0   \n",
       "4      no-error  ...      night-early                       347.0   \n",
       "..          ...  ...              ...                         ...   \n",
       "200    no-error  ...         passed-a                        81.0   \n",
       "201    no-error  ...       passed-and                        81.0   \n",
       "202    no-error  ...      higher-than                        32.0   \n",
       "203    no-error  ...        waste-one                        41.0   \n",
       "204    no-error  ...   chilly-weather                        30.0   \n",
       "\n",
       "     next_word_string_frequency  cond_pred_prev cond_pred_next  has_pair  \\\n",
       "0                         244.0        0.005139       0.005493     False   \n",
       "1                         754.0        0.194462       0.001763     False   \n",
       "2                         268.0        0.194462       0.002229     False   \n",
       "3                           6.0        0.129914       0.000725     False   \n",
       "4                           6.0        0.129914       0.001257     False   \n",
       "..                          ...             ...            ...       ...   \n",
       "200                       107.0        0.000674       0.000250      True   \n",
       "201                        36.0        0.000674       0.000084      True   \n",
       "202                       291.0        0.004683       0.010053     False   \n",
       "203                         3.0        0.000076       0.000051     False   \n",
       "204                        11.0        0.000032       0.002680     False   \n",
       "\n",
       "      pron  celexPhon  pron_frequency is_max  \n",
       "0      n2t        n2t              11      1  \n",
       "1      n2t        n2t              11      1  \n",
       "2      n2t        n2t              11      1  \n",
       "3      n2t        n2t              11      1  \n",
       "4      n2t        n2t              11      1  \n",
       "..     ...        ...             ...    ...  \n",
       "200   pBst       p#st               6      1  \n",
       "201   pBst       p#st               6      1  \n",
       "202  h2_TR       h2@R               1      1  \n",
       "203   w1st       w1st               1      1  \n",
       "204  JI_lI       JIlI               1      1  \n",
       "\n",
       "[205 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARPAbet_phonetic_transcription(word_list):\n",
    "    g2p = G2p()\n",
    "    arpabet_word_list = []\n",
    "    for word in word_list:\n",
    "        transcription = g2p(word)\n",
    "        arpabet_word_list.append(transcription)\n",
    "\n",
    "    return arpabet_word_list\n",
    "\n",
    "\n",
    "def get_english_phonology_from_celex(filename):\n",
    "    phonology_dict = {\"word\":[], \"disc\":[], \"clx\":[]}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\\\\")\n",
    "            word = line[1] # the word\n",
    "            phonology_dict[\"word\"].append(word)\n",
    "            disc = line[6] # pronunciation in DISC notation, hyphens to mark syllable boundaries, inverted comma for primary stress and double quote for secondary stress (PhonStrsDISC)\n",
    "            phonology_dict[\"disc\"].append(disc)\n",
    "            clx = line[8] # pronunciation in CELEX notation, with brackets (PhonSylBCLX)\n",
    "            phonology_dict[\"clx\"].append(clx)\n",
    "\n",
    "    celex_phonology_dict = pd.DataFrame.from_dict(phonology_dict).drop_duplicates()\n",
    "    celex_phonology_dict[\"disc_no_bound\"] = celex_phonology_dict[\"disc\"].apply(\n",
    "        lambda x: x.replace(\"'\", \"\").replace(\"-\", \"\"))\n",
    "    celex_phonology_dict[\"clx_no_bound\"] = celex_phonology_dict[\"clx\"].apply(\n",
    "        lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    return celex_phonology_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_celex_transcription(df, celex_phonology_dict):\n",
    "\n",
    "    return df.merge(celex_phonology_dict[[\"word\", \"disc\", \"clx\", \"disc_no_bound\", \"clx_no_bound\"]], how = \"left\", left_on=[\"word\", \"celexPhon\"], right_on=[\"word\",\"disc_no_bound\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_phonology_dict = get_english_phonology_from_celex(celex_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>'1</td>\n",
       "      <td>[eI]</td>\n",
       "      <td>1</td>\n",
       "      <td>eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>'1</td>\n",
       "      <td>[eI]</td>\n",
       "      <td>1</td>\n",
       "      <td>eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA</td>\n",
       "      <td>\"1-'1</td>\n",
       "      <td>[eI][eI]</td>\n",
       "      <td>\"11</td>\n",
       "      <td>eIeI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAs</td>\n",
       "      <td>\"1-'1z</td>\n",
       "      <td>[eI][eIz]</td>\n",
       "      <td>\"11z</td>\n",
       "      <td>eIeIz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abaci</td>\n",
       "      <td>'{-b@-s2</td>\n",
       "      <td>[&amp;][b@][saI]</td>\n",
       "      <td>{b@s2</td>\n",
       "      <td>&amp;b@saI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100620</th>\n",
       "      <td>Zouave</td>\n",
       "      <td>zu-'#v</td>\n",
       "      <td>[zu:][A:v]</td>\n",
       "      <td>zu#v</td>\n",
       "      <td>zu:A:v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100621</th>\n",
       "      <td>Zouaves</td>\n",
       "      <td>zu-'#vz</td>\n",
       "      <td>[zu:][A:vz]</td>\n",
       "      <td>zu#vz</td>\n",
       "      <td>zu:A:vz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100622</th>\n",
       "      <td>z's</td>\n",
       "      <td>'zEdz</td>\n",
       "      <td>[zEdz]</td>\n",
       "      <td>zEdz</td>\n",
       "      <td>zEdz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100623</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>zU-'ki-nI</td>\n",
       "      <td>[zU][ki:][nI]</td>\n",
       "      <td>zUkinI</td>\n",
       "      <td>zUki:nI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100624</th>\n",
       "      <td>zucchinis</td>\n",
       "      <td>zU-'ki-nIz</td>\n",
       "      <td>[zU][ki:][nIz]</td>\n",
       "      <td>zUkinIz</td>\n",
       "      <td>zUki:nIz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90401 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word        disc             clx disc_no_bound clx_no_bound\n",
       "0               a          '1            [eI]             1           eI\n",
       "2               A          '1            [eI]             1           eI\n",
       "4              AA       \"1-'1        [eI][eI]           \"11         eIeI\n",
       "6             AAs      \"1-'1z       [eI][eIz]          \"11z        eIeIz\n",
       "7           abaci    '{-b@-s2    [&][b@][saI]         {b@s2       &b@saI\n",
       "...           ...         ...             ...           ...          ...\n",
       "100620     Zouave      zu-'#v      [zu:][A:v]          zu#v       zu:A:v\n",
       "100621    Zouaves     zu-'#vz     [zu:][A:vz]         zu#vz      zu:A:vz\n",
       "100622        z's       'zEdz          [zEdz]          zEdz         zEdz\n",
       "100623   zucchini   zU-'ki-nI   [zU][ki:][nI]        zUkinI      zUki:nI\n",
       "100624  zucchinis  zU-'ki-nIz  [zU][ki:][nIz]       zUkinIz     zUki:nIz\n",
       "\n",
       "[90401 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celex_phonology_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_mapped = get_celex_transcription(homophones_in_data,celex_phonology_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>cond_pred_next</th>\n",
       "      <th>has_pair</th>\n",
       "      <th>pron</th>\n",
       "      <th>celexPhon</th>\n",
       "      <th>pron_frequency</th>\n",
       "      <th>is_max</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>14.940000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>297.990000</td>\n",
       "      <td>298.300000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>737.299999</td>\n",
       "      <td>737.609999</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1187.000000</td>\n",
       "      <td>1187.520000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>night</td>\n",
       "      <td>1195.000000</td>\n",
       "      <td>1195.350000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>False</td>\n",
       "      <td>n2t</td>\n",
       "      <td>n2t</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>'n2t</td>\n",
       "      <td>[naIt]</td>\n",
       "      <td>n2t</td>\n",
       "      <td>naIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1260.480000</td>\n",
       "      <td>1260.780000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>'p#st</td>\n",
       "      <td>[pA:st]</td>\n",
       "      <td>p#st</td>\n",
       "      <td>pA:st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>passed</td>\n",
       "      <td>1264.710000</td>\n",
       "      <td>1264.750000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>True</td>\n",
       "      <td>pBst</td>\n",
       "      <td>p#st</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>'p#st</td>\n",
       "      <td>[pA:st]</td>\n",
       "      <td>p#st</td>\n",
       "      <td>pA:st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>higher</td>\n",
       "      <td>1307.420000</td>\n",
       "      <td>1307.800000</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>False</td>\n",
       "      <td>h2_TR</td>\n",
       "      <td>h2@R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'h2-@R</td>\n",
       "      <td>[haI][@r*]</td>\n",
       "      <td>h2@R</td>\n",
       "      <td>haI@r*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>waste</td>\n",
       "      <td>1384.379999</td>\n",
       "      <td>1384.669999</td>\n",
       "      <td>0.29</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>False</td>\n",
       "      <td>w1st</td>\n",
       "      <td>w1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'w1st</td>\n",
       "      <td>[weIst]</td>\n",
       "      <td>w1st</td>\n",
       "      <td>weIst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>chilly</td>\n",
       "      <td>1403.240000</td>\n",
       "      <td>1403.650000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>False</td>\n",
       "      <td>JI_lI</td>\n",
       "      <td>JIlI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'JI-lI</td>\n",
       "      <td>[tSI][lI]</td>\n",
       "      <td>JIlI</td>\n",
       "      <td>tSIlI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source_file    word        start  \\\n",
       "0    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night    14.540000   \n",
       "1    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   297.990000   \n",
       "2    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night   737.299999   \n",
       "3    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1187.000000   \n",
       "4    2016-10-25_2300_US_KABC_Eyewitness_News_4PM   night  1195.000000   \n",
       "..                                           ...     ...          ...   \n",
       "200         2016-12-17_1330_US_KCET_Asia_Insight  passed  1260.480000   \n",
       "201         2016-12-17_1330_US_KCET_Asia_Insight  passed  1264.710000   \n",
       "202         2016-12-17_1330_US_KCET_Asia_Insight  higher  1307.420000   \n",
       "203         2016-12-17_1330_US_KCET_Asia_Insight   waste  1384.379999   \n",
       "204         2016-12-17_1330_US_KCET_Asia_Insight  chilly  1403.240000   \n",
       "\n",
       "             end  duration       label_type mp4_error aac_error aac2wav_error  \\\n",
       "0      14.940000      0.40  high-confidence  no-error  no-error      no-error   \n",
       "1     298.300000      0.31  high-confidence  no-error  no-error      no-error   \n",
       "2     737.609999      0.31  high-confidence  no-error  no-error      no-error   \n",
       "3    1187.520000      0.52  high-confidence  no-error  no-error      no-error   \n",
       "4    1195.350000      0.35   low-confidence  no-error  no-error      no-error   \n",
       "..           ...       ...              ...       ...       ...           ...   \n",
       "200  1260.780000      0.30  high-confidence  no-error  no-error      no-error   \n",
       "201  1264.750000      0.04   low-confidence  no-error  no-error      no-error   \n",
       "202  1307.800000      0.38  high-confidence  no-error  no-error      no-error   \n",
       "203  1384.669999      0.29  high-confidence  no-error  no-error      no-error   \n",
       "204  1403.650000      0.41  high-confidence  no-error  no-error      no-error   \n",
       "\n",
       "    eafgz_error  ... cond_pred_next  has_pair   pron  celexPhon  \\\n",
       "0      no-error  ...       0.005493     False    n2t        n2t   \n",
       "1      no-error  ...       0.001763     False    n2t        n2t   \n",
       "2      no-error  ...       0.002229     False    n2t        n2t   \n",
       "3      no-error  ...       0.000725     False    n2t        n2t   \n",
       "4      no-error  ...       0.001257     False    n2t        n2t   \n",
       "..          ...  ...            ...       ...    ...        ...   \n",
       "200    no-error  ...       0.000250      True   pBst       p#st   \n",
       "201    no-error  ...       0.000084      True   pBst       p#st   \n",
       "202    no-error  ...       0.010053     False  h2_TR       h2@R   \n",
       "203    no-error  ...       0.000051     False   w1st       w1st   \n",
       "204    no-error  ...       0.002680     False  JI_lI       JIlI   \n",
       "\n",
       "    pron_frequency  is_max    disc         clx  disc_no_bound clx_no_bound  \n",
       "0               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "1               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "2               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "3               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "4               11       1    'n2t      [naIt]            n2t         naIt  \n",
       "..             ...     ...     ...         ...            ...          ...  \n",
       "200              6       1   'p#st     [pA:st]           p#st        pA:st  \n",
       "201              6       1   'p#st     [pA:st]           p#st        pA:st  \n",
       "202              1       1  'h2-@R  [haI][@r*]           h2@R       haI@r*  \n",
       "203              1       1   'w1st     [weIst]           w1st        weIst  \n",
       "204              1       1  'JI-lI   [tSI][lI]           JIlI        tSIlI  \n",
       "\n",
       "[205 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_character_code = pd.read_csv(\"Data/celex_phonetic_character_code_berndt1987.csv\", delimiter=\";\")\n",
    "berndt_conditional_probs = pd.read_csv(\"Data/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyboard_compatible_phonetic_symbol</th>\n",
       "      <th>CELEX</th>\n",
       "      <th>g2p(ARPAbet)</th>\n",
       "      <th>DISC</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ay</td>\n",
       "      <td>eI</td>\n",
       "      <td>EY1</td>\n",
       "      <td>1</td>\n",
       "      <td>ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>AE1</td>\n",
       "      <td>{</td>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee</td>\n",
       "      <td>i:</td>\n",
       "      <td>IY1</td>\n",
       "      <td>i</td>\n",
       "      <td>bee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eh</td>\n",
       "      <td>E</td>\n",
       "      <td>EH1</td>\n",
       "      <td>E</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>er</td>\n",
       "      <td>@r*</td>\n",
       "      <td>ER0</td>\n",
       "      <td>@R</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>aI</td>\n",
       "      <td>AY1</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ih</td>\n",
       "      <td>I</td>\n",
       "      <td>IH1</td>\n",
       "      <td>I</td>\n",
       "      <td>bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>@U</td>\n",
       "      <td>OW1</td>\n",
       "      <td>5</td>\n",
       "      <td>boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ah</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1</td>\n",
       "      <td>Q</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aw</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1</td>\n",
       "      <td>Q</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oo</td>\n",
       "      <td>u:</td>\n",
       "      <td>UW1</td>\n",
       "      <td>u</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u</td>\n",
       "      <td>U</td>\n",
       "      <td>UH1</td>\n",
       "      <td>U</td>\n",
       "      <td>hook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yu</td>\n",
       "      <td>ju:</td>\n",
       "      <td>YUW1</td>\n",
       "      <td>ju</td>\n",
       "      <td>unite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>uh+</td>\n",
       "      <td>V</td>\n",
       "      <td>AH1</td>\n",
       "      <td>V</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oy</td>\n",
       "      <td>OI</td>\n",
       "      <td>OY1</td>\n",
       "      <td>4</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>au</td>\n",
       "      <td>aU</td>\n",
       "      <td>AW1</td>\n",
       "      <td>6</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>uh-</td>\n",
       "      <td>@</td>\n",
       "      <td>AH0</td>\n",
       "      <td>@</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>d</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>G</td>\n",
       "      <td>g</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>HH</td>\n",
       "      <td>h</td>\n",
       "      <td>hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dj</td>\n",
       "      <td>dZ</td>\n",
       "      <td>JH</td>\n",
       "      <td>_</td>\n",
       "      <td>joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>K</td>\n",
       "      <td>k</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>L</td>\n",
       "      <td>l</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>M</td>\n",
       "      <td>m</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>n</td>\n",
       "      <td>nod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>P</td>\n",
       "      <td>p</td>\n",
       "      <td>pen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>r</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>sue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>t</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>V</td>\n",
       "      <td>v</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>y</td>\n",
       "      <td>j</td>\n",
       "      <td>Y</td>\n",
       "      <td>j</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>z</td>\n",
       "      <td>z</td>\n",
       "      <td>Z</td>\n",
       "      <td>z</td>\n",
       "      <td>zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tch</td>\n",
       "      <td>tS</td>\n",
       "      <td>CH</td>\n",
       "      <td>J</td>\n",
       "      <td>chin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ks</td>\n",
       "      <td>ks</td>\n",
       "      <td>KS</td>\n",
       "      <td>ks</td>\n",
       "      <td>ox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gz</td>\n",
       "      <td>gz</td>\n",
       "      <td>GZ</td>\n",
       "      <td>gz</td>\n",
       "      <td>exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kw</td>\n",
       "      <td>kw</td>\n",
       "      <td>KW</td>\n",
       "      <td>kw</td>\n",
       "      <td>quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ul</td>\n",
       "      <td>l,</td>\n",
       "      <td>AH0L</td>\n",
       "      <td>P</td>\n",
       "      <td>puddle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>um</td>\n",
       "      <td>@m</td>\n",
       "      <td>AH0M</td>\n",
       "      <td>@m</td>\n",
       "      <td>chasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>un</td>\n",
       "      <td>n,</td>\n",
       "      <td>AH0N</td>\n",
       "      <td>H</td>\n",
       "      <td>pardon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ng</td>\n",
       "      <td>N</td>\n",
       "      <td>NG</td>\n",
       "      <td>N</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sh</td>\n",
       "      <td>S</td>\n",
       "      <td>SH</td>\n",
       "      <td>S</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>th-</td>\n",
       "      <td>T</td>\n",
       "      <td>TH</td>\n",
       "      <td>T</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>th+</td>\n",
       "      <td>D</td>\n",
       "      <td>DH</td>\n",
       "      <td>D</td>\n",
       "      <td>then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>zh</td>\n",
       "      <td>Z</td>\n",
       "      <td>ZH</td>\n",
       "      <td>Z</td>\n",
       "      <td>rouge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>honest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyboard_compatible_phonetic_symbol CELEX g2p(ARPAbet) DISC Example\n",
       "0                                   ay    eI          EY1    1     ale\n",
       "1                                   ae     &          AE1    {     add\n",
       "2                                   ee    i:          IY1    i     bee\n",
       "3                                   eh     E          EH1    E     end\n",
       "4                                   er   @r*          ER0   @R  father\n",
       "5                                   ai    aI          AY1    2    high\n",
       "6                                   ih     I          IH1    I     bin\n",
       "7                                    o    @U          OW1    5    boat\n",
       "8                                   ah     O          AA1    Q     cot\n",
       "9                                   aw     O          AA1    Q    soft\n",
       "10                                  oo    u:          UW1    u    food\n",
       "11                                   u     U          UH1    U    hook\n",
       "12                                  yu   ju:         YUW1   ju   unite\n",
       "13                                 uh+     V          AH1    V      up\n",
       "14                                  oy    OI          OY1    4     boy\n",
       "15                                  au    aU          AW1    6     out\n",
       "16                                 uh-     @          AH0    @   about\n",
       "17                                   b     b            B    b     but\n",
       "18                                   d     d            D    d     day\n",
       "19                                   f     f            F    f     fan\n",
       "20                                   g     g            G    g      go\n",
       "21                                   h     h           HH    h     hat\n",
       "22                                  dj    dZ           JH    _    joke\n",
       "23                                   k     k            K    k    keep\n",
       "24                                   l     l            L    l    late\n",
       "25                                   m     m            M    m     man\n",
       "26                                   n     n            N    n     nod\n",
       "27                                   p     p            P    p     pen\n",
       "28                                   r     r            R    r     rat\n",
       "29                                   s     s            S    s     sue\n",
       "30                                   t     t            T    t     two\n",
       "31                                   v     v            V    v     van\n",
       "32                                   w     w            W    w    wait\n",
       "33                                   y     j            Y    j     yet\n",
       "34                                   z     z            Z    z    zone\n",
       "35                                 tch    tS           CH    J    chin\n",
       "36                                  ks    ks           KS   ks      ox\n",
       "37                                  gz    gz           GZ   gz   exist\n",
       "38                                  kw    kw           KW   kw    quit\n",
       "39                                  ul    l,         AH0L    P  puddle\n",
       "40                                  um    @m         AH0M   @m   chasm\n",
       "41                                  un    n,         AH0N    H  pardon\n",
       "42                                  ng     N           NG    N    sing\n",
       "43                                  sh     S           SH    S     she\n",
       "44                                 th-     T           TH    T    thin\n",
       "45                                 th+     D           DH    D    then\n",
       "46                                  zh     Z           ZH    Z   rouge\n",
       "47                                  nl   NaN          NaN  NaN  honest"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_character_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'letter_length', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next', 'has_pair', 'pron', 'celexPhon',\n",
       "       'pron_frequency', 'is_max', 'disc', 'clx', 'disc_no_bound',\n",
       "       'clx_no_bound'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_mapped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39337</th>\n",
       "      <td>gym</td>\n",
       "      <td>'_Im</td>\n",
       "      <td>[dZIm]</td>\n",
       "      <td>_Im</td>\n",
       "      <td>dZIm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  disc     clx disc_no_bound clx_no_bound\n",
       "39337  gym  '_Im  [dZIm]           _Im         dZIm"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celex_phonology_dict[celex_phonology_dict.word == \"gym\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet_encoded_words = get_ARPAbet_phonetic_transcription(homophones_in_data_celex_mapped.word)\n",
    "arpabet_used_in_data = set(sum(arpabet_encoded_words,[]))\n",
    "\n",
    "#disc_encoded_words = list(homophones_in_data_celex_mapped.disc[pd.notnull(homophones_in_data_celex_mapped.disc)].str.replace(\"'\",\"\").str.split(\"-\"))\n",
    "#disc_used_in_data = set(sum(disc_encoded_words,[]))\n",
    "\n",
    "#clx_encoded_words = list(homophones_in_data_celex_mapped.clx[pd.notnull(homophones_in_data_celex_mapped.clx)].str.replace(\"[\",\"\").str.split(\"]\"))\n",
    "#clx_used_in_data = set(filter(lambda x: x != \"\",sum(clx_encoded_words,[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'AO1', 'EH0', 'ER1', 'EY2', 'IH0', 'IY0', 'OW0', 'OW2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpabet_used_in_data - set(berndt_character_code[\"g2p(ARPAbet)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_characters_used_in_data = set(''.join(list(disc_used_in_data)))\n",
    "disc_characters_for_berndts_encoding = set(''.join([str(i) for i in list(set(berndt_character_code.DISC))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_characters_used_in_data = set(''.join(list(clx_used_in_data)))\n",
    "clx_characters_for_berndts_encoding = set(''.join([str(i) for i in list(set(berndt_character_code.CELEX))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#', '$', '7', '8'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_characters_used_in_data - disc_characters_for_berndts_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clx_characters_used_in_data - clx_characters_for_berndts_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: b8R ['b8R'] bear\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: f8R ['f8R'] fair\n",
      "Missing: h$l ['h$l'] hall\n",
      "Missing: p#st ['p#st'] passed\n",
      "Missing: p#st ['p#st'] passed\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(disc_encoded_words):\n",
    "    for j in word:\n",
    "        if any(x in j for x in ['#', '$', '7', '8']):\n",
    "            print(\"Missing:\", j, word, homophones_in_data_celex_mapped.word[pd.notnull(homophones_in_data_celex_mapped.disc)].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] passed\n",
      "Missing: pA:st ['pA:st', ''] passed\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(clx_encoded_words):\n",
    "    for j in word:\n",
    "        if any(x in j for x in ['A']):\n",
    "            print(\"Missing:\", j, word, homophones_in_data_celex_mapped.word[pd.notnull(homophones_in_data_celex_mapped.clx)].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(arpabet_encoded_words):\n",
    "    for j in word:\n",
    "        if j in [\"EY2\"]:\n",
    "            print(\"Missing:\", j, word, homophones_in_data.word.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'AO1', 'EH0', 'ER1', 'EY2', 'IY0', 'OW0', 'OW2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ER1: heard, hurts\n",
    "EH0: ensure\n",
    "EY2: finance\n",
    "AA2: lumbar\n",
    "OW0 : cocoa\n",
    "OW2: coco\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EY1', 'L'],\n",
       " ['AE1', 'D'],\n",
       " ['B', 'IY1'],\n",
       " ['EH1', 'N', 'D'],\n",
       " ['F', 'AA1', 'DH', 'ER0'],\n",
       " ['HH', 'AY1'],\n",
       " ['B', 'IH1', 'N'],\n",
       " ['B', 'OW1', 'T'],\n",
       " ['K', 'AA1', 'T'],\n",
       " ['S', 'AA1', 'F', 'T'],\n",
       " ['F', 'UW1', 'D'],\n",
       " ['HH', 'UH1', 'K'],\n",
       " ['Y', 'UW1', 'N', 'AY2', 'T'],\n",
       " ['AH1', 'P'],\n",
       " ['B', 'OY1'],\n",
       " ['AW1', 'T'],\n",
       " ['AH0', 'B', 'AW1', 'T'],\n",
       " ['B', 'AH1', 'T'],\n",
       " ['D', 'EY1'],\n",
       " ['F', 'AE1', 'N'],\n",
       " ['G', 'OW1'],\n",
       " ['HH', 'AE1', 'T'],\n",
       " ['JH', 'OW1', 'K'],\n",
       " ['K', 'IY1', 'P'],\n",
       " ['L', 'EY1', 'T'],\n",
       " ['M', 'AE1', 'N'],\n",
       " ['N', 'AA1', 'D'],\n",
       " ['P', 'EH1', 'N'],\n",
       " ['R', 'AE1', 'T'],\n",
       " ['S', 'UW1'],\n",
       " ['T', 'UW1'],\n",
       " ['V', 'AE1', 'N'],\n",
       " ['W', 'EY1', 'T'],\n",
       " ['Y', 'EH1', 'T'],\n",
       " ['Z', 'OW1', 'N'],\n",
       " ['CH', 'IH1', 'N'],\n",
       " ['AA1', 'K', 'S'],\n",
       " ['IH0', 'G', 'Z', 'IH1', 'S', 'T'],\n",
       " ['K', 'W', 'IH1', 'T'],\n",
       " ['P', 'AH1', 'D', 'AH0', 'L'],\n",
       " ['K', 'AE1', 'Z', 'AH0', 'M'],\n",
       " ['P', 'AA1', 'R', 'D', 'AH0', 'N'],\n",
       " ['S', 'IH1', 'NG'],\n",
       " ['SH', 'IY1'],\n",
       " ['TH', 'IH1', 'N'],\n",
       " ['DH', 'EH1', 'N'],\n",
       " ['R', 'UW1', 'ZH'],\n",
       " ['AA1', 'N', 'AH0', 'S', 'T']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ARPAbet_phonetic_transcription(berndt_character_code.Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IH0', 'G', 'Z', 'IH1', 'S', 'T'] exist\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(get_ARPAbet_phonetic_transcription(berndt_character_code.Example)):\n",
    "    for j in word:\n",
    "        if j in ['IH0']:\n",
    "            print(word, berndt_character_code.Example[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R', 'IH1', 'NG', 'IH0', 'NG']]\n",
      "[['B', 'IH1', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"ringing\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bin\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'IY1']]\n",
      "[['CH', 'IH1', 'L', 'IY0']]\n",
      "[['G', 'R', 'IY1', 'D', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"bee\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"chilly\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"greedy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', 'AA1', 'F', 'T']]\n",
      "[['B', 'AO1', 'R', 'D']]\n",
      "[['K', 'AO1', 'R', 'S']]\n",
      "[['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"soft\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"board\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"course\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"extraordinary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EH0', 'N', 'SH', 'UH1', 'R']]\n",
      "[['EH1', 'N', 'D', 'ER0', 'AH0', 'N', 'S']]\n",
      "[['EH0', 'N', 'G', 'EY1', 'JH']]\n",
      "[['EH0', 'N', 'EY1', 'B', 'AH0', 'L']]\n",
      "[['EH1', 'N', 'D']]\n",
      "[['EH1', 'JH']]\n",
      "[['EH1', 'N', 'T', 'ER0']]\n",
      "[['EH0', 'N', 'R', 'UW1', 'T', 'UW2', 'D']]\n",
      "[['AA1', 'N', 'K', 'AO2', 'R']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"ensure\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"endurance\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"engage\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enable\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"end\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"edge\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enter\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enrooted\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"encore\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ER1', 'N']]\n",
      "[['F', 'AA1', 'DH', 'ER0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"earn\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"father\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F', 'IY0', 'AA1', 'N', 'S', 'EY2']]\n",
      "[['EH1', 'JH', 'AH0', 'K', 'EY2', 'T']]\n",
      "[['IH0', 'G', 'Z', 'AE1', 'JH', 'ER0', 'EY2', 'T']]\n",
      "[['S', 'ER1', 'V', 'EY2']]\n",
      "[['B', 'EY1']]\n",
      "[['K', 'AH0', 'N', 'V', 'EY1']]\n",
      "[['P', 'R', 'EY1']]\n",
      "[['G', 'R', 'EY1']]\n",
      "[['P', 'ER0', 'V', 'EY1']]\n",
      "[['TH', 'ER1', 'Z', 'D', 'EY2']]\n",
      "[['D', 'EY1']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"fiance\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"educate\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"exaggerate\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"survey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bay\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"convey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"prey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"gray\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"purvey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"thursday\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"day\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(get_ARPAbet_phonetic_transcription(berndt_character_code.Example)):\n",
    "    for j in word:\n",
    "        if j in ['IH0']:\n",
    "            print(word, berndt_character_code.Example[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_conditional_probs_words = get_ARPAbet_phonetic_transcription(berndt_conditional_probs.Example)\n",
    "arpabet_used_in_bernd_examples = set(sum(berndt_conditional_probs_words,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 ER1 ['ER1', 'N'] earn\n",
      "63 ER1 ['HH', 'ER1', 'S'] hearse\n",
      "103 ER1 ['AH0', 'F', 'ER1', 'M'] affirm \n",
      "110 ER1 ['D', 'ER1', 'JH'] dirge\n",
      "140 ER1 ['W', 'ER1', 'S'] worse\n",
      "166 ER1 ['S', 'K', 'ER1', 'JH'] scourge\n",
      "182 ER1 ['S', 'ER1', 'V', 'EY2'] survey\n",
      "182 EY2 ['S', 'ER1', 'V', 'EY2'] survey\n",
      "234 EY2 ['EH1', 'JH', 'AH0', 'K', 'EY2', 'T'] educate\n",
      "251 EY2 ['IH0', 'G', 'Z', 'AE1', 'JH', 'ER0', 'EY2', 'T'] exaggerate\n",
      "298 ER1 ['P', 'ER1'] purr \n",
      "305 ER1 ['D', 'IH0', 'S', 'ER1', 'N'] discern\n",
      "315 ER1 ['D', 'IH0', 'Z', 'ER1', 'T'] dessert\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(berndt_conditional_probs_words):\n",
    "    for j in word:\n",
    "        if j in [\"ER1\", \"EY2\"]:\n",
    "            print(i,j, word, berndt_conditional_probs.Example.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'OW2'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpabet_used_in_data - arpabet_used_in_bernd_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
