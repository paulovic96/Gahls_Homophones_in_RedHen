{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from g2p_en import G2p # https://github.com/Kyubyong/g2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_dict_file = \"Data/epw.cd\"\n",
    "filename = \"Data/2016_all_words_no_audio.pickle\"\n",
    "hom_filename = \"Data/hom.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dataframe from Data/2016_all_words_no_audio.pickle\n",
      "Preprocessing: extract pause information...\n",
      "Remove pauses from data!\n",
      "Preprocessing: apply word preprocessing...\n",
      "Preprocessing: calculate word duration...\n",
      "Preprocessing: calculate word frequency...\n",
      "Preprocessing: extract context information...\n",
      "Preprocessing: calculate letter length...\n",
      "Preprocessing: calculate contextual predictability...\n",
      "(18864660, 25) RangeIndex(start=0, stop=18864660, step=1)\n"
     ]
    }
   ],
   "source": [
    "df = preprocessing.read_dataframe(filename, remove_pauses=True, remove_errors=True, preprocessing=True, drop_error_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = [\"2016-12-17_1330_US_KCET_Asia_Insight\", \"2016-10-25_2300_US_KABC_Eyewitness_News_4PM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_word_frequency</th>\n",
       "      <th>next_word</th>\n",
       "      <th>next_word_frequency</th>\n",
       "      <th>letter_length</th>\n",
       "      <th>prev_word_string</th>\n",
       "      <th>next_word_string</th>\n",
       "      <th>prev_word_string_frequency</th>\n",
       "      <th>next_word_string_frequency</th>\n",
       "      <th>cond_pred_prev</th>\n",
       "      <th>cond_pred_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14828820</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>police</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>don't</td>\n",
       "      <td>32647.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police-don't</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828821</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>don't</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.21</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>18598.0</td>\n",
       "      <td>believe</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>5</td>\n",
       "      <td>police-don't</td>\n",
       "      <td>don't-believe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.054839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828822</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>believe</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.33</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>32647.0</td>\n",
       "      <td>the</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>7</td>\n",
       "      <td>don't-believe</td>\n",
       "      <td>believe-the</td>\n",
       "      <td>540.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828823</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>the</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.18</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>mother</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>3</td>\n",
       "      <td>believe-the</td>\n",
       "      <td>the-mother</td>\n",
       "      <td>793.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.143822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828824</th>\n",
       "      <td>2016-10-25_2300_US_KABC_Eyewitness_News_4PM</td>\n",
       "      <td>mother</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.39</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>or</td>\n",
       "      <td>57737.0</td>\n",
       "      <td>6</td>\n",
       "      <td>the-mother</td>\n",
       "      <td>mother-or</td>\n",
       "      <td>490.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805800</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>2017</td>\n",
       "      <td>1657.55</td>\n",
       "      <td>1657.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>335519.0</td>\n",
       "      <td>as</td>\n",
       "      <td>89095.0</td>\n",
       "      <td>4</td>\n",
       "      <td>in-2017</td>\n",
       "      <td>2017-as</td>\n",
       "      <td>151.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805801</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>as</td>\n",
       "      <td>1659.25</td>\n",
       "      <td>1659.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>597.0</td>\n",
       "      <td>the</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-as</td>\n",
       "      <td>as-the</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805802</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>the</td>\n",
       "      <td>1659.50</td>\n",
       "      <td>1659.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>89095.0</td>\n",
       "      <td>world's</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>3</td>\n",
       "      <td>as-the</td>\n",
       "      <td>the-world's</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.077546</td>\n",
       "      <td>0.794099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805803</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>world's</td>\n",
       "      <td>1659.65</td>\n",
       "      <td>1660.25</td>\n",
       "      <td>0.60</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>932396.0</td>\n",
       "      <td>largest</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>7</td>\n",
       "      <td>the-world's</td>\n",
       "      <td>world's-largest</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.110604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805804</th>\n",
       "      <td>2016-12-17_1330_US_KCET_Asia_Insight</td>\n",
       "      <td>largest</td>\n",
       "      <td>1660.25</td>\n",
       "      <td>1660.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>world's-largest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7435 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file     word    start  \\\n",
       "14828820  2016-10-25_2300_US_KABC_Eyewitness_News_4PM   police     0.29   \n",
       "14828821  2016-10-25_2300_US_KABC_Eyewitness_News_4PM    don't     0.67   \n",
       "14828822  2016-10-25_2300_US_KABC_Eyewitness_News_4PM  believe     0.88   \n",
       "14828823  2016-10-25_2300_US_KABC_Eyewitness_News_4PM      the     1.22   \n",
       "14828824  2016-10-25_2300_US_KABC_Eyewitness_News_4PM   mother     1.40   \n",
       "...                                               ...      ...      ...   \n",
       "17805800         2016-12-17_1330_US_KCET_Asia_Insight     2017  1657.55   \n",
       "17805801         2016-12-17_1330_US_KCET_Asia_Insight       as  1659.25   \n",
       "17805802         2016-12-17_1330_US_KCET_Asia_Insight      the  1659.50   \n",
       "17805803         2016-12-17_1330_US_KCET_Asia_Insight  world's  1659.65   \n",
       "17805804         2016-12-17_1330_US_KCET_Asia_Insight  largest  1660.25   \n",
       "\n",
       "              end  duration       label_type mp4_error aac_error  \\\n",
       "14828820     0.67      0.38  high-confidence  no-error  no-error   \n",
       "14828821     0.88      0.21  high-confidence  no-error  no-error   \n",
       "14828822     1.21      0.33  high-confidence  no-error  no-error   \n",
       "14828823     1.40      0.18  high-confidence  no-error  no-error   \n",
       "14828824     1.79      0.39  high-confidence  no-error  no-error   \n",
       "...           ...       ...              ...       ...       ...   \n",
       "17805800  1657.71      0.16  high-confidence  no-error  no-error   \n",
       "17805801  1659.49      0.24  high-confidence  no-error  no-error   \n",
       "17805802  1659.65      0.15  high-confidence  no-error  no-error   \n",
       "17805803  1660.25      0.60  high-confidence  no-error  no-error   \n",
       "17805804  1660.82      0.57  high-confidence  no-error  no-error   \n",
       "\n",
       "         aac2wav_error eafgz_error  ... prev_word_frequency  next_word  \\\n",
       "14828820      no-error    no-error  ...                 NaN      don't   \n",
       "14828821      no-error    no-error  ...             18598.0    believe   \n",
       "14828822      no-error    no-error  ...             32647.0        the   \n",
       "14828823      no-error    no-error  ...              9847.0     mother   \n",
       "14828824      no-error    no-error  ...            932396.0         or   \n",
       "...                ...         ...  ...                 ...        ...   \n",
       "17805800      no-error    no-error  ...            335519.0         as   \n",
       "17805801      no-error    no-error  ...               597.0        the   \n",
       "17805802      no-error    no-error  ...             89095.0    world's   \n",
       "17805803      no-error    no-error  ...            932396.0    largest   \n",
       "17805804      no-error    no-error  ...              1593.0        NaN   \n",
       "\n",
       "          next_word_frequency  letter_length prev_word_string  \\\n",
       "14828820              32647.0              6              NaN   \n",
       "14828821               9847.0              5     police-don't   \n",
       "14828822             932396.0              7    don't-believe   \n",
       "14828823               3407.0              3      believe-the   \n",
       "14828824              57737.0              6       the-mother   \n",
       "...                       ...            ...              ...   \n",
       "17805800              89095.0              4          in-2017   \n",
       "17805801             932396.0              2          2017-as   \n",
       "17805802               1593.0              3           as-the   \n",
       "17805803               1971.0              7      the-world's   \n",
       "17805804                  NaN              7  world's-largest   \n",
       "\n",
       "          next_word_string prev_word_string_frequency  \\\n",
       "14828820      police-don't                        NaN   \n",
       "14828821     don't-believe                       37.0   \n",
       "14828822       believe-the                      540.0   \n",
       "14828823        the-mother                      793.0   \n",
       "14828824         mother-or                      490.0   \n",
       "...                    ...                        ...   \n",
       "17805800           2017-as                      151.0   \n",
       "17805801            as-the                       15.0   \n",
       "17805802       the-world's                     6909.0   \n",
       "17805803   world's-largest                     1265.0   \n",
       "17805804               NaN                      218.0   \n",
       "\n",
       "          next_word_string_frequency  cond_pred_prev cond_pred_next  \n",
       "14828820                        37.0             NaN       0.001133  \n",
       "14828821                       540.0        0.001989       0.054839  \n",
       "14828822                       793.0        0.016541       0.000850  \n",
       "14828823                       490.0        0.080532       0.143822  \n",
       "14828824                        21.0        0.000526       0.000364  \n",
       "...                              ...             ...            ...  \n",
       "17805800                        15.0        0.000450       0.000168  \n",
       "17805801                      6909.0        0.025126       0.007410  \n",
       "17805802                      1265.0        0.077546       0.794099  \n",
       "17805803                       218.0        0.001357       0.110604  \n",
       "17805804                         NaN        0.136849            NaN  \n",
       "\n",
       "[7435 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(\"sub_df.csv\", index_col=\"Unnamed: 0\")\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read Gahls Homophone data from Data/hom.csv\n",
      "406 out of 412 homophones found in Data:\n",
      "Homophone Pairs found in Data: 200\n",
      "Homophones without Pair:  ['flowers', 'holes', 'moose', 'naval', 'pairs', 'taught']\n",
      "Missing homophones: ['flours' 'mousse' 'navel' 'pears' 'taut' 'wholes']\n"
     ]
    }
   ],
   "source": [
    "homophones_in_data, gahls_homophones, gahls_homophones_missing_in_data = preprocessing.read_and_extract_homophones(hom_filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spell', 'pron', 'lgPronCelFq', 'logCelFq', 'logAvgDur', 'stem',\n",
       "       'is_complex', 'celexPhon', 'phonNeighCount', 'NearestSemNeighCor',\n",
       "       'MeanCorTop20', 'AvCor', 'MedianCor', 'MeanCorTop20Unrel',\n",
       "       'CossinTwinsStem', 'CossinTwinsFull', 'L2Ldiag', 'EuclidDistTwins',\n",
       "       'SL1norm', 'CorrectLDLpred', 'SumChatWord', 'MinChatWord', 'L1ChatWord',\n",
       "       'CorPredWord', 'LWLinkRatioWord', 'RankProd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gahls_homophones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARPAbet_phonetic_transcription(word_list):\n",
    "    g2p = G2p()\n",
    "    arpabet_word_list = []\n",
    "    for word in word_list:\n",
    "        transcription = g2p(word)\n",
    "        arpabet_word_list.append(transcription)\n",
    "\n",
    "    return arpabet_word_list\n",
    "\n",
    "\n",
    "def get_english_phonology_from_celex(filename):\n",
    "    phonology_dict = {\"word\":[], \"disc\":[], \"clx\":[]}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\\\\")\n",
    "            word = line[1] # the word\n",
    "            phonology_dict[\"word\"].append(word)\n",
    "            disc = line[6] # pronunciation in DISC notation, hyphens to mark syllable boundaries, inverted comma for primary stress and double quote for secondary stress (PhonStrsDISC)\n",
    "            phonology_dict[\"disc\"].append(disc)\n",
    "            clx = line[8] # pronunciation in CELEX notation, with brackets (PhonSylBCLX)\n",
    "            phonology_dict[\"clx\"].append(clx)\n",
    "\n",
    "    celex_phonology_dict = pd.DataFrame.from_dict(phonology_dict).drop_duplicates()\n",
    "    celex_phonology_dict[\"disc_no_bound\"] = celex_phonology_dict[\"disc\"].apply(\n",
    "        lambda x: x.replace(\"'\", \"\").replace(\"-\", \"\"))\n",
    "    celex_phonology_dict[\"clx_no_bound\"] = celex_phonology_dict[\"clx\"].apply(\n",
    "        lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    return celex_phonology_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_celex_transcription(df, celex_phonology_dict):\n",
    "\n",
    "    return df.merge(celex_phonology_dict[[\"word\", \"disc\", \"clx\", \"disc_no_bound\", \"clx_no_bound\"]], how = \"left\", left_on=[\"word\", \"celexPhon\"], right_on=[\"word\",\"disc_no_bound\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex_phonology_dict = get_english_phonology_from_celex(celex_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>'1</td>\n",
       "      <td>[eI]</td>\n",
       "      <td>1</td>\n",
       "      <td>eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>'1</td>\n",
       "      <td>[eI]</td>\n",
       "      <td>1</td>\n",
       "      <td>eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA</td>\n",
       "      <td>\"1-'1</td>\n",
       "      <td>[eI][eI]</td>\n",
       "      <td>\"11</td>\n",
       "      <td>eIeI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAs</td>\n",
       "      <td>\"1-'1z</td>\n",
       "      <td>[eI][eIz]</td>\n",
       "      <td>\"11z</td>\n",
       "      <td>eIeIz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abaci</td>\n",
       "      <td>'{-b@-s2</td>\n",
       "      <td>[&amp;][b@][saI]</td>\n",
       "      <td>{b@s2</td>\n",
       "      <td>&amp;b@saI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100620</th>\n",
       "      <td>Zouave</td>\n",
       "      <td>zu-'#v</td>\n",
       "      <td>[zu:][A:v]</td>\n",
       "      <td>zu#v</td>\n",
       "      <td>zu:A:v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100621</th>\n",
       "      <td>Zouaves</td>\n",
       "      <td>zu-'#vz</td>\n",
       "      <td>[zu:][A:vz]</td>\n",
       "      <td>zu#vz</td>\n",
       "      <td>zu:A:vz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100622</th>\n",
       "      <td>z's</td>\n",
       "      <td>'zEdz</td>\n",
       "      <td>[zEdz]</td>\n",
       "      <td>zEdz</td>\n",
       "      <td>zEdz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100623</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>zU-'ki-nI</td>\n",
       "      <td>[zU][ki:][nI]</td>\n",
       "      <td>zUkinI</td>\n",
       "      <td>zUki:nI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100624</th>\n",
       "      <td>zucchinis</td>\n",
       "      <td>zU-'ki-nIz</td>\n",
       "      <td>[zU][ki:][nIz]</td>\n",
       "      <td>zUkinIz</td>\n",
       "      <td>zUki:nIz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90401 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word        disc             clx disc_no_bound clx_no_bound\n",
       "0               a          '1            [eI]             1           eI\n",
       "2               A          '1            [eI]             1           eI\n",
       "4              AA       \"1-'1        [eI][eI]           \"11         eIeI\n",
       "6             AAs      \"1-'1z       [eI][eIz]          \"11z        eIeIz\n",
       "7           abaci    '{-b@-s2    [&][b@][saI]         {b@s2       &b@saI\n",
       "...           ...         ...             ...           ...          ...\n",
       "100620     Zouave      zu-'#v      [zu:][A:v]          zu#v       zu:A:v\n",
       "100621    Zouaves     zu-'#vz     [zu:][A:vz]         zu#vz      zu:A:vz\n",
       "100622        z's       'zEdz          [zEdz]          zEdz         zEdz\n",
       "100623   zucchini   zU-'ki-nI   [zU][ki:][nI]        zUkinI      zUki:nI\n",
       "100624  zucchinis  zU-'ki-nIz  [zU][ki:][nIz]       zUkinIz     zUki:nIz\n",
       "\n",
       "[90401 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celex_phonology_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_in_data_celex_mapped = get_celex_transcription(homophones_in_data,celex_phonology_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>label_type</th>\n",
       "      <th>mp4_error</th>\n",
       "      <th>aac_error</th>\n",
       "      <th>aac2wav_error</th>\n",
       "      <th>eafgz_error</th>\n",
       "      <th>...</th>\n",
       "      <th>cond_pred_next</th>\n",
       "      <th>has_pair</th>\n",
       "      <th>pron</th>\n",
       "      <th>celexPhon</th>\n",
       "      <th>pron_frequency</th>\n",
       "      <th>is_max</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01_0100_US_KNBC_Channel_4_News</td>\n",
       "      <td>right</td>\n",
       "      <td>12.070000</td>\n",
       "      <td>12.280000</td>\n",
       "      <td>0.21</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>True</td>\n",
       "      <td>r2t</td>\n",
       "      <td>r2t</td>\n",
       "      <td>41655</td>\n",
       "      <td>1</td>\n",
       "      <td>'r2t</td>\n",
       "      <td>[raIt]</td>\n",
       "      <td>r2t</td>\n",
       "      <td>raIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01_0100_US_KNBC_Channel_4_News</td>\n",
       "      <td>right</td>\n",
       "      <td>38.320000</td>\n",
       "      <td>38.540000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188603</td>\n",
       "      <td>True</td>\n",
       "      <td>r2t</td>\n",
       "      <td>r2t</td>\n",
       "      <td>41655</td>\n",
       "      <td>1</td>\n",
       "      <td>'r2t</td>\n",
       "      <td>[raIt]</td>\n",
       "      <td>r2t</td>\n",
       "      <td>raIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01_0100_US_KNBC_Channel_4_News</td>\n",
       "      <td>right</td>\n",
       "      <td>139.660000</td>\n",
       "      <td>139.880000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>True</td>\n",
       "      <td>r2t</td>\n",
       "      <td>r2t</td>\n",
       "      <td>41655</td>\n",
       "      <td>1</td>\n",
       "      <td>'r2t</td>\n",
       "      <td>[raIt]</td>\n",
       "      <td>r2t</td>\n",
       "      <td>raIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01_0100_US_KNBC_Channel_4_News</td>\n",
       "      <td>right</td>\n",
       "      <td>277.530000</td>\n",
       "      <td>277.750000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188603</td>\n",
       "      <td>True</td>\n",
       "      <td>r2t</td>\n",
       "      <td>r2t</td>\n",
       "      <td>41655</td>\n",
       "      <td>1</td>\n",
       "      <td>'r2t</td>\n",
       "      <td>[raIt]</td>\n",
       "      <td>r2t</td>\n",
       "      <td>raIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01_0100_US_KNBC_Channel_4_News</td>\n",
       "      <td>right</td>\n",
       "      <td>414.939999</td>\n",
       "      <td>415.159999</td>\n",
       "      <td>0.22</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188603</td>\n",
       "      <td>True</td>\n",
       "      <td>r2t</td>\n",
       "      <td>r2t</td>\n",
       "      <td>41655</td>\n",
       "      <td>1</td>\n",
       "      <td>'r2t</td>\n",
       "      <td>[raIt]</td>\n",
       "      <td>r2t</td>\n",
       "      <td>raIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530336</th>\n",
       "      <td>2016-09-20_0030_US_KCET_Nightly_Business_Report</td>\n",
       "      <td>franc</td>\n",
       "      <td>1146.660000</td>\n",
       "      <td>1147.190000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>low-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>True</td>\n",
       "      <td>frANk</td>\n",
       "      <td>fr{Nk</td>\n",
       "      <td>515</td>\n",
       "      <td>1</td>\n",
       "      <td>'fr{Nk</td>\n",
       "      <td>[fr&amp;Nk]</td>\n",
       "      <td>fr{Nk</td>\n",
       "      <td>fr&amp;Nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530337</th>\n",
       "      <td>2016-11-09_1300_US_KNBC_Today_in_LA_at_5am</td>\n",
       "      <td>franc</td>\n",
       "      <td>2347.150000</td>\n",
       "      <td>2347.520000</td>\n",
       "      <td>0.37</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>True</td>\n",
       "      <td>frANk</td>\n",
       "      <td>fr{Nk</td>\n",
       "      <td>515</td>\n",
       "      <td>1</td>\n",
       "      <td>'fr{Nk</td>\n",
       "      <td>[fr&amp;Nk]</td>\n",
       "      <td>fr{Nk</td>\n",
       "      <td>fr&amp;Nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530338</th>\n",
       "      <td>2016-11-22_0200_US_KCBS_CBS_2_News_at_6PM</td>\n",
       "      <td>spayed</td>\n",
       "      <td>753.980000</td>\n",
       "      <td>754.290000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>True</td>\n",
       "      <td>sp1d</td>\n",
       "      <td>sp1d</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>'sp1d</td>\n",
       "      <td>[speId]</td>\n",
       "      <td>sp1d</td>\n",
       "      <td>speId</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530339</th>\n",
       "      <td>2016-11-30_1400_US_CNN_Newsroom</td>\n",
       "      <td>plumb</td>\n",
       "      <td>803.059999</td>\n",
       "      <td>803.339999</td>\n",
       "      <td>0.28</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>True</td>\n",
       "      <td>plVm</td>\n",
       "      <td>plVm</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>'plVm</td>\n",
       "      <td>[plVm]</td>\n",
       "      <td>plVm</td>\n",
       "      <td>plVm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530340</th>\n",
       "      <td>2016-12-18_2000_US_CNN_Newsroom_Sunday</td>\n",
       "      <td>reeks</td>\n",
       "      <td>3571.660000</td>\n",
       "      <td>3572.050000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>no-error</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>True</td>\n",
       "      <td>riks</td>\n",
       "      <td>riks</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>'riks</td>\n",
       "      <td>[ri:ks]</td>\n",
       "      <td>riks</td>\n",
       "      <td>ri:ks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530341 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source_file    word        start  \\\n",
       "0                2016-01-01_0100_US_KNBC_Channel_4_News   right    12.070000   \n",
       "1                2016-01-01_0100_US_KNBC_Channel_4_News   right    38.320000   \n",
       "2                2016-01-01_0100_US_KNBC_Channel_4_News   right   139.660000   \n",
       "3                2016-01-01_0100_US_KNBC_Channel_4_News   right   277.530000   \n",
       "4                2016-01-01_0100_US_KNBC_Channel_4_News   right   414.939999   \n",
       "...                                                 ...     ...          ...   \n",
       "530336  2016-09-20_0030_US_KCET_Nightly_Business_Report   franc  1146.660000   \n",
       "530337       2016-11-09_1300_US_KNBC_Today_in_LA_at_5am   franc  2347.150000   \n",
       "530338        2016-11-22_0200_US_KCBS_CBS_2_News_at_6PM  spayed   753.980000   \n",
       "530339                  2016-11-30_1400_US_CNN_Newsroom   plumb   803.059999   \n",
       "530340           2016-12-18_2000_US_CNN_Newsroom_Sunday   reeks  3571.660000   \n",
       "\n",
       "                end  duration       label_type mp4_error aac_error  \\\n",
       "0         12.280000      0.21  high-confidence  no-error  no-error   \n",
       "1         38.540000      0.22  high-confidence  no-error  no-error   \n",
       "2        139.880000      0.22  high-confidence  no-error  no-error   \n",
       "3        277.750000      0.22  high-confidence  no-error  no-error   \n",
       "4        415.159999      0.22  high-confidence  no-error  no-error   \n",
       "...             ...       ...              ...       ...       ...   \n",
       "530336  1147.190000      0.53   low-confidence  no-error  no-error   \n",
       "530337  2347.520000      0.37  high-confidence  no-error  no-error   \n",
       "530338   754.290000      0.31  high-confidence  no-error  no-error   \n",
       "530339   803.339999      0.28  high-confidence  no-error  no-error   \n",
       "530340  3572.050000      0.39  high-confidence  no-error  no-error   \n",
       "\n",
       "       aac2wav_error eafgz_error  ... cond_pred_next  has_pair   pron  \\\n",
       "0           no-error    no-error  ...       0.017207      True    r2t   \n",
       "1           no-error    no-error  ...       0.188603      True    r2t   \n",
       "2           no-error    no-error  ...       0.000264      True    r2t   \n",
       "3           no-error    no-error  ...       0.188603      True    r2t   \n",
       "4           no-error    no-error  ...       0.188603      True    r2t   \n",
       "...              ...         ...  ...            ...       ...    ...   \n",
       "530336      no-error    no-error  ...       0.000005      True  frANk   \n",
       "530337      no-error    no-error  ...       0.000005      True  frANk   \n",
       "530338      no-error    no-error  ...       0.000002      True   sp1d   \n",
       "530339      no-error    no-error  ...       0.001192      True   plVm   \n",
       "530340      no-error    no-error  ...       0.000003      True   riks   \n",
       "\n",
       "        celexPhon pron_frequency  is_max    disc      clx  disc_no_bound  \\\n",
       "0             r2t          41655       1    'r2t   [raIt]            r2t   \n",
       "1             r2t          41655       1    'r2t   [raIt]            r2t   \n",
       "2             r2t          41655       1    'r2t   [raIt]            r2t   \n",
       "3             r2t          41655       1    'r2t   [raIt]            r2t   \n",
       "4             r2t          41655       1    'r2t   [raIt]            r2t   \n",
       "...           ...            ...     ...     ...      ...            ...   \n",
       "530336      fr{Nk            515       1  'fr{Nk  [fr&Nk]          fr{Nk   \n",
       "530337      fr{Nk            515       1  'fr{Nk  [fr&Nk]          fr{Nk   \n",
       "530338       sp1d             13       1   'sp1d  [speId]           sp1d   \n",
       "530339       plVm             23       1   'plVm   [plVm]           plVm   \n",
       "530340       riks              7       1   'riks  [ri:ks]           riks   \n",
       "\n",
       "       clx_no_bound  \n",
       "0              raIt  \n",
       "1              raIt  \n",
       "2              raIt  \n",
       "3              raIt  \n",
       "4              raIt  \n",
       "...             ...  \n",
       "530336        fr&Nk  \n",
       "530337        fr&Nk  \n",
       "530338        speId  \n",
       "530339         plVm  \n",
       "530340        ri:ks  \n",
       "\n",
       "[530341 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_character_code = pd.read_csv(\"Data/celex_phonetic_character_code_berndt1987.csv\", delimiter=\";\")\n",
    "berndt_conditional_probs = pd.read_csv(\"Data/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyboard_compatible_phonetic_symbol</th>\n",
       "      <th>CELEX</th>\n",
       "      <th>g2p(ARPAbet)</th>\n",
       "      <th>DISC</th>\n",
       "      <th>Example</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ay</td>\n",
       "      <td>eI</td>\n",
       "      <td>EY1,EY2</td>\n",
       "      <td>1</td>\n",
       "      <td>ale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>AE0,AE1,AE2</td>\n",
       "      <td>{</td>\n",
       "      <td>add</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee</td>\n",
       "      <td>i:</td>\n",
       "      <td>IY0, IY1</td>\n",
       "      <td>i</td>\n",
       "      <td>bee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eh</td>\n",
       "      <td>E</td>\n",
       "      <td>EH0,EH1,EH2</td>\n",
       "      <td>E</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>er</td>\n",
       "      <td>@r*</td>\n",
       "      <td>ER0,ER1,ER2</td>\n",
       "      <td>@R</td>\n",
       "      <td>father</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>aI</td>\n",
       "      <td>AY0,AY1,AY2</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ih</td>\n",
       "      <td>I</td>\n",
       "      <td>IH0,IH1,IH2</td>\n",
       "      <td>I</td>\n",
       "      <td>bin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>@U</td>\n",
       "      <td>OW0,OW1,OW2</td>\n",
       "      <td>5</td>\n",
       "      <td>boat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ah</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1,AA2</td>\n",
       "      <td>Q</td>\n",
       "      <td>cot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aw</td>\n",
       "      <td>O</td>\n",
       "      <td>AO1,AO2</td>\n",
       "      <td>Q</td>\n",
       "      <td>soft</td>\n",
       "      <td>AA1 in soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oo</td>\n",
       "      <td>u:</td>\n",
       "      <td>UW0,UW1</td>\n",
       "      <td>u</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u</td>\n",
       "      <td>U</td>\n",
       "      <td>UH1</td>\n",
       "      <td>U</td>\n",
       "      <td>hook</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yu</td>\n",
       "      <td>ju:</td>\n",
       "      <td>YUW1</td>\n",
       "      <td>ju</td>\n",
       "      <td>unite</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>uh+</td>\n",
       "      <td>V</td>\n",
       "      <td>AH1</td>\n",
       "      <td>V</td>\n",
       "      <td>up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oy</td>\n",
       "      <td>OI</td>\n",
       "      <td>OY1,OY2</td>\n",
       "      <td>4</td>\n",
       "      <td>boy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>au</td>\n",
       "      <td>aU</td>\n",
       "      <td>AW0,AW1</td>\n",
       "      <td>6</td>\n",
       "      <td>out</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>uh-</td>\n",
       "      <td>@</td>\n",
       "      <td>AH0</td>\n",
       "      <td>@</td>\n",
       "      <td>about</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>but</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>d</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>fan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>G</td>\n",
       "      <td>g</td>\n",
       "      <td>go</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>HH</td>\n",
       "      <td>h</td>\n",
       "      <td>hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dj</td>\n",
       "      <td>dZ</td>\n",
       "      <td>JH</td>\n",
       "      <td>_</td>\n",
       "      <td>joke</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>K</td>\n",
       "      <td>k</td>\n",
       "      <td>keep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>L</td>\n",
       "      <td>l</td>\n",
       "      <td>late</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>M</td>\n",
       "      <td>m</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>n</td>\n",
       "      <td>nod</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>P</td>\n",
       "      <td>p</td>\n",
       "      <td>pen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>r</td>\n",
       "      <td>rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>sue</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>t</td>\n",
       "      <td>two</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>V</td>\n",
       "      <td>v</td>\n",
       "      <td>van</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "      <td>wait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>y</td>\n",
       "      <td>j</td>\n",
       "      <td>Y</td>\n",
       "      <td>j</td>\n",
       "      <td>yet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>z</td>\n",
       "      <td>z</td>\n",
       "      <td>Z</td>\n",
       "      <td>z</td>\n",
       "      <td>zone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tch</td>\n",
       "      <td>tS</td>\n",
       "      <td>CH</td>\n",
       "      <td>J</td>\n",
       "      <td>chin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ks</td>\n",
       "      <td>ks</td>\n",
       "      <td>KS</td>\n",
       "      <td>ks</td>\n",
       "      <td>ox</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gz</td>\n",
       "      <td>gz</td>\n",
       "      <td>GZ</td>\n",
       "      <td>gz</td>\n",
       "      <td>exist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kw</td>\n",
       "      <td>kw</td>\n",
       "      <td>KW</td>\n",
       "      <td>kw</td>\n",
       "      <td>quit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ul</td>\n",
       "      <td>l,</td>\n",
       "      <td>AH0-L</td>\n",
       "      <td>P</td>\n",
       "      <td>puddle</td>\n",
       "      <td>AH0-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>um</td>\n",
       "      <td>@m</td>\n",
       "      <td>AH0-M</td>\n",
       "      <td>@m</td>\n",
       "      <td>chasm</td>\n",
       "      <td>AHO-M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>un</td>\n",
       "      <td>n,</td>\n",
       "      <td>AH0-N</td>\n",
       "      <td>H</td>\n",
       "      <td>pardon</td>\n",
       "      <td>AHO-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ng</td>\n",
       "      <td>N</td>\n",
       "      <td>NG</td>\n",
       "      <td>N</td>\n",
       "      <td>sing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sh</td>\n",
       "      <td>S</td>\n",
       "      <td>SH</td>\n",
       "      <td>S</td>\n",
       "      <td>she</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>th-</td>\n",
       "      <td>T</td>\n",
       "      <td>TH</td>\n",
       "      <td>T</td>\n",
       "      <td>thin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>th+</td>\n",
       "      <td>D</td>\n",
       "      <td>DH</td>\n",
       "      <td>D</td>\n",
       "      <td>then</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>zh</td>\n",
       "      <td>Z</td>\n",
       "      <td>ZH</td>\n",
       "      <td>Z</td>\n",
       "      <td>rouge</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>honest</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyboard_compatible_phonetic_symbol CELEX g2p(ARPAbet) DISC Example  \\\n",
       "0                                   ay    eI      EY1,EY2    1     ale   \n",
       "1                                   ae     &  AE0,AE1,AE2    {     add   \n",
       "2                                   ee    i:     IY0, IY1    i     bee   \n",
       "3                                   eh     E  EH0,EH1,EH2    E     end   \n",
       "4                                   er   @r*  ER0,ER1,ER2   @R  father   \n",
       "5                                   ai    aI  AY0,AY1,AY2    2    high   \n",
       "6                                   ih     I  IH0,IH1,IH2    I     bin   \n",
       "7                                    o    @U  OW0,OW1,OW2    5    boat   \n",
       "8                                   ah     O      AA1,AA2    Q     cot   \n",
       "9                                   aw     O      AO1,AO2    Q    soft   \n",
       "10                                  oo    u:      UW0,UW1    u    food   \n",
       "11                                   u     U          UH1    U    hook   \n",
       "12                                  yu   ju:         YUW1   ju   unite   \n",
       "13                                 uh+     V          AH1    V      up   \n",
       "14                                  oy    OI      OY1,OY2    4     boy   \n",
       "15                                  au    aU      AW0,AW1    6     out   \n",
       "16                                 uh-     @          AH0    @   about   \n",
       "17                                   b     b            B    b     but   \n",
       "18                                   d     d            D    d     day   \n",
       "19                                   f     f            F    f     fan   \n",
       "20                                   g     g            G    g      go   \n",
       "21                                   h     h           HH    h     hat   \n",
       "22                                  dj    dZ           JH    _    joke   \n",
       "23                                   k     k            K    k    keep   \n",
       "24                                   l     l            L    l    late   \n",
       "25                                   m     m            M    m     man   \n",
       "26                                   n     n            N    n     nod   \n",
       "27                                   p     p            P    p     pen   \n",
       "28                                   r     r            R    r     rat   \n",
       "29                                   s     s            S    s     sue   \n",
       "30                                   t     t            T    t     two   \n",
       "31                                   v     v            V    v     van   \n",
       "32                                   w     w            W    w    wait   \n",
       "33                                   y     j            Y    j     yet   \n",
       "34                                   z     z            Z    z    zone   \n",
       "35                                 tch    tS           CH    J    chin   \n",
       "36                                  ks    ks           KS   ks      ox   \n",
       "37                                  gz    gz           GZ   gz   exist   \n",
       "38                                  kw    kw           KW   kw    quit   \n",
       "39                                  ul    l,        AH0-L    P  puddle   \n",
       "40                                  um    @m        AH0-M   @m   chasm   \n",
       "41                                  un    n,        AH0-N    H  pardon   \n",
       "42                                  ng     N           NG    N    sing   \n",
       "43                                  sh     S           SH    S     she   \n",
       "44                                 th-     T           TH    T    thin   \n",
       "45                                 th+     D           DH    D    then   \n",
       "46                                  zh     Z           ZH    Z   rouge   \n",
       "47                                  nl   NaN          NaN  NaN  honest   \n",
       "\n",
       "           Note  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9   AA1 in soft  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  \n",
       "18          NaN  \n",
       "19          NaN  \n",
       "20          NaN  \n",
       "21          NaN  \n",
       "22          NaN  \n",
       "23          NaN  \n",
       "24          NaN  \n",
       "25          NaN  \n",
       "26          NaN  \n",
       "27          NaN  \n",
       "28          NaN  \n",
       "29          NaN  \n",
       "30          NaN  \n",
       "31          NaN  \n",
       "32          NaN  \n",
       "33          NaN  \n",
       "34          NaN  \n",
       "35          NaN  \n",
       "36          NaN  \n",
       "37          NaN  \n",
       "38          NaN  \n",
       "39        AH0-L  \n",
       "40        AHO-M  \n",
       "41        AHO-N  \n",
       "42          NaN  \n",
       "43          NaN  \n",
       "44          NaN  \n",
       "45          NaN  \n",
       "46          NaN  \n",
       "47          NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_character_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_file', 'word', 'start', 'end', 'duration', 'label_type',\n",
       "       'mp4_error', 'aac_error', 'aac2wav_error', 'eafgz_error', 'seg_error',\n",
       "       'preceding_pause', 'subsequent_pause', 'word_frequency', 'prev_word',\n",
       "       'prev_word_frequency', 'next_word', 'next_word_frequency',\n",
       "       'letter_length', 'prev_word_string', 'next_word_string',\n",
       "       'prev_word_string_frequency', 'next_word_string_frequency',\n",
       "       'cond_pred_prev', 'cond_pred_next', 'has_pair', 'pron', 'celexPhon',\n",
       "       'pron_frequency', 'is_max', 'disc', 'clx', 'disc_no_bound',\n",
       "       'clx_no_bound'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones_in_data_celex_mapped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disc</th>\n",
       "      <th>clx</th>\n",
       "      <th>disc_no_bound</th>\n",
       "      <th>clx_no_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39337</th>\n",
       "      <td>gym</td>\n",
       "      <td>'_Im</td>\n",
       "      <td>[dZIm]</td>\n",
       "      <td>_Im</td>\n",
       "      <td>dZIm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  disc     clx disc_no_bound clx_no_bound\n",
       "39337  gym  '_Im  [dZIm]           _Im         dZIm"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celex_phonology_dict[celex_phonology_dict.word == \"gym\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet_encoded_words = get_ARPAbet_phonetic_transcription(homophones_in_data_celex_mapped.word)\n",
    "arpabet_used_in_data = set(sum(arpabet_encoded_words,[]))\n",
    "\n",
    "#disc_encoded_words = list(homophones_in_data_celex_mapped.disc[pd.notnull(homophones_in_data_celex_mapped.disc)].str.replace(\"'\",\"\").str.split(\"-\"))\n",
    "#disc_used_in_data = set(sum(disc_encoded_words,[]))\n",
    "\n",
    "#clx_encoded_words = list(homophones_in_data_celex_mapped.clx[pd.notnull(homophones_in_data_celex_mapped.clx)].str.replace(\"[\",\"\").str.split(\"]\"))\n",
    "#clx_used_in_data = set(filter(lambda x: x != \"\",sum(clx_encoded_words,[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'AO1', 'EH0', 'ER1', 'EY2', 'IH0', 'IY0', 'OW0', 'OW2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpabet_used_in_data - set(berndt_character_code[\"g2p(ARPAbet)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_characters_used_in_data = set(''.join(list(disc_used_in_data)))\n",
    "disc_characters_for_berndts_encoding = set(''.join([str(i) for i in list(set(berndt_character_code.DISC))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clx_characters_used_in_data = set(''.join(list(clx_used_in_data)))\n",
    "clx_characters_for_berndts_encoding = set(''.join([str(i) for i in list(set(berndt_character_code.CELEX))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#', '$', '7', '8'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_characters_used_in_data - disc_characters_for_berndts_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clx_characters_used_in_data - clx_characters_for_berndts_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: m$ ['m$', 'nIN'] morning\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: h7R ['h7R'] here\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: k$s ['k$s'] course\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: h7R ['h7R'] hear\n",
      "Missing: b8R ['b8R'] bear\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: b$d ['b$d'] board\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: p#st ['p#st'] past\n",
      "Missing: f8R ['f8R'] fair\n",
      "Missing: h$l ['h$l'] hall\n",
      "Missing: p#st ['p#st'] passed\n",
      "Missing: p#st ['p#st'] passed\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(disc_encoded_words):\n",
    "    for j in word:\n",
    "        if any(x in j for x in ['#', '$', '7', '8']):\n",
    "            print(\"Missing:\", j, word, homophones_in_data_celex_mapped.word[pd.notnull(homophones_in_data_celex_mapped.disc)].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] past\n",
      "Missing: pA:st ['pA:st', ''] passed\n",
      "Missing: pA:st ['pA:st', ''] passed\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(clx_encoded_words):\n",
    "    for j in word:\n",
    "        if any(x in j for x in ['A']):\n",
    "            print(\"Missing:\", j, word, homophones_in_data_celex_mapped.word[pd.notnull(homophones_in_data_celex_mapped.clx)].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "Missing: EY2 ['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(arpabet_encoded_words):\n",
    "    for j in word:\n",
    "        if j in [\"EY2\"]:\n",
    "            print(\"Missing:\", j, word, homophones_in_data.word.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'AO1', 'EH0', 'ER1', 'EY2', 'IY0', 'OW0', 'OW2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ER1: heard, hurts\n",
    "EH0: ensure\n",
    "EY2: fiance\n",
    "AA2: lumbar\n",
    "OW0 : cocoa\n",
    "OW2: coco\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EY1', 'L'],\n",
       " ['AE1', 'D'],\n",
       " ['B', 'IY1'],\n",
       " ['EH1', 'N', 'D'],\n",
       " ['F', 'AA1', 'DH', 'ER0'],\n",
       " ['HH', 'AY1'],\n",
       " ['B', 'IH1', 'N'],\n",
       " ['B', 'OW1', 'T'],\n",
       " ['K', 'AA1', 'T'],\n",
       " ['S', 'AA1', 'F', 'T'],\n",
       " ['F', 'UW1', 'D'],\n",
       " ['HH', 'UH1', 'K'],\n",
       " ['Y', 'UW1', 'N', 'AY2', 'T'],\n",
       " ['AH1', 'P'],\n",
       " ['B', 'OY1'],\n",
       " ['AW1', 'T'],\n",
       " ['AH0', 'B', 'AW1', 'T'],\n",
       " ['B', 'AH1', 'T'],\n",
       " ['D', 'EY1'],\n",
       " ['F', 'AE1', 'N'],\n",
       " ['G', 'OW1'],\n",
       " ['HH', 'AE1', 'T'],\n",
       " ['JH', 'OW1', 'K'],\n",
       " ['K', 'IY1', 'P'],\n",
       " ['L', 'EY1', 'T'],\n",
       " ['M', 'AE1', 'N'],\n",
       " ['N', 'AA1', 'D'],\n",
       " ['P', 'EH1', 'N'],\n",
       " ['R', 'AE1', 'T'],\n",
       " ['S', 'UW1'],\n",
       " ['T', 'UW1'],\n",
       " ['V', 'AE1', 'N'],\n",
       " ['W', 'EY1', 'T'],\n",
       " ['Y', 'EH1', 'T'],\n",
       " ['Z', 'OW1', 'N'],\n",
       " ['CH', 'IH1', 'N'],\n",
       " ['AA1', 'K', 'S'],\n",
       " ['IH0', 'G', 'Z', 'IH1', 'S', 'T'],\n",
       " ['K', 'W', 'IH1', 'T'],\n",
       " ['P', 'AH1', 'D', 'AH0', 'L'],\n",
       " ['K', 'AE1', 'Z', 'AH0', 'M'],\n",
       " ['P', 'AA1', 'R', 'D', 'AH0', 'N'],\n",
       " ['S', 'IH1', 'NG'],\n",
       " ['SH', 'IY1'],\n",
       " ['TH', 'IH1', 'N'],\n",
       " ['DH', 'EH1', 'N'],\n",
       " ['R', 'UW1', 'ZH'],\n",
       " ['AA1', 'N', 'AH0', 'S', 'T']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ARPAbet_phonetic_transcription(berndt_character_code.Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IH0', 'G', 'Z', 'IH1', 'S', 'T'] exist\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(get_ARPAbet_phonetic_transcription(berndt_character_code.Example)):\n",
    "    for j in word:\n",
    "        if j in ['IH0']:\n",
    "            print(word, berndt_character_code.Example[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R', 'IH1', 'NG', 'IH0', 'NG']]\n",
      "[['B', 'IH1', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"ringing\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bin\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'IY1']]\n",
      "[['CH', 'IH1', 'L', 'IY0']]\n",
      "[['G', 'R', 'IY1', 'D', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"bee\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"chilly\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"greedy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', 'AA1', 'F', 'T']]\n",
      "[['B', 'AO1', 'R', 'D']]\n",
      "[['K', 'AO1', 'R', 'S']]\n",
      "[['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"soft\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"board\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"course\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"extraordinary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EH0', 'N', 'SH', 'UH1', 'R']]\n",
      "[['EH1', 'N', 'D', 'ER0', 'AH0', 'N', 'S']]\n",
      "[['EH0', 'N', 'G', 'EY1', 'JH']]\n",
      "[['EH0', 'N', 'EY1', 'B', 'AH0', 'L']]\n",
      "[['EH1', 'N', 'D']]\n",
      "[['EH1', 'JH']]\n",
      "[['EH1', 'N', 'T', 'ER0']]\n",
      "[['EH0', 'N', 'R', 'UW1', 'T', 'UW2', 'D']]\n",
      "[['AA1', 'N', 'K', 'AO2', 'R']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"ensure\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"endurance\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"engage\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enable\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"end\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"edge\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enter\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"enrooted\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"encore\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ER1', 'N']]\n",
      "[['F', 'AA1', 'DH', 'ER0']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"earn\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"father\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F', 'IY0', 'AA1', 'N', 'S', 'EY2']]\n",
      "[['EH1', 'JH', 'AH0', 'K', 'EY2', 'T']]\n",
      "[['IH0', 'G', 'Z', 'AE1', 'JH', 'ER0', 'EY2', 'T']]\n",
      "[['S', 'ER1', 'V', 'EY2']]\n",
      "[['B', 'EY1']]\n",
      "[['K', 'AH0', 'N', 'V', 'EY1']]\n",
      "[['P', 'R', 'EY1']]\n",
      "[['G', 'R', 'EY1']]\n",
      "[['P', 'ER0', 'V', 'EY1']]\n",
      "[['TH', 'ER1', 'Z', 'D', 'EY2']]\n",
      "[['D', 'EY1']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"fiance\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"educate\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"exaggerate\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"survey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bay\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"convey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"prey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"gray\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"purvey\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"thursday\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"day\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F', 'AA1', 'L', 'OW0', 'IH0', 'NG']]\n",
      "[['B', 'Y', 'UH1', 'R', 'OW0']]\n",
      "[['CH', 'EH1', 'L', 'OW0']]\n",
      "[['AO1', 'L', 'S', 'OW0']]\n",
      "[['K', 'R', 'IH0', 'SH', 'EH1', 'N', 'D', 'OW0']]\n",
      "[['G', 'OW1', 'T']]\n",
      "[['K', 'OW1', 'K', 'OW2']]\n",
      "[['B', 'OW1', 'T']]\n",
      "[['AW1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"following\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bureau\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cello\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"also\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"crescendo\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"goat\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"coco\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"boat\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"out\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L', 'AH1', 'M', 'B', 'AA2', 'R']]\n",
      "[['L', 'AA1', 'R', 'JH']]\n",
      "[['F', 'AA1', 'DH', 'ER0']]\n",
      "[['K', 'AA1', 'T']]\n",
      "[['K', 'AA1', 'M', 'AH0']]\n",
      "[['K', 'AA1', 'M', 'AH0']]\n",
      "[['B', 'AA1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"lumbar\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"large\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"father\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cot\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"comma\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"comma\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"bot\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', 'AA1', 'F', 'T']]\n",
      "[['K', 'AA1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"soft\"]))\n",
    "print(get_ARPAbet_phonetic_transcription([\"cot\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(get_ARPAbet_phonetic_transcription(berndt_character_code.Example)):\n",
    "    for j in word:\n",
    "        if j in ['IH0']:\n",
    "            print(word, berndt_character_code.Example[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_conditional_probs_words = get_ARPAbet_phonetic_transcription(berndt_conditional_probs.Example)\n",
    "arpabet_used_in_bernd_examples = set(sum(berndt_conditional_probs_words,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 AO1 ['AO1', 'L', 'S', 'OW0'] also\n",
      "11 AO1 ['AO1', 'R', 'AH0', 'N', 'JH'] orange\n",
      "13 AO1 ['F', 'AO1', 'L', 'S'] false\n",
      "27 AO1 ['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0'] extraordinary\n",
      "28 AO1 ['F', 'AO1', 'S', 'AH0', 'T'] faucet\n",
      "30 AO1 ['T', 'AO1', 'P'] taupe \n",
      "31 AO1 ['IH0', 'P', 'AO1', 'L', 'AH0', 'T'] epaulet\n",
      "33 AO1 ['M', 'AO1', 'V'] mauve\n",
      "36 AO1 ['L', 'AO1'] law\n",
      "73 AO1 ['F', 'AO1', 'R', 'F', 'IH0', 'T'] forfeit\n",
      "127 AO1 ['AO1', 'F'] off\n",
      "137 AO1 ['G', 'AO1', 'N'] gone\n",
      "142 AO1 ['B', 'R', 'AO1', 'D'] broad\n",
      "143 AO1 ['K', 'AO1', 'R', 'S'] coarse\n",
      "150 AO1 ['T', 'AO1', 'R', 'T', 'AH0', 'S'] tortoise\n",
      "153 AO1 ['D', 'AO1', 'R'] door\n",
      "155 AO1 ['IH0', 'N', 'AO1', 'R', 'M', 'AH0', 'S'] enormous\n",
      "158 AO1 ['F', 'AO1', 'R'] four\n",
      "164 AO1 ['K', 'AO1', 'R', 'S'] course\n",
      "203 AO1 ['S', 'T', 'AO1', 'R', 'IY0'] story\n",
      "223 AO1 ['K', 'AO1', 'R', 'AH0', 'S'] chorus\n",
      "237 AO1 ['K', 'AO1', 'R', 'JH', 'AH0', 'L'] cordial\n",
      "241 AO1 ['SH', 'AO1', 'R', 'T', 'AH0', 'N'] shorten\n",
      "246 AO1 ['AO1', 'F', 'AH0', 'N'] often\n",
      "269 AO1 ['T', 'AO1', 'K'] talk\n",
      "270 AO1 ['AO1', 'L'] all\n",
      "319 AO1 ['S', 'AO1', 'R', 'D'] sword\n",
      "324 AO1 ['M', 'AO1', 'R', 'G', 'AH0', 'JH'] mortgage\n",
      "325 AO1 ['TH', 'AO1'] thaw\n",
      "341 AO1 ['W', 'AO1', 'L', 'T', 'S'] waltz\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(berndt_conditional_probs_words):\n",
    "    for j in word:\n",
    "        if j in [\"AO1\"]:\n",
    "            print(i,j, word, berndt_conditional_probs.Example.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA2', 'OW2'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpabet_used_in_data - arpabet_used_in_bernd_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Keyboard compatible phonetic symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_character_code = pd.read_csv(\"Data/celex_phonetic_character_code_berndt1987.csv\", delimiter=\";\")\n",
    "berndt_conditional_probs = pd.read_csv(\"Data/Conditional_Probabilities_for_Grapheme-to-Phoneme_Correspondences_Berndt1987.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_conditional_probs_words = get_ARPAbet_phonetic_transcription(berndt_conditional_probs.Example)\n",
    "arpabet_used_in_bernd_examples = set(sum(berndt_conditional_probs_words,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyboard_compatible_phonetic_symbol</th>\n",
       "      <th>CELEX</th>\n",
       "      <th>g2p(ARPAbet)</th>\n",
       "      <th>DISC</th>\n",
       "      <th>Example</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ay</td>\n",
       "      <td>eI</td>\n",
       "      <td>EY1,EY2</td>\n",
       "      <td>1</td>\n",
       "      <td>ale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>AE0,AE1,AE2</td>\n",
       "      <td>{</td>\n",
       "      <td>add</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee</td>\n",
       "      <td>i:</td>\n",
       "      <td>IY0, IY1</td>\n",
       "      <td>i</td>\n",
       "      <td>bee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eh</td>\n",
       "      <td>E</td>\n",
       "      <td>EH0,EH1,EH2</td>\n",
       "      <td>E</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>er</td>\n",
       "      <td>@r*</td>\n",
       "      <td>ER0,ER1,ER2</td>\n",
       "      <td>@R</td>\n",
       "      <td>father</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>aI</td>\n",
       "      <td>AY0,AY1,AY2</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ih</td>\n",
       "      <td>I</td>\n",
       "      <td>IH0,IH1,IH2</td>\n",
       "      <td>I</td>\n",
       "      <td>bin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>@U</td>\n",
       "      <td>OW0,OW1,OW2</td>\n",
       "      <td>5</td>\n",
       "      <td>boat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ah</td>\n",
       "      <td>O</td>\n",
       "      <td>AA1,AA2</td>\n",
       "      <td>Q</td>\n",
       "      <td>cot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aw</td>\n",
       "      <td>O</td>\n",
       "      <td>AO1,AO2</td>\n",
       "      <td>Q</td>\n",
       "      <td>soft</td>\n",
       "      <td>AA1 in soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oo</td>\n",
       "      <td>u:</td>\n",
       "      <td>UW0,UW1</td>\n",
       "      <td>u</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u</td>\n",
       "      <td>U</td>\n",
       "      <td>UH1</td>\n",
       "      <td>U</td>\n",
       "      <td>hook</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yu</td>\n",
       "      <td>ju:</td>\n",
       "      <td>YUW1</td>\n",
       "      <td>ju</td>\n",
       "      <td>unite</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>uh+</td>\n",
       "      <td>V</td>\n",
       "      <td>AH1</td>\n",
       "      <td>V</td>\n",
       "      <td>up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oy</td>\n",
       "      <td>OI</td>\n",
       "      <td>OY1,OY2</td>\n",
       "      <td>4</td>\n",
       "      <td>boy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>au</td>\n",
       "      <td>aU</td>\n",
       "      <td>AW0,AW1</td>\n",
       "      <td>6</td>\n",
       "      <td>out</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>uh-</td>\n",
       "      <td>@</td>\n",
       "      <td>AH0</td>\n",
       "      <td>@</td>\n",
       "      <td>about</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>but</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>d</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>fan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>G</td>\n",
       "      <td>g</td>\n",
       "      <td>go</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>HH</td>\n",
       "      <td>h</td>\n",
       "      <td>hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dj</td>\n",
       "      <td>dZ</td>\n",
       "      <td>JH</td>\n",
       "      <td>_</td>\n",
       "      <td>joke</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>K</td>\n",
       "      <td>k</td>\n",
       "      <td>keep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>L</td>\n",
       "      <td>l</td>\n",
       "      <td>late</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>M</td>\n",
       "      <td>m</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>n</td>\n",
       "      <td>nod</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>P</td>\n",
       "      <td>p</td>\n",
       "      <td>pen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>r</td>\n",
       "      <td>rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>sue</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>t</td>\n",
       "      <td>two</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>V</td>\n",
       "      <td>v</td>\n",
       "      <td>van</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "      <td>wait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>y</td>\n",
       "      <td>j</td>\n",
       "      <td>Y</td>\n",
       "      <td>j</td>\n",
       "      <td>yet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>z</td>\n",
       "      <td>z</td>\n",
       "      <td>Z</td>\n",
       "      <td>z</td>\n",
       "      <td>zone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tch</td>\n",
       "      <td>tS</td>\n",
       "      <td>CH</td>\n",
       "      <td>J</td>\n",
       "      <td>chin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ks</td>\n",
       "      <td>ks</td>\n",
       "      <td>KS</td>\n",
       "      <td>ks</td>\n",
       "      <td>ox</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gz</td>\n",
       "      <td>gz</td>\n",
       "      <td>GZ</td>\n",
       "      <td>gz</td>\n",
       "      <td>exist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kw</td>\n",
       "      <td>kw</td>\n",
       "      <td>KW</td>\n",
       "      <td>kw</td>\n",
       "      <td>quit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ul</td>\n",
       "      <td>l,</td>\n",
       "      <td>AH0-L</td>\n",
       "      <td>P</td>\n",
       "      <td>puddle</td>\n",
       "      <td>AH0-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>um</td>\n",
       "      <td>@m</td>\n",
       "      <td>AH0-M</td>\n",
       "      <td>@m</td>\n",
       "      <td>chasm</td>\n",
       "      <td>AHO-M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>un</td>\n",
       "      <td>n,</td>\n",
       "      <td>AH0-N</td>\n",
       "      <td>H</td>\n",
       "      <td>pardon</td>\n",
       "      <td>AHO-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ng</td>\n",
       "      <td>N</td>\n",
       "      <td>NG</td>\n",
       "      <td>N</td>\n",
       "      <td>sing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sh</td>\n",
       "      <td>S</td>\n",
       "      <td>SH</td>\n",
       "      <td>S</td>\n",
       "      <td>she</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>th-</td>\n",
       "      <td>T</td>\n",
       "      <td>TH</td>\n",
       "      <td>T</td>\n",
       "      <td>thin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>th+</td>\n",
       "      <td>D</td>\n",
       "      <td>DH</td>\n",
       "      <td>D</td>\n",
       "      <td>then</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>zh</td>\n",
       "      <td>Z</td>\n",
       "      <td>ZH</td>\n",
       "      <td>Z</td>\n",
       "      <td>rouge</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>honest</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyboard_compatible_phonetic_symbol CELEX g2p(ARPAbet) DISC Example  \\\n",
       "0                                   ay    eI      EY1,EY2    1     ale   \n",
       "1                                   ae     &  AE0,AE1,AE2    {     add   \n",
       "2                                   ee    i:     IY0, IY1    i     bee   \n",
       "3                                   eh     E  EH0,EH1,EH2    E     end   \n",
       "4                                   er   @r*  ER0,ER1,ER2   @R  father   \n",
       "5                                   ai    aI  AY0,AY1,AY2    2    high   \n",
       "6                                   ih     I  IH0,IH1,IH2    I     bin   \n",
       "7                                    o    @U  OW0,OW1,OW2    5    boat   \n",
       "8                                   ah     O      AA1,AA2    Q     cot   \n",
       "9                                   aw     O      AO1,AO2    Q    soft   \n",
       "10                                  oo    u:      UW0,UW1    u    food   \n",
       "11                                   u     U          UH1    U    hook   \n",
       "12                                  yu   ju:         YUW1   ju   unite   \n",
       "13                                 uh+     V          AH1    V      up   \n",
       "14                                  oy    OI      OY1,OY2    4     boy   \n",
       "15                                  au    aU      AW0,AW1    6     out   \n",
       "16                                 uh-     @          AH0    @   about   \n",
       "17                                   b     b            B    b     but   \n",
       "18                                   d     d            D    d     day   \n",
       "19                                   f     f            F    f     fan   \n",
       "20                                   g     g            G    g      go   \n",
       "21                                   h     h           HH    h     hat   \n",
       "22                                  dj    dZ           JH    _    joke   \n",
       "23                                   k     k            K    k    keep   \n",
       "24                                   l     l            L    l    late   \n",
       "25                                   m     m            M    m     man   \n",
       "26                                   n     n            N    n     nod   \n",
       "27                                   p     p            P    p     pen   \n",
       "28                                   r     r            R    r     rat   \n",
       "29                                   s     s            S    s     sue   \n",
       "30                                   t     t            T    t     two   \n",
       "31                                   v     v            V    v     van   \n",
       "32                                   w     w            W    w    wait   \n",
       "33                                   y     j            Y    j     yet   \n",
       "34                                   z     z            Z    z    zone   \n",
       "35                                 tch    tS           CH    J    chin   \n",
       "36                                  ks    ks           KS   ks      ox   \n",
       "37                                  gz    gz           GZ   gz   exist   \n",
       "38                                  kw    kw           KW   kw    quit   \n",
       "39                                  ul    l,        AH0-L    P  puddle   \n",
       "40                                  um    @m        AH0-M   @m   chasm   \n",
       "41                                  un    n,        AH0-N    H  pardon   \n",
       "42                                  ng     N           NG    N    sing   \n",
       "43                                  sh     S           SH    S     she   \n",
       "44                                 th-     T           TH    T    thin   \n",
       "45                                 th+     D           DH    D    then   \n",
       "46                                  zh     Z           ZH    Z   rouge   \n",
       "47                                  nl   NaN          NaN  NaN  honest   \n",
       "\n",
       "           Note  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9   AA1 in soft  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  \n",
       "18          NaN  \n",
       "19          NaN  \n",
       "20          NaN  \n",
       "21          NaN  \n",
       "22          NaN  \n",
       "23          NaN  \n",
       "24          NaN  \n",
       "25          NaN  \n",
       "26          NaN  \n",
       "27          NaN  \n",
       "28          NaN  \n",
       "29          NaN  \n",
       "30          NaN  \n",
       "31          NaN  \n",
       "32          NaN  \n",
       "33          NaN  \n",
       "34          NaN  \n",
       "35          NaN  \n",
       "36          NaN  \n",
       "37          NaN  \n",
       "38          NaN  \n",
       "39        AH0-L  \n",
       "40        AHO-M  \n",
       "41        AHO-N  \n",
       "42          NaN  \n",
       "43          NaN  \n",
       "44          NaN  \n",
       "45          NaN  \n",
       "46          NaN  \n",
       "47          NaN  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_character_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_arpabbet_dict = {}\n",
    "for i,p in enumerate(berndt_character_code[\"g2p(ARPAbet)\"]):\n",
    "    if not p is np.nan:\n",
    "        p = p.replace(\" \",\"\").split(\",\")       \n",
    "        if len(p) > 1:\n",
    "            for p_i in p:\n",
    "                \"\"\"\n",
    "                if p_i in berndt_arpabbet_dict:\n",
    "                    value_list = berndt_arpabbet_dict[p_i]\n",
    "                    if isinstance(value_list, list): \n",
    "                        value_list += [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                    else:\n",
    "                        value_list = [value_list] + [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                    \n",
    "                    berndt_arpabbet_dict[p_i] = value_list\n",
    "                else:\n",
    "                \"\"\"\n",
    "                berndt_arpabbet_dict[p_i] = berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]\n",
    "        else:\n",
    "            \"\"\"\n",
    "            if p[0] in berndt_arpabbet_dict:\n",
    "                value_list = berndt_arpabbet_dict[p[0]]\n",
    "                if isinstance(value_list, list): \n",
    "                    value_list += [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                else:\n",
    "                    value_list = [value_list] + [berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]]\n",
    "                    \n",
    "                berndt_arpabbet_dict[p[0]] = value_list\n",
    "            else:   \n",
    "            \"\"\"\n",
    "            berndt_arpabbet_dict[p[0]] = berndt_character_code.keyboard_compatible_phonetic_symbol.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EY1': 'ay',\n",
       " 'EY2': 'ay',\n",
       " 'AE0': 'ae',\n",
       " 'AE1': 'ae',\n",
       " 'AE2': 'ae',\n",
       " 'IY0': 'ee',\n",
       " 'IY1': 'ee',\n",
       " 'EH0': 'eh',\n",
       " 'EH1': 'eh',\n",
       " 'EH2': 'eh',\n",
       " 'ER0': 'er',\n",
       " 'ER1': 'er',\n",
       " 'ER2': 'er',\n",
       " 'AY0': 'ai',\n",
       " 'AY1': 'ai',\n",
       " 'AY2': 'ai',\n",
       " 'IH0': 'ih',\n",
       " 'IH1': 'ih',\n",
       " 'IH2': 'ih',\n",
       " 'OW0': 'o',\n",
       " 'OW1': 'o',\n",
       " 'OW2': 'o',\n",
       " 'AA1': 'ah',\n",
       " 'AA2': 'ah',\n",
       " 'AO1': 'aw',\n",
       " 'AO2': 'aw',\n",
       " 'UW0': 'oo',\n",
       " 'UW1': 'oo',\n",
       " 'UH1': 'u',\n",
       " 'YUW1': 'yu',\n",
       " 'AH1': 'uh+',\n",
       " 'OY1': 'oy',\n",
       " 'OY2': 'oy',\n",
       " 'AW0': 'au',\n",
       " 'AW1': 'au',\n",
       " 'AH0': 'uh-',\n",
       " 'B': 'b',\n",
       " 'D': 'd',\n",
       " 'F': 'f',\n",
       " 'G': 'g',\n",
       " 'HH': 'h',\n",
       " 'JH': 'dj',\n",
       " 'K': 'k',\n",
       " 'L': 'l',\n",
       " 'M': 'm',\n",
       " 'N': 'n',\n",
       " 'P': 'p',\n",
       " 'R': 'r',\n",
       " 'S': 's',\n",
       " 'T': 't',\n",
       " 'V': 'v',\n",
       " 'W': 'w',\n",
       " 'Y': 'y',\n",
       " 'Z': 'z',\n",
       " 'CH': 'tch',\n",
       " 'KS': 'ks',\n",
       " 'GZ': 'gz',\n",
       " 'KW': 'kw',\n",
       " 'AH0-L': 'ul',\n",
       " 'AH0-M': 'um',\n",
       " 'AH0-N': 'un',\n",
       " 'NG': 'ng',\n",
       " 'SH': 'sh',\n",
       " 'TH': 'th-',\n",
       " 'DH': 'th+',\n",
       " 'ZH': 'zh'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_arpabbet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyboard_phonetic_symbols(arpabet_word, dictionary):\n",
    "    skip_word = False\n",
    "    keyboard_encoding = []\n",
    "    for i,p in enumerate(arpabet_word):\n",
    "        if skip_word == True:\n",
    "            skip_word = False\n",
    "        else:\n",
    "            if p == 'AH0':\n",
    "                if i<len(arpabet_word)-1:\n",
    "                    if arpabet_word[i+1] == \"L\":\n",
    "                        keyboard_encoding.append([dictionary[p + \"-\" + \"L\"],[dictionary[p],dictionary[\"L\"]]])\n",
    "                        skip_word = True\n",
    "                    elif arpabet_word[i+1] == \"M\":\n",
    "                        keyboard_encoding.append([dictionary[p + \"-\" + \"M\"],[dictionary[p],dictionary[\"M\"]]])\n",
    "                        skip_word = True\n",
    "                    elif arpabet_word[i+1] == \"N\":\n",
    "                        keyboard_encoding.append([dictionary[p + \"-\" + \"N\"],[dictionary[p],dictionary[\"N\"]]])\n",
    "                        skip_word = True\n",
    "                    else:\n",
    "                        keyboard_encoding.append(dictionary[p])\n",
    "            elif p == \"K\":\n",
    "                if i<len(arpabet_word)-1:\n",
    "                    if arpabet_word[i+1] == \"S\":\n",
    "                        keyboard_encoding.append([dictionary[p]+dictionary[\"S\"],[dictionary[p],dictionary[\"S\"]]])\n",
    "                        skip_word = True\n",
    "                    else:\n",
    "                        keyboard_encoding.append(dictionary[p])\n",
    "            else:\n",
    "                keyboard_encoding.append(dictionary[p])\n",
    "    return keyboard_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'AE1', 'B'] cab\n",
      "['k', 'ae', 'b']\n",
      "['K', 'AH0', 'N', 'AE1', 'L'] canal\n",
      "['k', ['un', ['uh-', 'n']], 'ae', 'l']\n",
      "['EY1', 'N', 'JH', 'AH0', 'L'] angel\n",
      "['ay', 'n', 'dj', ['ul', ['uh-', 'l']]]\n",
      "['W', 'AA1', 'D'] wad\n",
      "['w', 'ah', 'd']\n",
      "['AO1', 'L', 'S', 'OW0'] also\n",
      "['aw', 'l', 's', 'o']\n",
      "['K', 'AW1', 'ER0', 'D'] coward\n",
      "['k', 'au', 'er', 'd']\n",
      "['M', 'EH1', 'N', 'IY0'] many\n",
      "['m', 'eh', 'n', 'ee']\n",
      "['S', 'P', 'IH1', 'N', 'AH0', 'CH'] spinach\n",
      "['s', 'p', 'ih', 'n', 'uh-', 'tch']\n",
      "['EY1', 'T'] ate\n",
      "['ay', 't']\n",
      "['S', 'EH1', 'N', 'AH0', 'T'] senate\n",
      "['s', 'eh', 'n', 'uh-', 't']\n",
      "['M', 'AE1', 'D', 'AH0', 'M'] madame\n",
      "['m', 'ae', 'd', ['um', ['uh-', 'm']]]\n",
      "['AO1', 'R', 'AH0', 'N', 'JH'] orange\n",
      "['aw', 'r', ['un', ['uh-', 'n']], 'dj']\n",
      "['AA1', 'R'] are\n",
      "['ah', 'r']\n",
      "['F', 'AO1', 'L', 'S'] false\n",
      "['f', 'aw', 'l', 's']\n",
      "['P', 'AY1', 'R', 'AH0', 'T'] pirate\n",
      "['p', 'ai', 'r', 'uh-', 't']\n",
      "['AE1', 'L', 'JH', 'IY0'] algae\n",
      "['ae', 'l', 'dj', 'ee']\n",
      "['EH0', 'S', 'TH', 'EH1', 'T', 'IH0', 'K'] aesthetic\n",
      "['eh', 's', 'th-', 'eh', 't', 'ih']\n",
      "['D', 'AE1', 'L', 'Y', 'AH0'] dahlia\n",
      "['d', 'ae', 'l', 'y']\n",
      "['EY1', 'D'] aid \n",
      "['ay', 'd']\n",
      "['S', 'EH1', 'D'] said\n",
      "['s', 'eh', 'd']\n",
      "['K', 'AE1', 'P', 'T', 'AH0', 'N'] captain\n",
      "['k', 'ae', 'p', 't', ['un', ['uh-', 'n']]]\n",
      "['V', 'IH1', 'L', 'AH0', 'N'] villain\n",
      "['v', 'ih', 'l', ['un', ['uh-', 'n']]]\n",
      "['P', 'L', 'AE1', 'D'] plaid\n",
      "['p', 'l', 'ae', 'd']\n",
      "['EY1', 'D'] aide\n",
      "['ay', 'd']\n",
      "['M', 'IH2', 'L', 'Y', 'AH0', 'N', 'EH1', 'R'] millionaire\n",
      "['m', 'ih', 'l', 'y', ['un', ['uh-', 'n']], 'eh', 'r']\n",
      "['AY1', 'L'] aisle\n",
      "['ai', 'l']\n",
      "['S', 'T', 'R', 'EY1', 'T'] straight\n",
      "['s', 't', 'r', 'ay', 't']\n",
      "['IH0', 'K', 'S', 'T', 'R', 'AO1', 'R', 'D', 'AH0', 'N', 'EH2', 'R', 'IY0'] extraordinary\n",
      "['ih', ['ks', ['k', 's']], 't', 'r', 'aw', 'r', 'd', ['un', ['uh-', 'n']], 'eh', 'r', 'ee']\n",
      "['F', 'AO1', 'S', 'AH0', 'T'] faucet\n",
      "['f', 'aw', 's', 'uh-', 't']\n",
      "['AE1', 'N', 'T'] aunt\n",
      "['ae', 'n', 't']\n",
      "['T', 'AO1', 'P'] taupe \n",
      "['t', 'aw', 'p']\n",
      "['IH0', 'P', 'AO1', 'L', 'AH0', 'T'] epaulet\n",
      "['ih', 'p', 'aw', 'l', 'uh-', 't']\n",
      "['K', 'AA1', 'Z'] cause\n",
      "['k', 'ah', 'z']\n",
      "['M', 'AO1', 'V'] mauve\n",
      "['m', 'aw', 'v']\n",
      "['G', 'EY1', 'JH'] gauge\n",
      "['g', 'ay', 'dj']\n",
      "['K', 'AA1', 'T'] caught\n",
      "['k', 'ah', 't']\n",
      "['L', 'AO1'] law\n",
      "['l', 'aw']\n",
      "['AA1'] awe\n",
      "['ah']\n",
      "['W', 'EY1'] way\n",
      "['w', 'ay']\n",
      "['K', 'AY1', 'AE0', 'K'] kayak \n",
      "['k', 'ai', 'ae']\n",
      "['S', 'EH1', 'Z'] says\n",
      "['s', 'eh', 'z']\n",
      "['AY1'] aye \n",
      "['ai']\n",
      "['EH1', 'N', 'D'] end\n",
      "['eh', 'n', 'd']\n",
      "['B', 'EY1', 'K', 'ER0'] baker\n",
      "['b', 'ay', 'k', 'er']\n",
      "['S', 'IY1', 'N', 'Y', 'ER0'] senior\n",
      "['s', 'ee', 'n', 'y', 'er']\n",
      "['R', 'IH0', 'B', 'EH1', 'L'] rebel\n",
      "['r', 'ih', 'b', 'eh', 'l']\n",
      "['K', 'AH0', 'F', 'EY1'] cafe \n",
      "['k', 'uh-', 'f', 'ay']\n",
      "['AA1', 'N', 'K', 'AO2', 'R'] encore\n",
      "['ah', 'n', 'k', 'aw', 'r']\n",
      "['P', 'R', 'IH1', 'T', 'IY0'] pretty\n",
      "['p', 'r', 'ih', 't', 'ee']\n",
      "['AH0', 'Z', 'EY1', 'L', 'Y', 'AH0'] azalea\n",
      "['uh-', 'z', 'ay', 'l', 'y']\n",
      "['EH1', 'JH'] edge\n",
      "['eh', 'dj']\n",
      "['S', 'AY1', 'AH0', 'N', 'S'] science\n",
      "['s', 'ai', ['un', ['uh-', 'n']], 's']\n",
      "['IY1', 'V'] eve\n",
      "['ee', 'v']\n",
      "['T', 'R', 'AE1', 'V', 'ER0', 'S'] traverse\n",
      "['t', 'r', 'ae', 'v', 'er', 's']\n",
      "['F', 'EY1', 'T'] fete\n",
      "['f', 'ay', 't']\n",
      "['P', 'R', 'IH1', 'V', 'L', 'AH0', 'JH'] privilege\n",
      "['p', 'r', 'ih', 'v', 'l', 'uh-', 'dj']\n",
      "['IY1', 'T'] eat\n",
      "['ee', 't']\n",
      "['HH', 'EH1', 'D'] head\n",
      "['h', 'eh', 'd']\n",
      "['ER1', 'N'] earn\n",
      "['er', 'n']\n",
      "['HH', 'AA1', 'R', 'T'] heart\n",
      "['h', 'ah', 'r', 't']\n",
      "['B', 'R', 'EY1', 'K'] break\n",
      "['b', 'r', 'ay']\n",
      "['P', 'AE1', 'JH', 'AH0', 'N', 'T'] pageant\n",
      "['p', 'ae', 'dj', ['un', ['uh-', 'n']], 't']\n",
      "['IY1', 'Z'] ease\n",
      "['ee', 'z']\n",
      "['HH', 'ER1', 'S'] hearse\n",
      "['h', 'er', 's']\n",
      "['M', 'AY1', 'L', 'AH0', 'JH'] mileage\n",
      "['m', 'ai', 'l', 'uh-', 'dj']\n",
      "['K', 'L', 'EH1', 'N', 'Z'] cleanse\n",
      "['k', 'l', 'eh', 'n', 'z']\n",
      "['B', 'OW1'] beau\n",
      "['b', 'o']\n",
      "['B', 'Y', 'UW1', 'T', 'IY0'] beauty\n",
      "['b', 'y', 'oo', 't', 'ee']\n",
      "['B', 'IY1'] bee\n",
      "['b', 'ee']\n",
      "['B', 'IH1', 'N'] been\n",
      "['b', 'ih', 'n']\n",
      "['G', 'IY1', 'S'] geese\n",
      "['g', 'ee', 's']\n",
      "['S', 'IY1', 'L', 'IH0', 'NG'] ceiling\n",
      "['s', 'ee', 'l', 'ih', 'ng']\n",
      "['V', 'EY1', 'N'] vein\n",
      "['v', 'ay', 'n']\n",
      "['F', 'AO1', 'R', 'F', 'IH0', 'T'] forfeit\n",
      "['f', 'aw', 'r', 'f', 'ih', 't']\n",
      "['S', 'T', 'AY1', 'N'] stein\n",
      "['s', 't', 'ai', 'n']\n",
      "['HH', 'AY1', 'F', 'ER0'] heifer\n",
      "['h', 'ai', 'f', 'er']\n",
      "['S', 'AA1', 'V', 'R', 'AH0', 'N'] sovereign\n",
      "['s', 'ah', 'v', 'r', ['un', ['uh-', 'n']]]\n",
      "['S', 'IY1', 'Z'] seize\n",
      "['s', 'ee', 'z']\n",
      "['S', 'EY1', 'N', 'IY0'] seine\n",
      "['s', 'ay', 'n', 'ee']\n",
      "['EY1', 'T'] eight\n",
      "['ay', 't']\n",
      "['HH', 'AY1', 'T'] height\n",
      "['h', 'ai', 't']\n",
      "['P', 'IH1', 'JH', 'AH0', 'N'] pigeon\n",
      "['p', 'ih', 'dj', ['un', ['uh-', 'n']]]\n",
      "['L', 'EH1', 'P', 'ER0', 'D'] leopard\n",
      "['l', 'eh', 'p', 'er', 'd']\n",
      "['P', 'IY1', 'P', 'AH0', 'L'] people\n",
      "['p', 'ee', 'p', ['ul', ['uh-', 'l']]]\n",
      "['K', 'ER0', 'EY1', 'JH', 'AH0', 'S'] courageous\n",
      "['k', 'er', 'ay', 'dj', 'uh-', 's']\n",
      "['B', 'EH1', 'R', 'AH0', 'T'] beret\n",
      "['b', 'eh', 'r', 'uh-', 't']\n",
      "['F', 'Y', 'UW1', 'D'] feud\n",
      "['f', 'y', 'oo', 'd']\n",
      "['AE1', 'M', 'AH0', 'T', 'ER2'] amateur\n",
      "['ae', 'm', 'uh-', 't', 'er']\n",
      "['S', 'L', 'UW1', 'TH'] sleuth\n",
      "['s', 'l', 'oo', 'th-']\n",
      "['P', 'L', 'UH1', 'R', 'AH0', 'S', 'IY0'] pleurisy\n",
      "['p', 'l', 'u', 'r', 'uh-', 's', 'ee']\n",
      "['D', 'UW1', 'S'] deuce\n",
      "['d', 'oo', 's']\n",
      "['N', 'UW1', 'Z'] news\n",
      "['n', 'oo', 'z']\n",
      "['SH', 'R', 'UW1', 'D'] shrewd\n",
      "['sh', 'r', 'oo', 'd']\n",
      "['S', 'OW1'] sew\n",
      "['s', 'o']\n",
      "['Y', 'UW1'] ewe\n",
      "['y', 'oo']\n",
      "['K', 'IY1'] key\n",
      "['k', 'ee']\n",
      "['DH', 'EY1'] they \n",
      "['th+', 'ay']\n",
      "['G', 'AY1', 'Z', 'ER0'] geyser\n",
      "['g', 'ai', 'z', 'er']\n",
      "['EH1', 'R', 'IY0'] eyrie\n",
      "['eh', 'r', 'ee']\n",
      "['AY1'] eye \n",
      "['ai']\n",
      "['IH0', 'N'] in\n",
      "['ih', 'n']\n",
      "['S', 'IH1', 'V', 'AH0', 'L'] civil\n",
      "['s', 'ih', 'v', ['ul', ['uh-', 'l']]]\n",
      "['F', 'AY1', 'N', 'D'] find\n",
      "['f', 'ai', 'n', 'd']\n",
      "['AH0', 'F', 'ER1', 'M'] affirm \n",
      "['uh-', 'f', 'er', 'm']\n",
      "['S', 'IY1', 'N', 'Y', 'ER0'] senior\n",
      "['s', 'ee', 'n', 'y', 'er']\n",
      "['S', 'K', 'IY1'] ski\n",
      "['s', 'k', 'ee']\n",
      "['AY1', 'S'] ice\n",
      "['ai', 's']\n",
      "['G', 'IH1', 'V'] give\n",
      "['g', 'ih', 'v']\n",
      "['IH0', 'L', 'IY1', 'T'] elite\n",
      "['ih', 'l', 'ee', 't']\n",
      "['F', 'R', 'AE1', 'JH', 'AH0', 'L'] fragile \n",
      "['f', 'r', 'ae', 'dj', ['ul', ['uh-', 'l']]]\n",
      "['D', 'ER1', 'JH'] dirge\n",
      "['d', 'er', 'dj']\n",
      "['P', 'AA1', 'R', 'L', 'AH0', 'M', 'AH0', 'N', 'T'] parliament\n",
      "['p', 'ah', 'r', 'l', ['um', ['uh-', 'm']], ['un', ['uh-', 'n']], 't']\n",
      "['M', 'EH1', 'R', 'IH0', 'JH'] marriage\n",
      "['m', 'eh', 'r', 'ih', 'dj']\n",
      "['CH', 'IY1', 'F'] chief\n",
      "['tch', 'ee', 'f']\n",
      "['T', 'R', 'AY1', 'D'] tried\n",
      "['t', 'r', 'ai', 'd']\n",
      "['EY1', 'N', 'CH', 'AH0', 'N', 'T'] ancient\n",
      "['ay', 'n', 'tch', ['un', ['uh-', 'n']], 't']\n",
      "['M', 'IH1', 'S', 'CH', 'AH0', 'F'] mischief\n",
      "['m', 'ih', 's', 'tch', 'uh-', 'f']\n",
      "['F', 'R', 'EH1', 'N', 'D'] friend\n",
      "['f', 'r', 'eh', 'n', 'd']\n",
      "['P', 'IY1', 'S'] piece\n",
      "['p', 'ee', 's']\n",
      "['P', 'EY1', 'SH', 'AH0', 'N', 'S'] patience\n",
      "['p', 'ay', 'sh', ['un', ['uh-', 'n']], 's']\n",
      "['S', 'IH1', 'V'] sieve\n",
      "['s', 'ih', 'v']\n",
      "['L', 'UW1'] lieu\n",
      "['l', 'oo']\n",
      "['V', 'Y', 'UW1'] view\n",
      "['v', 'y', 'oo']\n",
      "['N', 'AY1', 'T'] night\n",
      "['n', 'ai', 't']\n",
      "['OW1', 'N', 'L', 'IY0'] only\n",
      "['o', 'n', 'l', 'ee']\n",
      "['K', 'AA1', 'R', 'T', 'AH0', 'N'] carton\n",
      "['k', 'ah', 'r', 't', ['un', ['uh-', 'n']]]\n",
      "['AA1', 'D'] odd\n",
      "['ah', 'd']\n",
      "['AO1', 'F'] off\n",
      "['aw', 'f']\n",
      "['AA1', 'N', 'ER0'] honor \n",
      "['ah', 'n', 'er']\n",
      "['AH1', 'V', 'AH0', 'N'] oven\n",
      "['uh+', 'v', ['un', ['uh-', 'n']]]\n",
      "['HH', 'UW1'] who\n",
      "['h', 'oo']\n",
      "['T', 'AH0', 'D', 'EY1'] today\n",
      "['t', 'uh-', 'd', 'ay']\n",
      "['W', 'IH1', 'M', 'AH0', 'N'] women\n",
      "['w', 'ih', 'm', ['un', ['uh-', 'n']]]\n",
      "['CH', 'UW1', 'Z'] choose\n",
      "['tch', 'oo', 'z']\n",
      "['K', 'OW1', 'D'] code\n",
      "['k', 'o', 'd']\n",
      "['K', 'AH1', 'M'] come\n",
      "['k', 'uh+', 'm']\n",
      "['W', 'EH1', 'L', 'K', 'AH0', 'M'] welcome\n",
      "['w', 'eh', 'l', 'k', ['um', ['uh-', 'm']]]\n",
      "['G', 'AO1', 'N'] gone\n",
      "['g', 'aw', 'n']\n",
      "['D', 'AA1', 'JH'] dodge\n",
      "['d', 'ah', 'dj']\n",
      "['L', 'UW1', 'Z'] lose\n",
      "['l', 'oo', 'z']\n",
      "['W', 'ER1', 'S'] worse\n",
      "['w', 'er', 's']\n",
      "['K', 'OW1', 'T'] coat\n",
      "['k', 'o', 't']\n",
      "['B', 'R', 'AO1', 'D'] broad\n",
      "['b', 'r', 'aw', 'd']\n",
      "['K', 'AO1', 'R', 'S'] coarse\n",
      "['k', 'aw', 'r', 's']\n",
      "['D', 'OW1'] doe\n",
      "['d', 'o']\n",
      "['AH0', 'M', 'IY1', 'B', 'AH0']  amoeba\n",
      "[['um', ['uh-', 'm']], 'ee', 'b']\n",
      "['K', 'AH0', 'N', 'UW1'] canoe \n",
      "['k', ['un', ['uh-', 'n']], 'oo']\n",
      "['OW1', 'M'] ohm\n",
      "['o', 'm']\n",
      "['K', 'OY1', 'L'] coil\n",
      "['k', 'oy', 'l']\n",
      "['V', 'OY1', 'S'] voice\n",
      "['v', 'oy', 's']\n",
      "['T', 'AO1', 'R', 'T', 'AH0', 'S'] tortoise\n",
      "['t', 'aw', 'r', 't', 'uh-', 's']\n",
      "['B', 'UW1', 'T'] boot\n",
      "['b', 'oo', 't']\n",
      "['W', 'UH1', 'D'] wood\n",
      "['w', 'u', 'd']\n",
      "['D', 'AO1', 'R'] door\n",
      "['d', 'aw', 'r']\n",
      "['B', 'L', 'AH1', 'D'] blood\n",
      "['b', 'l', 'uh+', 'd']\n",
      "['IH0', 'N', 'AO1', 'R', 'M', 'AH0', 'S'] enormous\n",
      "['ih', 'n', 'aw', 'r', 'm', 'uh-', 's']\n",
      "['AW1', 'T'] out\n",
      "['au', 't']\n",
      "['T', 'AH1', 'CH'] touch\n",
      "['t', 'uh+', 'tch']\n",
      "['F', 'AO1', 'R'] four\n",
      "['f', 'aw', 'r']\n",
      "['Y', 'UW1'] you\n",
      "['y', 'oo']\n",
      "['K', 'UH1', 'D'] could\n",
      "['k', 'u', 'd']\n",
      "['G', 'L', 'AE1', 'M', 'ER0'] glamour\n",
      "['g', 'l', 'ae', 'm', 'er']\n",
      "['B', 'IH1', 'V', 'W', 'AE0', 'K'] bivouac \n",
      "['b', 'ih', 'v', 'w', 'ae']\n",
      "['AW1', 'N', 'S'] ounce\n",
      "['au', 'n', 's']\n",
      "['K', 'AO1', 'R', 'S'] course\n",
      "['k', 'aw', 'r', 's']\n",
      "['R', 'UW1', 'T'] route\n",
      "['r', 'oo', 't']\n",
      "['S', 'K', 'ER1', 'JH'] scourge\n",
      "['s', 'k', 'er', 'dj']\n",
      "['B', 'AA1', 'T'] bought \n",
      "['b', 'ah', 't']\n",
      "['D', 'OW1'] dough\n",
      "['d', 'o']\n",
      "['D', 'R', 'AW1', 'T'] drought\n",
      "['d', 'r', 'au', 't']\n",
      "['TH', 'R', 'UW1'] through\n",
      "['th-', 'r', 'oo']\n",
      "['OW1', 'N'] own\n",
      "['o', 'n']\n",
      "['T', 'AW1', 'AH0', 'L'] towel\n",
      "['t', 'au', ['ul', ['uh-', 'l']]]\n",
      "['N', 'AA1', 'L', 'AH0', 'JH'] knowledge\n",
      "['n', 'ah', 'l', 'uh-', 'dj']\n",
      "['B', 'R', 'AW1', 'Z'] browse\n",
      "['b', 'r', 'au', 'z']\n",
      "['OW1'] owe\n",
      "['o']\n",
      "['B', 'OY1'] boy\n",
      "['b', 'oy']\n",
      "['K', 'AY0', 'OW1', 'T', 'IY0'] coyote\n",
      "['k', 'ai', 'o', 't', 'ee']\n",
      "['G', 'AA1', 'R', 'G', 'OY2', 'L'] gargoyle\n",
      "['g', 'ah', 'r', 'g', 'oy', 'l']\n",
      "['AH1', 'P'] up\n",
      "['uh+', 'p']\n",
      "['Y', 'UW1', 'N', 'Y', 'AH0', 'N'] union\n",
      "['y', 'oo', 'n', 'y', ['un', ['uh-', 'n']]]\n",
      "['M', 'IY1', 'D', 'IY0', 'AH0', 'M'] medium\n",
      "['m', 'ee', 'd', 'ee', ['um', ['uh-', 'm']]]\n",
      "['S', 'ER1', 'V', 'EY2'] survey\n",
      "['s', 'er', 'v', 'ay']\n",
      "['P', 'UH1', 'T'] put\n",
      "['p', 'u', 't']\n",
      "['T', 'R', 'UW1', 'TH'] truth\n",
      "['t', 'r', 'oo', 'th-']\n",
      "['L', 'IH1', 'K', 'W', 'AH0', 'D'] liquid\n",
      "['l', 'ih', 'k', 'w', 'uh-', 'd']\n",
      "['B', 'EH1', 'R', 'IY0'] bury\n",
      "['b', 'eh', 'r', 'ee']\n",
      "['B', 'IH1', 'Z', 'IY0'] busy\n",
      "['b', 'ih', 'z', 'ee']\n",
      "['Y', 'UW1', 'S'] use\n",
      "['y', 'oo', 's']\n",
      "['R', 'UW1', 'D'] rude\n",
      "['r', 'oo', 'd']\n",
      "['M', 'EH1', 'ZH', 'ER0'] measure\n",
      "['m', 'eh', 'zh', 'er']\n",
      "['B', 'AH1', 'JH'] budge\n",
      "['b', 'uh+', 'dj']\n",
      "['SH', 'UH1', 'R'] sure\n",
      "['sh', 'u', 'r']\n",
      "['F', 'EH1', 'R', 'AH0', 'L'] ferrule\n",
      "['f', 'eh', 'r', ['ul', ['uh-', 'l']]]\n",
      "['M', 'IH1', 'N', 'AH0', 'T'] minute\n",
      "['m', 'ih', 'n', 'uh-', 't']\n",
      "['K', 'Y', 'UW1'] cue\n",
      "['k', 'y', 'oo']\n",
      "['B', 'L', 'UW1'] blue\n",
      "['b', 'l', 'oo']\n",
      "['B', 'IH1', 'L', 'D'] build\n",
      "['b', 'ih', 'l', 'd']\n",
      "['S', 'UW1', 'T'] suit\n",
      "['s', 'oo', 't']\n",
      "['F', 'R', 'UW1', 'T'] fruit\n",
      "['f', 'r', 'oo', 't']\n",
      "['JH', 'UW1', 'S'] juice\n",
      "['dj', 'oo', 's']\n",
      "['B', 'OY1', 'AH0', 'N', 'T'] buoyant\n",
      "['b', 'oy', ['un', ['uh-', 'n']], 't']\n",
      "['B', 'AY1'] buy\n",
      "['b', 'ai']\n",
      "['S', 'T', 'AO1', 'R', 'IY0'] story\n",
      "['s', 't', 'aw', 'r', 'ee']\n",
      "['T', 'AY1', 'P', 'IH0', 'S', 'T'] typist\n",
      "['t', 'ai', 'p', 'ih', 's', 't']\n",
      "['M', 'IH1', 'TH'] myth\n",
      "['m', 'ih', 'th-']\n",
      "['Y', 'EH1', 'S'] yes\n",
      "['y', 'eh', 's']\n",
      "['EH1', 'TH', 'AH0', 'L'] ethyl\n",
      "['eh', 'th-', ['ul', ['uh-', 'l']]]\n",
      "['S', 'AE1', 'T', 'ER0'] satyr\n",
      "['s', 'ae', 't', 'er']\n",
      "['T', 'AY1', 'P'] type\n",
      "['t', 'ai', 'p']\n",
      "['AH0', 'P', 'AA1', 'K', 'AH0', 'L', 'IH2', 'P', 'S'] apocalypse\n",
      "['uh-', 'p', 'ah', 'k', ['ul', ['uh-', 'l']], 'ih', 'p', 's']\n",
      "['M', 'EH1', 'D', 'AH0', 'L'] medal\n",
      "['m', 'eh', 'd', ['ul', ['uh-', 'l']]]\n",
      "['B', 'AE1', 'D'] bad\n",
      "['b', 'ae', 'd']\n",
      "['EH1', 'B'] ebb \n",
      "['eh', 'b']\n",
      "['D', 'EH1', 'T'] debt\n",
      "['d', 'eh', 't']\n",
      "['K', 'AE1', 'B'] cab\n",
      "['k', 'ae', 'b']\n",
      "['S', 'EH1', 'N', 'T'] cent\n",
      "['s', 'eh', 'n', 't']\n",
      "['OW1', 'SH', 'AH0', 'N'] ocean \n",
      "['o', 'sh', ['un', ['uh-', 'n']]]\n",
      "['CH', 'EH1', 'L', 'OW0'] cello\n",
      "['tch', 'eh', 'l', 'o']\n",
      "['AA1', 'K', 'Y', 'AH0', 'P', 'AY2'] occupy\n",
      "['ah', 'k', 'y', 'uh-', 'p', 'ai']\n",
      "['S', 'AE1', 'K', 'ER0', 'AH0', 'N'] saccharin\n",
      "['s', 'ae', 'k', 'er', ['un', ['uh-', 'n']]]\n",
      "['OW1', 'SH', 'AH0', 'N'] ocean\n",
      "['o', 'sh', ['un', ['uh-', 'n']]]\n",
      "['CH', 'AA1', 'R', 'T'] chart\n",
      "['tch', 'ah', 'r', 't']\n",
      "['K', 'AO1', 'R', 'AH0', 'S'] chorus\n",
      "['k', 'aw', 'r', 'uh-', 's']\n",
      "['SH', 'EH1', 'F'] chef\n",
      "['sh', 'eh', 'f']\n",
      "['Y', 'AA1', 'T'] yacht\n",
      "['y', 'ah', 't']\n",
      "['S', 'OW1', 'SH', 'AH0', 'L'] social\n",
      "['s', 'o', 'sh', ['ul', ['uh-', 'l']]]\n",
      "['K', 'R', 'AE1', 'K', 'T'] cracked\n",
      "['k', 'r', 'ae', 'k', 't']\n",
      "['AE2', 'K', 'W', 'IY0', 'EH1', 'S'] acquiesce\n",
      "['ae', 'k', 'w', 'ee', 'eh', 's']\n",
      "['AH0', 'K', 'W', 'EY1', 'N', 'T'] acquaint\n",
      "['uh-', 'k', 'w', 'ay', 'n', 't']\n",
      "['EH1', 'TH', 'IH0', 'K', 'S'] ethics\n",
      "['eh', 'th-', 'ih', ['ks', ['k', 's']]]\n",
      "['IH0', 'N', 'D', 'AY1', 'T'] indict\n",
      "['ih', 'n', 'd', 'ai', 't']\n",
      "['Z', 'AA1', 'R'] czar\n",
      "['z', 'ah', 'r']\n",
      "['D', 'AE1', 'D'] dad\n",
      "['d', 'ae', 'd']\n",
      "['EH1', 'JH', 'AH0', 'K', 'EY2', 'T'] educate\n",
      "['eh', 'dj', 'uh-', 'k', 'ay', 't']\n",
      "['AE1', 'D'] add\n",
      "['ae', 'd']\n",
      "['B', 'AH1', 'JH', 'IH0', 'T'] budget\n",
      "['b', 'uh+', 'dj', 'ih', 't']\n",
      "['K', 'AO1', 'R', 'JH', 'AH0', 'L'] cordial\n",
      "['k', 'aw', 'r', 'dj', ['ul', ['uh-', 'l']]]\n",
      "['AH0', 'JH', 'AH1', 'S', 'T'] adjust\n",
      "['uh-', 'dj', 'uh+', 's', 't']\n",
      "['P', 'EY1', 'S', 'T'] paced\n",
      "['p', 'ay', 's', 't']\n",
      "['IY1', 'Z', 'AH0', 'L'] easel\n",
      "['ee', 'z', ['ul', ['uh-', 'l']]]\n",
      "['SH', 'AO1', 'R', 'T', 'AH0', 'N'] shorten\n",
      "['sh', 'aw', 'r', 't', ['un', ['uh-', 'n']]]\n",
      "['G', 'OW1', 'Z'] goes\n",
      "['g', 'o', 'z']\n",
      "['F', 'AA1', 'R', 'M'] farm\n",
      "['f', 'ah', 'r', 'm']\n",
      "['AH1', 'V'] of\n",
      "['uh+', 'v']\n",
      "['K', 'AH1', 'F'] cuff\n",
      "['k', 'uh+', 'f']\n",
      "['AO1', 'F', 'AH0', 'N'] often\n",
      "['aw', 'f', ['un', ['uh-', 'n']]]\n",
      "['G', 'AE1', 'P'] gap\n",
      "['g', 'ae', 'p']\n",
      "['JH', 'EH1', 'M'] gem\n",
      "['dj', 'eh', 'm']\n",
      "['R', 'AH0', 'ZH', 'IY1', 'M'] regime\n",
      "['r', 'uh-', 'zh', 'ee', 'm']\n",
      "['EH1', 'G'] egg\n",
      "['eh', 'g']\n",
      "['IH0', 'G', 'Z', 'AE1', 'JH', 'ER0', 'EY2', 'T'] exaggerate\n",
      "['ih', 'g', 'z', 'ae', 'dj', 'er', 'ay', 't']\n",
      "['G', 'OW1', 'S', 'T'] ghost\n",
      "['g', 'o', 's', 't']\n",
      "['R', 'AH1', 'F'] rough\n",
      "['r', 'uh+', 'f']\n",
      "['R', 'IY1', 'JH', 'AH0', 'N'] region\n",
      "['r', 'ee', 'dj', ['un', ['uh-', 'n']]]\n",
      "['F', 'L', 'EH1', 'G', 'M'] phlegm \n",
      "['f', 'l', 'eh', 'g', 'm']\n",
      "['N', 'AE1', 'T'] gnat \n",
      "['n', 'ae', 't']\n",
      "['R', 'OW1', 'G'] rogue \n",
      "['r', 'o', 'g']\n",
      "['HH', 'AA1', 'T'] hot\n",
      "['h', 'ah', 't']\n",
      "['IY1', 'V', 'AH0', 'L'] evil\n",
      "['ee', 'v', ['ul', ['uh-', 'l']]]\n",
      "['B', 'EY1', 'S', 'AH0', 'N'] basin\n",
      "['b', 'ay', 's', ['un', ['uh-', 'n']]]\n",
      "['JH', 'AE1', 'M'] jam\n",
      "['dj', 'ae', 'm']\n",
      "['K', 'IY1', 'P'] keep\n",
      "['k', 'ee', 'p']\n",
      "['K', 'AA1', 'K', 'IY0'] khaki\n",
      "['k', 'ah', 'k', 'ee']\n",
      "['N', 'IY1'] knee\n",
      "['n', 'ee']\n",
      "['L', 'AE1', 'D'] lad\n",
      "['l', 'ae', 'd']\n",
      "['K', 'UH1', 'D'] could\n",
      "['k', 'u', 'd']\n",
      "['EY1', 'B', 'AH0', 'L'] able\n",
      "['ay', 'b', ['ul', ['uh-', 'l']]]\n",
      "['K', 'AE1', 'F'] calf\n",
      "['k', 'ae', 'f']\n",
      "['T', 'AO1', 'K'] talk\n",
      "['t', 'aw']\n",
      "['AO1', 'L'] all\n",
      "['aw', 'l']\n",
      "['K', 'AA1', 'M'] calm\n",
      "['k', 'ah', 'm']\n",
      "['K', 'AE1', 'V', 'Z'] calves\n",
      "['k', 'ae', 'v', 'z']\n",
      "['M', 'AE1', 'N'] man\n",
      "['m', 'ae', 'n']\n",
      "['K', 'AE1', 'Z', 'AH0', 'M'] chasm\n",
      "['k', 'ae', 'z', ['um', ['uh-', 'm']]]\n",
      "['L', 'AE1', 'M'] lamb\n",
      "['l', 'ae', 'm']\n",
      "['M', 'AH1', 'M', 'IY0'] mummy\n",
      "['m', 'uh+', 'm', 'ee']\n",
      "['HH', 'IH1', 'M'] hymn\n",
      "['h', 'ih', 'm']\n",
      "['N', 'IH0', 'M', 'AA1', 'N', 'IH0', 'K', 'S'] mnemonics\n",
      "['n', 'ih', 'm', 'ah', 'n', 'ih', ['ks', ['k', 's']]]\n",
      "['N', 'AE1', 'P'] nap\n",
      "['n', 'ae', 'p']\n",
      "['B', 'AE1', 'NG', 'K'] bank\n",
      "['b', 'ae', 'ng']\n",
      "['L', 'EH1', 'NG', 'K', 'TH'] length \n",
      "['l', 'eh', 'ng', 'k', 'th-']\n",
      "['T', 'AH1', 'NG'] tongue\n",
      "['t', 'uh+', 'ng']\n",
      "['IH1', 'N'] inn\n",
      "['ih', 'n']\n",
      "['P', 'IH1', 'S', 'T', 'AH0', 'L'] pistol\n",
      "['p', 'ih', 's', 't', ['ul', ['uh-', 'l']]]\n",
      "['P', 'AA1', 'R', 'D', 'AH0', 'N'] pardon\n",
      "['p', 'ah', 'r', 'd', ['un', ['uh-', 'n']]]\n",
      "['P', 'AE1', 'D'] pad\n",
      "['p', 'ae', 'd']\n",
      "['R', 'AE1', 'Z', 'B', 'EH2', 'R', 'IY0'] raspberry\n",
      "['r', 'ae', 'z', 'b', 'eh', 'r', 'ee']\n",
      "['G', 'R', 'AE1', 'F'] graph\n",
      "['g', 'r', 'ae', 'f']\n",
      "['N', 'UW0', 'M', 'OW1', 'N', 'Y', 'AH0'] pneumonia\n",
      "['n', 'oo', 'm', 'o', 'n', 'y']\n",
      "['AE1', 'P', 'AH0', 'L'] apple\n",
      "['ae', 'p', ['ul', ['uh-', 'l']]]\n",
      "['S', 'AA1', 'L', 'M'] psalm \n",
      "['s', 'ah', 'l', 'm']\n",
      "['R', 'IH0', 'S', 'IY1', 'T'] receipt\n",
      "['r', 'ih', 's', 'ee', 't']\n",
      "['L', 'IH1', 'K', 'W', 'AH0', 'D'] liquid\n",
      "['l', 'ih', 'k', 'w', 'uh-', 'd']\n",
      "['K', 'W', 'IH1', 'L', 'T'] quilt\n",
      "['k', 'w', 'ih', 'l', 't']\n",
      "['B', 'UW0', 'K', 'EY1'] bouquet \n",
      "['b', 'oo', 'k', 'ay']\n",
      "['R', 'AE1', 'P'] rap\n",
      "['r', 'ae', 'p']\n",
      "['R', 'AY1', 'M'] rhyme \n",
      "['r', 'ai', 'm']\n",
      "['P', 'ER1'] purr \n",
      "['p', 'er']\n",
      "['S', 'IH1', 'T'] sit\n",
      "['s', 'ih', 't']\n",
      "['D', 'IH0', 'Z', 'AY1', 'N'] design\n",
      "['d', 'ih', 'z', 'ai', 'n']\n",
      "['Y', 'UW1', 'ZH', 'AH0', 'W', 'AH0', 'L'] usual\n",
      "['y', 'oo', 'zh', 'uh-', 'w', ['ul', ['uh-', 'l']]]\n",
      "['SH', 'UH1', 'G', 'ER0'] sugar\n",
      "['sh', 'u', 'g', 'er']\n",
      "['S', 'IY1', 'N'] scene\n",
      "['s', 'ee', 'n']\n",
      "['K', 'R', 'IH0', 'SH', 'EH1', 'N', 'D', 'OW0'] crescendo\n",
      "['k', 'r', 'ih', 'sh', 'eh', 'n', 'd', 'o']\n",
      "['D', 'IH0', 'S', 'ER1', 'N'] discern\n",
      "['d', 'ih', 's', 'er', 'n']\n",
      "['V', 'IH1', 'S', 'K', 'AW0', 'N', 'T'] viscount\n",
      "['v', 'ih', 's', 'k', 'au', 'n', 't']\n",
      "['S', 'K', 'IH1', 'Z', 'AH0', 'M'] schism\n",
      "['s', 'k', 'ih', 'z', ['um', ['uh-', 'm']]]\n",
      "['SH', 'W', 'AA1'] schwa\n",
      "['sh', 'w', 'ah']\n",
      "['K', 'AA1', 'N', 'SH', 'AH0', 'S'] conscious\n",
      "['k', 'ah', 'n', 'sh', 'uh-', 's']\n",
      "['SH', 'IH1', 'P'] ship\n",
      "['sh', 'ih', 'p']\n",
      "['F', 'Y', 'UW1', 'ZH', 'AH0', 'N'] fusion\n",
      "['f', 'y', 'oo', 'zh', ['un', ['uh-', 'n']]]\n",
      "['P', 'EH1', 'N', 'SH', 'AH0', 'N'] pension\n",
      "['p', 'eh', 'n', 'sh', ['un', ['uh-', 'n']]]\n",
      "['AY1', 'L', 'AH0', 'N', 'D'] island\n",
      "['ai', 'l', ['un', ['uh-', 'n']], 'd']\n",
      "['B', 'AA1', 'S'] boss\n",
      "['b', 'ah', 's']\n",
      "['D', 'IH0', 'Z', 'ER1', 'T'] dessert\n",
      "['d', 'ih', 'z', 'er', 't']\n",
      "['P', 'R', 'EH1', 'SH', 'ER0'] pressure\n",
      "['p', 'r', 'eh', 'sh', 'er']\n",
      "['M', 'IH1', 'SH', 'AH0', 'N'] mission\n",
      "['m', 'ih', 'sh', ['un', ['uh-', 'n']]]\n",
      "['L', 'IH1', 'S', 'AH0', 'N'] listen\n",
      "['l', 'ih', 's', ['un', ['uh-', 'n']]]\n",
      "['S', 'AO1', 'R', 'D'] sword\n",
      "['s', 'aw', 'r', 'd']\n",
      "['T', 'AE1', 'B'] tab\n",
      "['t', 'ae', 'b']\n",
      "['K', 'AH1', 'L', 'CH', 'ER0'] culture\n",
      "['k', 'uh+', 'l', 'tch', 'er']\n",
      "['IH2', 'N', 'IH1', 'SH', 'IY0', 'AH0', 'T'] initiate\n",
      "['ih', 'n', 'ih', 'sh', 'ee', 'uh-', 't']\n",
      "['W', 'AA1', 'CH'] watch\n",
      "['w', 'ah', 'tch']\n",
      "['M', 'AO1', 'R', 'G', 'AH0', 'JH'] mortgage\n",
      "['m', 'aw', 'r', 'g', 'uh-', 'dj']\n",
      "['TH', 'AO1'] thaw\n",
      "['th-', 'aw']\n",
      "['DH', 'AH0'] the\n",
      "['th+']\n",
      "['TH', 'AY1', 'M'] thyme\n",
      "['th-', 'ai', 'm']\n",
      "['AE1', 'K', 'SH', 'AH0', 'N'] action\n",
      "['ae', 'k', 'sh', ['un', ['uh-', 'n']]]\n",
      "['K', 'W', 'EH1', 'S', 'CH', 'AH0', 'N'] question\n",
      "['k', 'w', 'eh', 's', 'tch', ['un', ['uh-', 'n']]]\n",
      "['IH0', 'K', 'W', 'EY1', 'ZH', 'AH0', 'N'] equation\n",
      "['ih', 'k', 'w', 'ay', 'zh', ['un', ['uh-', 'n']]]\n",
      "['P', 'AH1', 'T'] putt\n",
      "['p', 'uh+', 't']\n",
      "['T', 'UW1'] two\n",
      "['t', 'oo']\n",
      "['V', 'AE1', 'T'] vat\n",
      "['v', 'ae', 't']\n",
      "['W', 'IY1'] we\n",
      "['w', 'ee']\n",
      "['W', 'AH1', 'T'] what\n",
      "['w', 'uh+', 't']\n",
      "['HH', 'UW1'] who\n",
      "['h', 'oo']\n",
      "['R', 'AE1', 'P'] wrap\n",
      "['r', 'ae', 'p']\n",
      "['AA1', 'K', 'S'] ox\n",
      "['ah', ['ks', ['k', 's']]]\n",
      "['IH0', 'G', 'Z', 'IH1', 'S', 'T'] exist\n",
      "['ih', 'g', 'z', 'ih', 's', 't']\n",
      "['Z', 'UW1'] zoo\n",
      "['z', 'oo']\n",
      "['W', 'AO1', 'L', 'T', 'S'] waltz\n",
      "['w', 'aw', 'l', 't', 's']\n",
      "['AE1', 'ZH', 'ER0'] azure\n",
      "['ae', 'zh', 'er']\n",
      "['B', 'AH1', 'Z'] buzz\n",
      "['b', 'uh+', 'z']\n",
      "['EH1', 'R'] heir\n",
      "['eh', 'r']\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(berndt_conditional_probs_words):\n",
    "    print(word,berndt_conditional_probs.Example.iloc[i])\n",
    "    print(get_keyboard_phonetic_symbols(word, berndt_arpabbet_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "berndt_computer_phonem_graph_prob_dict = {}\n",
    "for phoneme in berndt_conditional_probs.Phoneme.unique():\n",
    "    berndt_computer_phonem_graph_prob_dict[phoneme] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in berndt_conditional_probs.iterrows():\n",
    "    grapheme_prior_cond = (row[\"Grapheme\"], row['Prior_Probability'], row[\"Conditional_Probability\"])\n",
    "    berndt_computer_phonem_graph_prob_dict[row[\"Phoneme\"]].append(grapheme_prior_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ae': [('A', 0.0712, 0.542), ('A-E', 0.0111, 0.121), ('AI', 0.0026, 0.003)],\n",
       " 'uh-': [('A', 0.0712, 0.18600000000000003),\n",
       "  ('A-E', 0.0111, 0.002),\n",
       "  ('AI', 0.0026, 0.031),\n",
       "  ('AU', 0.0014, 0.006),\n",
       "  ('E', 0.073, 0.096),\n",
       "  ('E-E', 0.0032, 0.28600000000000003),\n",
       "  ('EA', 0.0047, 0.005),\n",
       "  ('El', 0.0005, 0.035),\n",
       "  ('EO', 0.0001, 0.6659999999999999),\n",
       "  ('EOU', 7e-05, 1.0),\n",
       "  ('EY-E', 0.0688, 0.18),\n",
       "  ('I-E', 0.0086, 6.0),\n",
       "  ('IA', 1e-05, 1.0),\n",
       "  ('IE', 0.0011, 0.171),\n",
       "  ('IE-E', 0.0002, 0.129),\n",
       "  ('O', 0.055, 0.26899999999999996),\n",
       "  ('O-E', 0.0043, 0.044000000000000004),\n",
       "  ('OI-E', 9e-05, 0.2),\n",
       "  ('OU', 0.0064, 0.48),\n",
       "  ('U', 0.0267, 0.102),\n",
       "  ('U-E', 0.0033, 0.01),\n",
       "  ('Y', 0.0193, 0.01)],\n",
       " 'ay': [('A', 0.0712, 0.129),\n",
       "  ('A-E', 0.0111, 0.6509999999999999),\n",
       "  ('AI', 0.0026, 0.7340000000000001),\n",
       "  ('AI-E', 0.0002, 0.818),\n",
       "  ('AIGH', 2.9999999999999997e-05, 1.0),\n",
       "  ('AU-E', 0.0001, 0.083),\n",
       "  ('AY', 0.0012, 0.97),\n",
       "  ('AY-E', 9e-06, 1.0),\n",
       "  ('E', 0.073, 0.002),\n",
       "  ('E-E', 0.0032, 0.017),\n",
       "  ('EA', 0.0047, 0.027000000000000003),\n",
       "  ('El', 0.0005, 0.245),\n",
       "  ('El-E', 7e-05, 0.25),\n",
       "  ('EIGH', 0.0001, 0.857),\n",
       "  ('ET', 8e-05, 1.0),\n",
       "  ('EY', 0.0005, 0.225)],\n",
       " 'ah': [('A', 0.0712, 0.077),\n",
       "  ('A-E', 0.0111, 0.025),\n",
       "  ('AH', 2.9999999999999997e-05, 1.0),\n",
       "  ('AU', 0.0014, 0.025),\n",
       "  ('E', 0.073, 0.0006),\n",
       "  ('EA', 0.0047, 0.035),\n",
       "  ('O', 0.055, 0.261),\n",
       "  ('O-E', 0.0043, 0.042),\n",
       "  ('OW', 0.0022, 0.016)],\n",
       " 'aw': [('A', 0.0712, 0.021),\n",
       "  ('A-E', 0.0111, 0.002),\n",
       "  ('AO', 1e-05, 1.0),\n",
       "  ('AU', 0.0014, 0.948),\n",
       "  ('AU-E', 0.0001, 0.75),\n",
       "  ('AUGH', 0.0001, 1.0),\n",
       "  ('AW', 0.0006, 1.0),\n",
       "  ('AW-E', 1e-05, 1.0),\n",
       "  ('O', 0.055, 0.07200000000000001),\n",
       "  ('O-E', 0.0043, 0.044000000000000004),\n",
       "  ('OA', 0.0012, 0.066),\n",
       "  ('OUGH', 0.0002, 0.517),\n",
       "  ('OW', 0.0022, 0.48100000000000004)],\n",
       " 'er': [('A', 0.0712, 0.021),\n",
       "  ('E', 0.073, 0.249),\n",
       "  ('E-E', 0.0032, 0.11900000000000001),\n",
       "  ('EA', 0.0047, 0.055999999999999994),\n",
       "  ('EA-E', 0.0003, 0.057999999999999996),\n",
       "  ('EU', 0.0003, 0.153),\n",
       "  ('EY-E', 0.0688, 0.015),\n",
       "  ('I-E', 0.0086, 1.0),\n",
       "  ('O', 0.055, 0.053),\n",
       "  ('O-E', 0.0043, 0.002),\n",
       "  ('OU', 0.0064, 0.031),\n",
       "  ('OU-E', 0.0006, 0.013999999999999999),\n",
       "  ('U', 0.0267, 0.08),\n",
       "  ('U-E', 0.0033, 0.09),\n",
       "  ('Y', 0.0193, 0.002)],\n",
       " 'eh': [('A', 0.0712, 0.02),\n",
       "  ('A-E', 0.0111, 0.042),\n",
       "  ('AE', 5e-05, 0.166),\n",
       "  ('AI', 0.0026, 0.17600000000000002),\n",
       "  ('AI-E', 0.0002, 0.136),\n",
       "  ('AY', 0.0012, 0.006999999999999999),\n",
       "  ('E', 0.073, 0.419),\n",
       "  ('E-E', 0.0032, 0.321),\n",
       "  ('EA', 0.0047, 0.298),\n",
       "  ('EA-E', 0.0003, 0.028999999999999998),\n",
       "  ('El', 0.0005, 0.105),\n",
       "  ('EO', 0.0001, 0.2),\n",
       "  ('EY', 0.0005, 0.016),\n",
       "  ('IE', 0.0011, 0.031),\n",
       "  ('U', 0.0267, 0.0006)],\n",
       " 'ih': [('A', 0.0712, 0.0005),\n",
       "  ('A-E', 0.0111, 0.154),\n",
       "  ('AI', 0.0026, 0.053),\n",
       "  ('E', 0.073, 0.0006),\n",
       "  ('E-E', 0.0032, 0.002),\n",
       "  ('EA-E', 0.0003, 0.028999999999999998),\n",
       "  ('EE', 0.0026, 0.02),\n",
       "  ('El', 0.0005, 0.192),\n",
       "  ('EY-E', 0.0688, 0.716),\n",
       "  ('I-E', 0.0086, 0.35600000000000004),\n",
       "  ('IA-E', 2e-05, 1.0),\n",
       "  ('IE', 0.0011, 0.10099999999999999),\n",
       "  ('IE-E', 0.0002, 0.032),\n",
       "  ('O', 0.055, 0.0001),\n",
       "  ('U', 0.0267, 0.001),\n",
       "  ('U-E', 0.0033, 0.008),\n",
       "  ('UI', 0.0002, 0.5329999999999999),\n",
       "  ('Y', 0.0193, 0.073),\n",
       "  ('Y-E', 0.0002, 0.040999999999999995)],\n",
       " 'ee': [('AE', 5e-05, 0.833),\n",
       "  ('E', 0.073, 0.23),\n",
       "  ('E-E', 0.0032, 0.252),\n",
       "  ('EA', 0.0047, 0.5760000000000001),\n",
       "  ('EA-E', 0.0003, 0.882),\n",
       "  ('EE', 0.0026, 0.9790000000000001),\n",
       "  ('EE-E', 8e-05, 1.0),\n",
       "  ('El', 0.0005, 0.315),\n",
       "  ('El-E', 7e-05, 0.75),\n",
       "  ('EO', 0.0001, 0.133),\n",
       "  ('EY', 0.0005, 0.741),\n",
       "  ('EY-E', 0.0688, 0.005),\n",
       "  ('I-E', 0.0086, 46.0),\n",
       "  ('IE', 0.0011, 0.49200000000000005),\n",
       "  ('IE-E', 0.0002, 0.838),\n",
       "  ('OE', 0.0002, 0.22699999999999998),\n",
       "  ('Y', 0.0193, 0.7859999999999999)],\n",
       " 'ai': [('AI-E', 0.0002, 0.045),\n",
       "  ('AY', 0.0012, 0.022000000000000002),\n",
       "  ('El', 0.0005, 0.105),\n",
       "  ('EIGH', 0.0001, 0.142),\n",
       "  ('EY', 0.0005, 0.016),\n",
       "  ('EY-E', 5.9999999999999995e-05, 1.0),\n",
       "  ('EY-E', 0.0688, 0.07400000000000001),\n",
       "  ('I-E', 0.0086, 0.589),\n",
       "  ('IE', 0.0011, 0.203),\n",
       "  ('IGH', 0.0008, 1.0),\n",
       "  ('OY', 0.0004, 0.02),\n",
       "  ('UY', 2e-05, 1.0),\n",
       "  ('Y', 0.0193, 0.1),\n",
       "  ('Y-E', 0.0002, 0.958)],\n",
       " 'o': [('AU', 0.0014, 0.019),\n",
       "  ('AU-E', 0.0001, 0.166),\n",
       "  ('EAU', 0.0001, 0.545),\n",
       "  ('EW', 0.0005, 0.047),\n",
       "  ('O', 0.055, 0.314),\n",
       "  ('O-E', 0.0043, 0.785),\n",
       "  ('OA', 0.0012, 0.9329999999999999),\n",
       "  ('OA-E', 2e-05, 1.0),\n",
       "  ('OE', 0.0002, 0.59),\n",
       "  ('OH', 2.9999999999999997e-05, 1.0),\n",
       "  ('OO', 0.0027, 0.028999999999999998),\n",
       "  ('OU', 0.0064, 0.040999999999999995),\n",
       "  ('OU-E', 0.0006, 0.147),\n",
       "  ('OUGH', 0.0002, 0.275),\n",
       "  ('OW', 0.0022, 0.502),\n",
       "  ('OW-E', 2e-05, 0.33299999999999996)],\n",
       " 'y': [('E', 0.073, 0.0001), ('EY-E', 0.0688, 0.008), ('Y', 0.0193, 0.025)],\n",
       " 'yu': [('EAU', 0.0001, 0.45399999999999996),\n",
       "  ('EU', 0.0003, 0.7170000000000001),\n",
       "  ('EU-E', 9e-06, 1.0),\n",
       "  ('EW', 0.0005, 0.603),\n",
       "  ('EW-E', 9e-06, 1.0),\n",
       "  ('IEU', 2.9999999999999997e-05, 1.0),\n",
       "  ('IEW', 5e-05, 1.0),\n",
       "  ('U', 0.0267, 0.28),\n",
       "  ('U-E', 0.0033, 0.703),\n",
       "  ('UE', 0.0003, 0.627),\n",
       "  ('UI', 0.0002, 0.266)],\n",
       " 'oo': [('EU', 0.0003, 0.102),\n",
       "  ('EW', 0.0005, 0.349),\n",
       "  ('O', 0.055, 0.006),\n",
       "  ('OO-E', 0.0001, 1.0),\n",
       "  ('O-E', 0.0043, 0.025),\n",
       "  ('OE', 0.0002, 0.18100000000000002),\n",
       "  ('OO', 0.0027, 0.57),\n",
       "  ('OU', 0.0064, 0.040999999999999995),\n",
       "  ('OU-E', 0.0006, 0.044000000000000004),\n",
       "  ('OUGH', 0.0002, 0.068),\n",
       "  ('U', 0.0267, 0.032),\n",
       "  ('U-E', 0.0033, 0.09300000000000001),\n",
       "  ('UE', 0.0003, 0.37200000000000005),\n",
       "  ('UI', 0.0002, 0.2),\n",
       "  ('Ul-E', 2.9999999999999997e-05, 1.0),\n",
       "  ('UO', 1e-05, 1.0)],\n",
       " 'u': [('EU', 0.0003, 0.025),\n",
       "  ('O', 0.055, 0.002),\n",
       "  ('OO', 0.0027, 0.376),\n",
       "  ('OU', 0.0064, 0.035),\n",
       "  ('U', 0.0267, 0.068),\n",
       "  ('U-E', 0.0033, 0.03)],\n",
       " 'uh+': [('O', 0.055, 0.018000000000000002),\n",
       "  ('O-E', 0.0043, 0.055),\n",
       "  ('OO', 0.0027, 0.023),\n",
       "  ('OU', 0.0064, 0.042),\n",
       "  ('U', 0.0267, 0.41700000000000004),\n",
       "  ('U-E', 0.0033, 0.063)],\n",
       " 'oy': [('OI', 0.0008, 1.0),\n",
       "  ('OI-E', 9e-05, 0.8),\n",
       "  ('OY', 0.0004, 0.972),\n",
       "  ('OY-E', 9e-06, 1.0)],\n",
       " 'au': [('OU', 0.0064, 0.324),\n",
       "  ('OU-E', 0.0006, 0.794),\n",
       "  ('OUGH', 0.0002, 0.13699999999999998),\n",
       "  ('OW-E', 2e-05, 0.6659999999999999)],\n",
       " 'w': [('OU', 0.0064, 0.001),\n",
       "  ('U', 0.0267, 0.016),\n",
       "  ('W', 0.0053, 1.0),\n",
       "  ('WH', 0.0009, 0.847)],\n",
       " 'ul': [('AL', 2.9999999999999997e-05, 1.0),\n",
       "  ('EL', 0.0001, 1.0),\n",
       "  ('IL', 5.9999999999999995e-05, 1.0),\n",
       "  ('LE', 0.0057, 1.0),\n",
       "  ('OL', 9e-06, 1.0)],\n",
       " 'b': [('B', 0.0206, 1.0), ('BB', 0.0005, 1.0), ('PB', 9e-06, 1.0)],\n",
       " 't': [('BT', 0.0001, 1.0),\n",
       "  ('CHT', 1e-05, 1.0),\n",
       "  ('CT', 1e-05, 1.0),\n",
       "  ('ED', 0.0002, 1.0),\n",
       "  ('PT', 1e-05, 1.0),\n",
       "  ('T', 0.0713, 0.973),\n",
       "  ('TH', 0.0051, 0.001),\n",
       "  ('TT', 0.0019, 1.0),\n",
       "  ('TW', 2e-05, 1.0)],\n",
       " 'k': [('C', 0.042, 0.757),\n",
       "  ('CCH', 0.0007, 1.0),\n",
       "  ('CCH', 9e-06, 1.0),\n",
       "  ('CH', 0.0045, 0.29),\n",
       "  ('CK', 0.0026, 1.0),\n",
       "  ('CQ', 2e-05, 1.0),\n",
       "  ('K', 0.0055, 1.0),\n",
       "  ('KH', 2e-05, 1.0),\n",
       "  ('Lk', 0.0001, 1.0),\n",
       "  ('Q', 0.0001, 1.0),\n",
       "  ('QU', 0.002, 0.12300000000000001),\n",
       "  ('SC', 0.0008, 0.033)],\n",
       " 's': [('C', 0.042, 0.23399999999999999),\n",
       "  ('PS', 0.0001, 1.0),\n",
       "  ('S', 0.0488, 0.868),\n",
       "  ('SC', 0.0008, 0.865),\n",
       "  ('SCH', 2.9999999999999997e-05, 0.5),\n",
       "  ('SS', 0.0042, 0.9520000000000001),\n",
       "  ('ST', 0.0003, 1.0),\n",
       "  ('SW', 2.9999999999999997e-05, 1.0),\n",
       "  ('Z', 0.0021, 0.025)],\n",
       " 'sh': [('C', 0.042, 0.008),\n",
       "  ('CE', 1e-05, 1.0),\n",
       "  ('CH', 0.0045, 0.069),\n",
       "  ('Cl', 0.0007, 1.0),\n",
       "  ('S', 0.0488, 0.003),\n",
       "  ('SC', 0.0008, 0.067),\n",
       "  ('SCH', 2.9999999999999997e-05, 0.5),\n",
       "  ('SCI', 4e-05, 1.0),\n",
       "  ('SH', 0.0036, 1.0),\n",
       "  ('Sl', 0.0008, 0.431),\n",
       "  ('SS', 0.0042, 0.019),\n",
       "  ('SSI', 0.0004, 1.0),\n",
       "  ('T', 0.0713, 0.003),\n",
       "  ('Tl', 0.0076, 0.983)],\n",
       " 'tch': [('C', 0.042, 0.0004),\n",
       "  ('CH', 0.0045, 0.64),\n",
       "  ('T', 0.0713, 0.022000000000000002),\n",
       "  ('TCH', 0.0005, 1.0),\n",
       "  ('Tl', 0.0076, 0.015)],\n",
       " 'kw': [('CQU', 4e-05, 1.0), ('QU', 0.002, 0.8759999999999999)],\n",
       " 'ks': [('CS', 0.0002, 1.0), ('X', 0.0033, 0.885)],\n",
       " 'z': [('CZ', 9e-06, 1.0),\n",
       "  ('ES', 0.0004, 1.0),\n",
       "  ('S', 0.0488, 0.12),\n",
       "  ('SC', 0.0008, 0.033),\n",
       "  ('SS', 0.0042, 0.027999999999999997),\n",
       "  ('Z', 0.0021, 0.996),\n",
       "  ('ZZ', 0.0002, 1.0)],\n",
       " 'd': [('D', 0.0336, 0.991), ('DD', 0.0006, 1.0), ('LD', 5e-05, 1.0)],\n",
       " 'dj': [('D', 0.0336, 0.008),\n",
       "  ('DG', 0.0004, 1.0),\n",
       "  ('DI', 1e-05, 1.0),\n",
       "  ('DJ', 0.0001, 1.0),\n",
       "  ('G', 0.0169, 0.35100000000000003),\n",
       "  ('GG', 0.0006, 0.027999999999999997),\n",
       "  ('Gl', 0.0001, 1.0),\n",
       "  ('J', 0.002, 1.0)],\n",
       " 'un': [('EN', 0.0007, 1.0), ('IN', 0.0003, 1.0), ('ON', 2e-05, 1.0)],\n",
       " 'f': [('F', 0.0146, 0.998),\n",
       "  ('FF', 0.0016, 1.0),\n",
       "  ('FT', 2e-05, 1.0),\n",
       "  ('GH', 0.0001, 0.444),\n",
       "  ('LF', 8e-05, 1.0),\n",
       "  ('PH', 0.0022, 1.0)],\n",
       " 'v': [('F', 0.0146, 0.001),\n",
       "  ('LV', 2.9999999999999997e-05, 1.0),\n",
       "  ('V', 0.0136, 1.0)],\n",
       " 'g': [('G', 0.0169, 0.64),\n",
       "  ('GG', 0.0006, 0.971),\n",
       "  ('GH', 0.0001, 0.555),\n",
       "  ('GUE', 0.0001, 1.0),\n",
       "  ('TG', 9e-06, 1.0)],\n",
       " 'zh': [('G', 0.0169, 0.008),\n",
       "  ('S', 0.0488, 0.006),\n",
       "  ('Sl', 0.0008, 0.568),\n",
       "  ('Tl', 0.0076, 0.001),\n",
       "  ('Z', 0.0021, 0.008)],\n",
       " 'm': [('GM', 7e-05, 1.0),\n",
       "  ('LM', 0.0001, 1.0),\n",
       "  ('M', 0.0313, 0.971),\n",
       "  ('MB', 0.0002, 1.0),\n",
       "  ('MM', 0.0012, 1.0),\n",
       "  ('MN', 7e-05, 0.875)],\n",
       " 'n': [('GN', 0.0002, 1.0),\n",
       "  ('KN', 0.0003, 1.0),\n",
       "  ('MN', 7e-05, 0.125),\n",
       "  ('N', 0.071, 0.9670000000000001),\n",
       "  ('NN', 0.0011, 1.0),\n",
       "  ('PN', 2e-05, 1.0)],\n",
       " 'h': [('H', 0.007, 1.0), ('WH', 0.0009, 0.152)],\n",
       " 'l': [('L', 0.0451, 1.0), ('LL', 0.0045, 1.0), ('SL', 4e-05, 1.0)],\n",
       " 'um': [('M', 0.0313, 0.027999999999999997)],\n",
       " 'ng': [('N', 0.071, 0.032), ('NG', 0.0033, 1.0), ('NGUE', 1e-05, 1.0)],\n",
       " 'p': [('P', 0.0304, 1.0), ('PP', 0.0014, 1.0)],\n",
       " 'r': [('R', 0.0841, 1.0),\n",
       "  ('RH', 0.0001, 1.0),\n",
       "  ('RR', 0.0019, 1.0),\n",
       "  ('WR', 0.0004, 1.0)],\n",
       " 'th-': [('TH', 0.0051, 0.732)],\n",
       " 'th+': [('TH', 0.0051, 0.265)],\n",
       " 'gz': [('X', 0.0033, 0.114)],\n",
       " nan: [('$H', 0.0003, 1.0)]}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berndt_computer_phonem_graph_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_homophones = np.unique(homophones_in_data.word)\n",
    "hom_phon_words = get_ARPAbet_phonetic_transcription(unique_homophones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AE1', 'D'] ad\n",
      "['ae', 'd']\n",
      "['AE1', 'D'] add\n",
      "['ae', 'd']\n",
      "['AE1', 'D', 'Z'] adds\n",
      "['ae', 'd', 'z']\n",
      "['AE1', 'D', 'Z'] ads\n",
      "['ae', 'd', 'z']\n",
      "['EY1', 'D'] aid\n",
      "['ay', 'd']\n",
      "['EY1', 'D'] aide\n",
      "['ay', 'd']\n",
      "['EY1', 'D', 'Z'] aides\n",
      "['ay', 'd', 'z']\n",
      "['EY1', 'D', 'Z'] aids\n",
      "['ay', 'd', 'z']\n",
      "['EH1', 'R', 'Z'] airs\n",
      "['eh', 'r', 'z']\n",
      "['AH0', 'L', 'AW1', 'D'] allowed\n",
      "[['ul', ['uh-', 'l']], 'au', 'd']\n",
      "['AH0', 'L', 'AW1', 'D'] aloud\n",
      "[['ul', ['uh-', 'l']], 'au', 'd']\n",
      "['B', 'EY1', 'L'] bail\n",
      "['b', 'ay', 'l']\n",
      "['B', 'EY1', 'T', 'S'] baits\n",
      "['b', 'ay', 't', 's']\n",
      "['B', 'AO1', 'L', 'D'] bald\n",
      "['b', 'aw', 'l', 'd']\n",
      "['B', 'EY1', 'L'] bale\n",
      "['b', 'ay', 'l']\n",
      "['B', 'AE1', 'N', 'D'] band\n",
      "['b', 'ae', 'n', 'd']\n",
      "['B', 'AE1', 'N', 'D'] banned\n",
      "['b', 'ae', 'n', 'd']\n",
      "['B', 'EH1', 'R'] bare\n",
      "['b', 'eh', 'r']\n",
      "['B', 'EY1', 'T', 'S'] bates\n",
      "['b', 'ay', 't', 's']\n",
      "['B', 'AO1', 'L', 'D'] bawled\n",
      "['b', 'aw', 'l', 'd']\n",
      "['B', 'EH1', 'R'] bear\n",
      "['b', 'eh', 'r']\n",
      "['B', 'IY1', 'T', 'S'] beats\n",
      "['b', 'ee', 't', 's']\n",
      "['B', 'IY1', 'T', 'S'] beets\n",
      "['b', 'ee', 't', 's']\n",
      "['B', 'EH1', 'L'] bell\n",
      "['b', 'eh', 'l']\n",
      "['B', 'EH1', 'L'] belle\n",
      "['b', 'eh', 'l']\n",
      "['B', 'EH1', 'R', 'IY0'] berry\n",
      "['b', 'eh', 'r', 'ee']\n",
      "['B', 'IH1', 'L', 'D'] billed\n",
      "['b', 'ih', 'l', 'd']\n",
      "['B', 'L', 'UW1'] blew\n",
      "['b', 'l', 'oo']\n",
      "['B', 'L', 'UW1'] blue\n",
      "['b', 'l', 'oo']\n",
      "['B', 'AO1', 'R'] boar\n",
      "['b', 'aw', 'r']\n",
      "['B', 'AO1', 'R', 'D'] board\n",
      "['b', 'aw', 'r', 'd']\n",
      "['B', 'OW1', 'L', 'D'] bold\n",
      "['b', 'o', 'l', 'd']\n",
      "['B', 'AO1', 'R'] bore\n",
      "['b', 'aw', 'r']\n",
      "['B', 'AO1', 'R', 'D'] bored\n",
      "['b', 'aw', 'r', 'd']\n",
      "['B', 'OW1', 'L', 'D'] bowled\n",
      "['b', 'o', 'l', 'd']\n",
      "['B', 'R', 'EY1', 'K', 'S'] brakes\n",
      "['b', 'r', 'ay', ['ks', ['k', 's']]]\n",
      "['B', 'R', 'EH1', 'D'] bread\n",
      "['b', 'r', 'eh', 'd']\n",
      "['B', 'R', 'EY1', 'K', 'S'] breaks\n",
      "['b', 'r', 'ay', ['ks', ['k', 's']]]\n",
      "['B', 'R', 'EH1', 'D'] bred\n",
      "['b', 'r', 'eh', 'd']\n",
      "['B', 'IH1', 'L', 'D'] build\n",
      "['b', 'ih', 'l', 'd']\n",
      "['B', 'EH1', 'R', 'IY0'] bury\n",
      "['b', 'eh', 'r', 'ee']\n",
      "['K', 'AE1', 'L', 'AH0', 'S'] callous\n",
      "['k', 'ae', 'l', 'uh-', 's']\n",
      "['K', 'AE1', 'L', 'AH0', 'S'] callus\n",
      "['k', 'ae', 'l', 'uh-', 's']\n",
      "['K', 'AE1', 'P', 'AH0', 'T', 'AH0', 'L'] capital\n",
      "['k', 'ae', 'p', 'uh-', 't', ['ul', ['uh-', 'l']]]\n",
      "['K', 'AE1', 'P', 'IH0', 'T', 'AH0', 'L'] capitol\n",
      "['k', 'ae', 'p', 'ih', 't', ['ul', ['uh-', 'l']]]\n",
      "['S', 'IY1', 'L', 'IH0', 'NG'] ceiling\n",
      "['s', 'ee', 'l', 'ih', 'ng']\n",
      "['S', 'EH1', 'L'] cell\n",
      "['s', 'eh', 'l']\n",
      "['S', 'EH1', 'L', 'ER0'] cellar\n",
      "['s', 'eh', 'l', 'er']\n",
      "['S', 'EH1', 'L', 'ER0', 'Z'] cellars\n",
      "['s', 'eh', 'l', 'er', 'z']\n",
      "['S', 'EH1', 'L', 'Z'] cells\n",
      "['s', 'eh', 'l', 'z']\n",
      "['S', 'EH1', 'N', 'T'] cent\n",
      "['s', 'eh', 'n', 't']\n",
      "['S', 'EH1', 'N', 'T', 'S'] cents\n",
      "['s', 'eh', 'n', 't', 's']\n",
      "['S', 'IH1', 'R', 'IY0', 'AH0', 'L'] cereal\n",
      "['s', 'ih', 'r', 'ee', ['ul', ['uh-', 'l']]]\n",
      "['CH', 'UW1', 'Z'] chews\n",
      "['tch', 'oo', 'z']\n",
      "['CH', 'IH1', 'L', 'IY0'] chile\n",
      "['tch', 'ih', 'l', 'ee']\n",
      "['CH', 'IH1', 'L', 'IY0'] chilly\n",
      "['tch', 'ih', 'l', 'ee']\n",
      "['CH', 'UW1', 'Z'] choose\n",
      "['tch', 'oo', 'z']\n",
      "['K', 'AO1', 'R', 'D'] chord\n",
      "['k', 'aw', 'r', 'd']\n",
      "['K', 'AO1', 'R', 'D', 'Z'] chords\n",
      "['k', 'aw', 'r', 'd', 'z']\n",
      "['SH', 'UW1', 'T'] chute\n",
      "['sh', 'oo', 't']\n",
      "['SH', 'UW1', 'T', 'S'] chutes\n",
      "['sh', 'oo', 't', 's']\n",
      "['K', 'AO1', 'R', 'S'] coarse\n",
      "['k', 'aw', 'r', 's']\n",
      "['K', 'OW1', 'K', 'OW2'] coco\n",
      "['k', 'o', 'k', 'o']\n",
      "['K', 'OW1', 'K', 'OW0'] cocoa\n",
      "['k', 'o', 'k', 'o']\n",
      "['K', 'AO1', 'R', 'D'] cord\n",
      "['k', 'aw', 'r', 'd']\n",
      "['K', 'AO1', 'R', 'D', 'Z'] cords\n",
      "['k', 'aw', 'r', 'd', 'z']\n",
      "['K', 'AO1', 'R'] core\n",
      "['k', 'aw', 'r']\n",
      "['K', 'AO1', 'R'] corps\n",
      "['k', 'aw', 'r']\n",
      "['K', 'AW1', 'N', 'S', 'AH0', 'L'] council\n",
      "['k', 'au', 'n', 's', ['ul', ['uh-', 'l']]]\n",
      "['K', 'AW1', 'N', 'S', 'AH0', 'L'] counsel\n",
      "['k', 'au', 'n', 's', ['ul', ['uh-', 'l']]]\n",
      "['K', 'AO1', 'R', 'S'] course\n",
      "['k', 'aw', 'r', 's']\n",
      "['K', 'R', 'UW1', 'Z'] crews\n",
      "['k', 'r', 'oo', 'z']\n",
      "['K', 'R', 'UW1', 'Z'] cruise\n",
      "['k', 'r', 'oo', 'z']\n",
      "['D', 'IH1', 'R'] dear\n",
      "['d', 'ih', 'r']\n",
      "['D', 'IH1', 'R'] deer\n",
      "['d', 'ih', 'r']\n",
      "['D', 'UW1'] dew\n",
      "['d', 'oo']\n",
      "['D', 'AY1'] die\n",
      "['d', 'ai']\n",
      "['D', 'AY1', 'D'] died\n",
      "['d', 'ai', 'd']\n",
      "['D', 'AY1', 'Z'] dies\n",
      "['d', 'ai', 'z']\n",
      "['D', 'AA1', 'K'] doc\n",
      "['d', 'ah']\n",
      "['D', 'AA1', 'K'] dock\n",
      "['d', 'ah']\n",
      "['D', 'OW1'] doe\n",
      "['d', 'o']\n",
      "['D', 'OW1'] dough\n",
      "['d', 'o']\n",
      "['D', 'R', 'AY1', 'ER0'] drier\n",
      "['d', 'r', 'ai', 'er']\n",
      "['D', 'R', 'AY1', 'ER0'] dryer\n",
      "['d', 'r', 'ai', 'er']\n",
      "['D', 'UW1'] due\n",
      "['d', 'oo']\n",
      "['D', 'AY1'] dye\n",
      "['d', 'ai']\n",
      "['D', 'AY1', 'D'] dyed\n",
      "['d', 'ai', 'd']\n",
      "['D', 'AY1', 'Z'] dyes\n",
      "['d', 'ai', 'z']\n",
      "['IH0', 'L', 'IH1', 'S', 'IH0', 'T'] elicit\n",
      "['ih', 'l', 'ih', 's', 'ih', 't']\n",
      "['EH0', 'N', 'SH', 'UH1', 'R'] ensure\n",
      "['eh', 'n', 'sh', 'u', 'r']\n",
      "['F', 'EH1', 'R'] fair\n",
      "['f', 'eh', 'r']\n",
      "['F', 'EH1', 'R'] fare\n",
      "['f', 'eh', 'r']\n",
      "['F', 'IY1', 'T'] feat\n",
      "['f', 'ee', 't']\n",
      "['F', 'IY1', 'T'] feet\n",
      "['f', 'ee', 't']\n",
      "['F', 'IY0', 'AA1', 'N', 'S', 'EY2'] fiance\n",
      "['f', 'ee', 'ah', 'n', 's', 'ay']\n",
      "['F', 'IY0', 'AE1', 'N', 'S', 'IY0'] fiancee\n",
      "['f', 'ee', 'ae', 'n', 's', 'ee']\n",
      "['F', 'IH1', 'L'] fill\n",
      "['f', 'ih', 'l']\n",
      "['F', 'AY1', 'N', 'D'] find\n",
      "['f', 'ai', 'n', 'd']\n",
      "['F', 'AY1', 'N', 'D'] fined\n",
      "['f', 'ai', 'n', 'd']\n",
      "['F', 'L', 'EH1', 'R'] flair\n",
      "['f', 'l', 'eh', 'r']\n",
      "['F', 'L', 'EH1', 'R'] flare\n",
      "['f', 'l', 'eh', 'r']\n",
      "['F', 'L', 'IY1'] flea\n",
      "['f', 'l', 'ee']\n",
      "['F', 'L', 'IY1'] flee\n",
      "['f', 'l', 'ee']\n",
      "['F', 'L', 'UW1'] flew\n",
      "['f', 'l', 'oo']\n",
      "['F', 'L', 'AW1', 'ER0'] flour\n",
      "['f', 'l', 'au', 'er']\n",
      "['F', 'L', 'AW1', 'ER0'] flower\n",
      "['f', 'l', 'au', 'er']\n",
      "['F', 'L', 'AW1', 'ER0', 'Z'] flowers\n",
      "['f', 'l', 'au', 'er', 'z']\n",
      "['F', 'L', 'UW1'] flu\n",
      "['f', 'l', 'oo']\n",
      "['F', 'R', 'AE1', 'NG', 'K'] franc\n",
      "['f', 'r', 'ae', 'ng']\n",
      "['F', 'R', 'AE1', 'NG', 'K'] frank\n",
      "['f', 'r', 'ae', 'ng']\n",
      "['G', 'R', 'EY1', 'T'] grate\n",
      "['g', 'r', 'ay', 't']\n",
      "['G', 'R', 'EY1', 'T'] great\n",
      "['g', 'r', 'ay', 't']\n",
      "['G', 'R', 'IH1', 'Z', 'L', 'IY0'] grisly\n",
      "['g', 'r', 'ih', 'z', 'l', 'ee']\n",
      "['G', 'R', 'IH1', 'Z', 'L', 'IY0'] grizzly\n",
      "['g', 'r', 'ih', 'z', 'l', 'ee']\n",
      "['G', 'EH1', 'S', 'T'] guessed\n",
      "['g', 'eh', 's', 't']\n",
      "['G', 'EH1', 'S', 'T'] guest\n",
      "['g', 'eh', 's', 't']\n",
      "['G', 'AY1', 'Z'] guise\n",
      "['g', 'ai', 'z']\n",
      "['G', 'AY1', 'Z'] guys\n",
      "['g', 'ai', 'z']\n",
      "['JH', 'IH1', 'M'] gym\n",
      "['dj', 'ih', 'm']\n",
      "['HH', 'AO1', 'L'] hall\n",
      "['h', 'aw', 'l']\n",
      "['HH', 'AO1', 'L', 'Z'] halls\n",
      "['h', 'aw', 'l', 'z']\n",
      "['HH', 'AA1', 'R', 'T'] hart\n",
      "['h', 'ah', 'r', 't']\n",
      "['HH', 'AO1', 'L'] haul\n",
      "['h', 'aw', 'l']\n",
      "['HH', 'AO1', 'L', 'Z'] hauls\n",
      "['h', 'aw', 'l', 'z']\n",
      "['HH', 'IY1', 'L'] heal\n",
      "['h', 'ee', 'l']\n",
      "['HH', 'IY1', 'L', 'Z'] heals\n",
      "['h', 'ee', 'l', 'z']\n",
      "['HH', 'IY1', 'R'] hear\n",
      "['h', 'ee', 'r']\n",
      "['HH', 'ER1', 'D'] heard\n",
      "['h', 'er', 'd']\n",
      "['HH', 'AA1', 'R', 'T'] heart\n",
      "['h', 'ah', 'r', 't']\n",
      "['HH', 'IY1', 'L'] heel\n",
      "['h', 'ee', 'l']\n",
      "['HH', 'IY1', 'L', 'Z'] heels\n",
      "['h', 'ee', 'l', 'z']\n",
      "['EH1', 'R', 'Z'] heirs\n",
      "['eh', 'r', 'z']\n",
      "['HH', 'ER1', 'D'] herd\n",
      "['h', 'er', 'd']\n",
      "['HH', 'IY1', 'R'] here\n",
      "['h', 'ee', 'r']\n",
      "['HH', 'EH1', 'R', 'T', 'S'] hertz\n",
      "['h', 'eh', 'r', 't', 's']\n",
      "['HH', 'AY1', 'ER0'] higher\n",
      "['h', 'ai', 'er']\n",
      "['HH', 'AY1', 'ER0'] hire\n",
      "['h', 'ai', 'er']\n",
      "['HH', 'AO1', 'R', 'S'] hoarse\n",
      "['h', 'aw', 'r', 's']\n",
      "['HH', 'OW1', 'L', 'D'] hold\n",
      "['h', 'o', 'l', 'd']\n",
      "['HH', 'OW1', 'L'] hole\n",
      "['h', 'o', 'l']\n",
      "['HH', 'OW1', 'L', 'D'] holed\n",
      "['h', 'o', 'l', 'd']\n",
      "['HH', 'OW1', 'L', 'Z'] holes\n",
      "['h', 'o', 'l', 'z']\n",
      "['HH', 'AO1', 'R', 'S'] horse\n",
      "['h', 'aw', 'r', 's']\n",
      "['HH', 'ER1', 'T', 'S'] hurts\n",
      "['h', 'er', 't', 's']\n",
      "['IH0', 'L', 'IH1', 'S', 'AH0', 'T'] illicit\n",
      "['ih', 'l', 'ih', 's', 'uh-', 't']\n",
      "['IH0', 'N', 'SH', 'UH1', 'R'] insure\n",
      "['ih', 'n', 'sh', 'u', 'r']\n",
      "['JH', 'IH1', 'M'] jim\n",
      "['dj', 'ih', 'm']\n",
      "['N', 'IY1', 'D', 'IH0', 'NG'] kneading\n",
      "['n', 'ee', 'd', 'ih', 'ng']\n",
      "['N', 'UW1'] knew\n",
      "['n', 'oo']\n",
      "['N', 'AY1', 'T'] knight\n",
      "['n', 'ai', 't']\n",
      "['N', 'AY1', 'T', 'S'] knights\n",
      "['n', 'ai', 't', 's']\n",
      "['N', 'IH1', 'T'] knit\n",
      "['n', 'ih', 't']\n",
      "['N', 'OW1', 'Z'] knows\n",
      "['n', 'o', 'z']\n",
      "['L', 'AE1', 'K', 'S'] lacks\n",
      "['l', 'ae', ['ks', ['k', 's']]]\n",
      "['L', 'AE1', 'K', 'S'] lax\n",
      "['l', 'ae', ['ks', ['k', 's']]]\n",
      "['L', 'IY1'] lea\n",
      "['l', 'ee']\n",
      "['L', 'IY1', 'S', 'T'] leased\n",
      "['l', 'ee', 's', 't']\n",
      "['L', 'IY1', 'S', 'T'] least\n",
      "['l', 'ee', 's', 't']\n",
      "['L', 'IY1'] lee\n",
      "['l', 'ee']\n",
      "['L', 'EH1', 'S', 'AH0', 'N'] lessen\n",
      "['l', 'eh', 's', ['un', ['uh-', 'n']]]\n",
      "['L', 'EH1', 'S', 'AH0', 'N'] lesson\n",
      "['l', 'eh', 's', ['un', ['uh-', 'n']]]\n",
      "['L', 'EH1', 'V', 'IY0'] levee\n",
      "['l', 'eh', 'v', 'ee']\n",
      "['L', 'EH1', 'V', 'IY0'] levy\n",
      "['l', 'eh', 'v', 'ee']\n",
      "['L', 'OW1', 'N'] loan\n",
      "['l', 'o', 'n']\n",
      "['L', 'OW1', 'N'] lone\n",
      "['l', 'o', 'n']\n",
      "['L', 'AH1', 'M', 'B', 'AA2', 'R'] lumbar\n",
      "['l', 'uh+', 'm', 'b', 'ah', 'r']\n",
      "['L', 'AH1', 'M', 'B', 'ER0'] lumber\n",
      "['l', 'uh+', 'm', 'b', 'er']\n",
      "['M', 'AE1', 'K'] mac\n",
      "['m', 'ae']\n",
      "['M', 'AA1', 'K'] mach\n",
      "['m', 'ah']\n",
      "['M', 'EY1', 'D'] made\n",
      "['m', 'ay', 'd']\n",
      "['M', 'EY1', 'D'] maid\n",
      "['m', 'ay', 'd']\n",
      "['M', 'EY1', 'L'] mail\n",
      "['m', 'ay', 'l']\n",
      "['M', 'EY1', 'L', 'Z'] mails\n",
      "['m', 'ay', 'l', 'z']\n",
      "['M', 'EY1', 'L'] male\n",
      "['m', 'ay', 'l']\n",
      "['M', 'EY1', 'L', 'Z'] males\n",
      "['m', 'ay', 'l', 'z']\n",
      "['M', 'AO1', 'L'] mall\n",
      "['m', 'aw', 'l']\n",
      "['M', 'AE1', 'N', 'ER0'] manner\n",
      "['m', 'ae', 'n', 'er']\n",
      "['M', 'AE1', 'N', 'ER0'] manor\n",
      "['m', 'ae', 'n', 'er']\n",
      "['M', 'AA1', 'R', 'K', 'S'] marks\n",
      "['m', 'ah', 'r', ['ks', ['k', 's']]]\n",
      "['M', 'AA1', 'R', 'K', 'S'] marx\n",
      "['m', 'ah', 'r', ['ks', ['k', 's']]]\n",
      "['M', 'AO1', 'L'] maul\n",
      "['m', 'aw', 'l']\n",
      "['M', 'IY1', 'T'] meat\n",
      "['m', 'ee', 't']\n",
      "['M', 'IY1', 'T', 'S'] meats\n",
      "['m', 'ee', 't', 's']\n",
      "['M', 'IY1', 'T'] meet\n",
      "['m', 'ee', 't']\n",
      "['M', 'IY1', 'T', 'S'] meets\n",
      "['m', 'ee', 't', 's']\n",
      "['M', 'IH1', 'S', 'T'] missed\n",
      "['m', 'ih', 's', 't']\n",
      "['M', 'IH1', 'S', 'T'] mist\n",
      "['m', 'ih', 's', 't']\n",
      "['M', 'OW1', 'D'] mode\n",
      "['m', 'o', 'd']\n",
      "['M', 'UW1', 'S'] moose\n",
      "['m', 'oo', 's']\n",
      "['M', 'AO1', 'R', 'N', 'IH0', 'NG'] morning\n",
      "['m', 'aw', 'r', 'n', 'ih', 'ng']\n",
      "['M', 'AO1', 'R', 'N', 'IH0', 'NG'] mourning\n",
      "['m', 'aw', 'r', 'n', 'ih', 'ng']\n",
      "['M', 'OW1', 'D'] mowed\n",
      "['m', 'o', 'd']\n",
      "['N', 'EY1', 'V', 'AH0', 'L'] naval\n",
      "['n', 'ay', 'v', ['ul', ['uh-', 'l']]]\n",
      "['N', 'IY1', 'D', 'IH0', 'NG'] needing\n",
      "['n', 'ee', 'd', 'ih', 'ng']\n",
      "['N', 'UW1'] new\n",
      "['n', 'oo']\n",
      "['N', 'AY1', 'T'] night\n",
      "['n', 'ai', 't']\n",
      "['N', 'AY1', 'T', 'S'] nights\n",
      "['n', 'ai', 't', 's']\n",
      "['N', 'IH1', 'T'] nit\n",
      "['n', 'ih', 't']\n",
      "['N', 'OW1', 'Z'] nose\n",
      "['n', 'o', 'z']\n",
      "['P', 'EY1', 'S', 'T'] paced\n",
      "['p', 'ay', 's', 't']\n",
      "['P', 'AE1', 'K', 'T'] packed\n",
      "['p', 'ae', 'k', 't']\n",
      "['P', 'AE1', 'K', 'T'] pact\n",
      "['p', 'ae', 'k', 't']\n",
      "['P', 'EY1', 'N'] pain\n",
      "['p', 'ay', 'n']\n",
      "['P', 'EY1', 'N', 'Z'] pains\n",
      "['p', 'ay', 'n', 'z']\n",
      "['P', 'EH1', 'R'] pair\n",
      "['p', 'eh', 'r']\n",
      "['P', 'EH1', 'R', 'Z'] pairs\n",
      "['p', 'eh', 'r', 'z']\n",
      "['P', 'EY1', 'N'] pane\n",
      "['p', 'ay', 'n']\n",
      "['P', 'EY1', 'N', 'Z'] panes\n",
      "['p', 'ay', 'n', 'z']\n",
      "['P', 'AE1', 'S', 'T'] passed\n",
      "['p', 'ae', 's', 't']\n",
      "['P', 'AE1', 'S', 'T'] past\n",
      "['p', 'ae', 's', 't']\n",
      "['P', 'EY1', 'S', 'T'] paste\n",
      "['p', 'ay', 's', 't']\n",
      "['P', 'AO1', 'Z'] pause\n",
      "['p', 'aw', 'z']\n",
      "['P', 'AO1', 'Z'] paws\n",
      "['p', 'aw', 'z']\n",
      "['P', 'IY1'] pea\n",
      "['p', 'ee']\n",
      "['P', 'IY1', 'S'] peace\n",
      "['p', 'ee', 's']\n",
      "['P', 'IY1', 'K'] peak\n",
      "['p', 'ee']\n",
      "['P', 'IY1', 'K', 'T'] peaked\n",
      "['p', 'ee', 'k', 't']\n",
      "['P', 'EH1', 'R'] pear\n",
      "['p', 'eh', 'r']\n",
      "['P', 'IY1'] pee\n",
      "['p', 'ee']\n",
      "['P', 'IY1', 'K'] peek\n",
      "['p', 'ee']\n",
      "['P', 'IH1', 'R'] peer\n",
      "['p', 'ih', 'r']\n",
      "['P', 'IH1', 'R', 'Z'] peers\n",
      "['p', 'ih', 'r', 'z']\n",
      "['F', 'IH1', 'L'] phil\n",
      "['f', 'ih', 'l']\n",
      "['P', 'AY1'] pi\n",
      "['p', 'ai']\n",
      "['P', 'AY1'] pie\n",
      "['p', 'ai']\n",
      "['P', 'IY1', 'S'] piece\n",
      "['p', 'ee', 's']\n",
      "['P', 'IH1', 'R'] pier\n",
      "['p', 'ih', 'r']\n",
      "['P', 'IH1', 'R', 'Z'] piers\n",
      "['p', 'ih', 'r', 'z']\n",
      "['P', 'IY1', 'K', 'T'] piqued\n",
      "['p', 'ee', 'k', 't']\n",
      "['P', 'L', 'EY1', 'N'] plain\n",
      "['p', 'l', 'ay', 'n']\n",
      "['P', 'L', 'EY1', 'N', 'Z'] plains\n",
      "['p', 'l', 'ay', 'n', 'z']\n",
      "['P', 'L', 'EY1', 'N'] plane\n",
      "['p', 'l', 'ay', 'n']\n",
      "['P', 'L', 'EY1', 'N', 'Z'] planes\n",
      "['p', 'l', 'ay', 'n', 'z']\n",
      "['P', 'L', 'AH1', 'M'] plum\n",
      "['p', 'l', 'uh+', 'm']\n",
      "['P', 'L', 'AH1', 'M'] plumb\n",
      "['p', 'l', 'uh+', 'm']\n",
      "['P', 'OW1', 'L'] pole\n",
      "['p', 'o', 'l']\n",
      "['P', 'OW1', 'L', 'Z'] poles\n",
      "['p', 'o', 'l', 'z']\n",
      "['P', 'OW1', 'L'] poll\n",
      "['p', 'o', 'l']\n",
      "['P', 'OW1', 'L', 'Z'] polls\n",
      "['p', 'o', 'l', 'z']\n",
      "['P', 'AA1', 'P', 'Y', 'AH0', 'L', 'AH0', 'S'] populace\n",
      "['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "['P', 'AA1', 'P', 'Y', 'AH0', 'L', 'AH0', 'S'] populous\n",
      "['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "['P', 'R', 'EY1', 'Z'] praise\n",
      "['p', 'r', 'ay', 'z']\n",
      "['P', 'R', 'EY1'] pray\n",
      "['p', 'r', 'ay']\n",
      "['P', 'R', 'EY1', 'IH0', 'NG'] praying\n",
      "['p', 'r', 'ay', 'ih', 'ng']\n",
      "['P', 'R', 'EY1'] prey\n",
      "['p', 'r', 'ay']\n",
      "['P', 'R', 'EY1', 'IH0', 'NG'] preying\n",
      "['p', 'r', 'ay', 'ih', 'ng']\n",
      "['P', 'R', 'EY1', 'Z'] preys\n",
      "['p', 'r', 'ay', 'z']\n",
      "['P', 'R', 'IH1', 'N', 'S', 'AH0', 'P', 'AH0', 'L'] principal\n",
      "['p', 'r', 'ih', 'n', 's', 'uh-', 'p', ['ul', ['uh-', 'l']]]\n",
      "['P', 'R', 'IH1', 'N', 'S', 'AH0', 'P', 'AH0', 'L'] principle\n",
      "['p', 'r', 'ih', 'n', 's', 'uh-', 'p', ['ul', ['uh-', 'l']]]\n",
      "['P', 'UH1', 'T', 'S'] puts\n",
      "['p', 'u', 't', 's']\n",
      "['P', 'AH1', 'T', 'S'] putts\n",
      "['p', 'uh+', 't', 's']\n",
      "['R', 'AE1', 'K'] rack\n",
      "['r', 'ae']\n",
      "['R', 'EY1', 'N'] rain\n",
      "['r', 'ay', 'n']\n",
      "['R', 'EY1', 'N', 'D'] rained\n",
      "['r', 'ay', 'n', 'd']\n",
      "['R', 'EY1', 'N', 'Z'] rains\n",
      "['r', 'ay', 'n', 'z']\n",
      "['R', 'EY1', 'Z'] raise\n",
      "['r', 'ay', 'z']\n",
      "['R', 'AE1', 'P'] rap\n",
      "['r', 'ae', 'p']\n",
      "['R', 'EY1', 'Z'] rays\n",
      "['r', 'ay', 'z']\n",
      "['R', 'IY1', 'K', 'S'] reeks\n",
      "['r', 'ee', ['ks', ['k', 's']]]\n",
      "['R', 'EY1', 'N', 'D'] reigned\n",
      "['r', 'ay', 'n', 'd']\n",
      "['R', 'EY1', 'N'] rein\n",
      "['r', 'ay', 'n']\n",
      "['R', 'EY1', 'N', 'Z'] reins\n",
      "['r', 'ay', 'n', 'z']\n",
      "['R', 'AY1', 'T'] right\n",
      "['r', 'ai', 't']\n",
      "['R', 'AY1', 'T', 'S'] rights\n",
      "['r', 'ai', 't', 's']\n",
      "['R', 'IH1', 'NG'] ring\n",
      "['r', 'ih', 'ng']\n",
      "['R', 'IH1', 'NG', 'IH0', 'NG'] ringing\n",
      "['r', 'ih', 'ng', 'ih', 'ng']\n",
      "['R', 'OW1', 'D'] road\n",
      "['r', 'o', 'd']\n",
      "['R', 'OW1', 'M'] roam\n",
      "['r', 'o', 'm']\n",
      "['R', 'OW1', 'D'] rode\n",
      "['r', 'o', 'd']\n",
      "['R', 'OW1', 'L', 'Z'] roles\n",
      "['r', 'o', 'l', 'z']\n",
      "['R', 'OW1', 'L', 'Z'] rolls\n",
      "['r', 'o', 'l', 'z']\n",
      "['R', 'OW1', 'M'] rome\n",
      "['r', 'o', 'm']\n",
      "['R', 'OW1', 'Z'] rose\n",
      "['r', 'o', 'z']\n",
      "['R', 'OW1', 'T'] rote\n",
      "['r', 'o', 't']\n",
      "['R', 'AH1', 'F'] rough\n",
      "['r', 'uh+', 'f']\n",
      "['R', 'OW1', 'Z'] rows\n",
      "['r', 'o', 'z']\n",
      "['R', 'AH1', 'F'] ruff\n",
      "['r', 'uh+', 'f']\n",
      "['S', 'AE1', 'K'] sac\n",
      "['s', 'ae']\n",
      "['S', 'AE1', 'K'] sack\n",
      "['s', 'ae']\n",
      "['S', 'AE1', 'K', 'S'] sacks\n",
      "['s', 'ae', ['ks', ['k', 's']]]\n",
      "['S', 'EY1', 'L'] sail\n",
      "['s', 'ay', 'l']\n",
      "['S', 'EY1', 'L', 'Z'] sails\n",
      "['s', 'ay', 'l', 'z']\n",
      "['S', 'EY1', 'L'] sale\n",
      "['s', 'ay', 'l']\n",
      "['S', 'EY1', 'L', 'Z'] sales\n",
      "['s', 'ay', 'l', 'z']\n",
      "['S', 'AE1', 'K', 'S'] sax\n",
      "['s', 'ae', ['ks', ['k', 's']]]\n",
      "['S', 'IY1', 'N'] scene\n",
      "['s', 'ee', 'n']\n",
      "['S', 'EH1', 'N', 'T', 'S'] scents\n",
      "['s', 'eh', 'n', 't', 's']\n",
      "['S', 'IY1'] sea\n",
      "['s', 'ee']\n",
      "['S', 'IY1', 'L', 'IH0', 'NG'] sealing\n",
      "['s', 'ee', 'l', 'ih', 'ng']\n",
      "['S', 'IY1', 'M'] seam\n",
      "['s', 'ee', 'm']\n",
      "['S', 'IY1', 'M', 'Z'] seams\n",
      "['s', 'ee', 'm', 'z']\n",
      "['S', 'IY1', 'Z'] seas\n",
      "['s', 'ee', 'z']\n",
      "['S', 'IY1'] see\n",
      "['s', 'ee']\n",
      "['S', 'IY1', 'M'] seem\n",
      "['s', 'ee', 'm']\n",
      "['S', 'IY1', 'M', 'Z'] seems\n",
      "['s', 'ee', 'm', 'z']\n",
      "['S', 'IY1', 'N'] seen\n",
      "['s', 'ee', 'n']\n",
      "['S', 'IY1', 'Z'] sees\n",
      "['s', 'ee', 'z']\n",
      "['S', 'EH1', 'L'] sell\n",
      "['s', 'eh', 'l']\n",
      "['S', 'EH1', 'L', 'ER0'] seller\n",
      "['s', 'eh', 'l', 'er']\n",
      "['S', 'EH1', 'L', 'ER0', 'Z'] sellers\n",
      "['s', 'eh', 'l', 'er', 'z']\n",
      "['S', 'EH1', 'L', 'Z'] sells\n",
      "['s', 'eh', 'l', 'z']\n",
      "['S', 'EH1', 'N', 'T'] sent\n",
      "['s', 'eh', 'n', 't']\n",
      "['S', 'IH1', 'R', 'IY0', 'AH0', 'L'] serial\n",
      "['s', 'ih', 'r', 'ee', ['ul', ['uh-', 'l']]]\n",
      "['SH', 'IH1', 'R'] shear\n",
      "['sh', 'ih', 'r']\n",
      "['SH', 'IH1', 'R'] sheer\n",
      "['sh', 'ih', 'r']\n",
      "['SH', 'UW1', 'T'] shoot\n",
      "['sh', 'oo', 't']\n",
      "['SH', 'UW1', 'T', 'S'] shoots\n",
      "['sh', 'oo', 't', 's']\n",
      "['S', 'AY1', 'T'] sight\n",
      "['s', 'ai', 't']\n",
      "['S', 'AY1', 'T', 'AH0', 'D'] sighted\n",
      "['s', 'ai', 't', 'uh-', 'd']\n",
      "['S', 'AY1', 'T', 'S'] sights\n",
      "['s', 'ai', 't', 's']\n",
      "['S', 'IH1', 'NG', 'K'] sink\n",
      "['s', 'ih', 'ng']\n",
      "['S', 'AY1', 'T'] site\n",
      "['s', 'ai', 't']\n",
      "['S', 'AY1', 'T', 'IH0', 'D'] sited\n",
      "['s', 'ai', 't', 'ih', 'd']\n",
      "['S', 'AY1', 'T', 'S'] sites\n",
      "['s', 'ai', 't', 's']\n",
      "['S', 'L', 'EY1'] slay\n",
      "['s', 'l', 'ay']\n",
      "['S', 'L', 'EY1'] sleigh\n",
      "['s', 'l', 'ay']\n",
      "['S', 'OW1', 'L'] sole\n",
      "['s', 'o', 'l']\n",
      "['S', 'OW1', 'L', 'Z'] soles\n",
      "['s', 'o', 'l', 'z']\n",
      "['S', 'AH1', 'N'] son\n",
      "['s', 'uh+', 'n']\n",
      "['S', 'AH1', 'N', 'Z'] sons\n",
      "['s', 'uh+', 'n', 'z']\n",
      "['S', 'OW1', 'L'] soul\n",
      "['s', 'o', 'l']\n",
      "['S', 'OW1', 'L', 'Z'] souls\n",
      "['s', 'o', 'l', 'z']\n",
      "['S', 'P', 'EY1', 'D'] spade\n",
      "['s', 'p', 'ay', 'd']\n",
      "['S', 'P', 'EY1', 'D'] spayed\n",
      "['s', 'p', 'ay', 'd']\n",
      "['S', 'T', 'EY1', 'K'] stake\n",
      "['s', 't', 'ay']\n",
      "['S', 'T', 'EY1', 'K', 'S'] stakes\n",
      "['s', 't', 'ay', ['ks', ['k', 's']]]\n",
      "['S', 'T', 'EY1', 'K'] steak\n",
      "['s', 't', 'ay']\n",
      "['S', 'T', 'EY1', 'K', 'S'] steaks\n",
      "['s', 't', 'ay', ['ks', ['k', 's']]]\n",
      "['S', 'T', 'IY1', 'L'] steal\n",
      "['s', 't', 'ee', 'l']\n",
      "['S', 'T', 'IY1', 'L'] steel\n",
      "['s', 't', 'ee', 'l']\n",
      "['S', 'T', 'R', 'EY1', 'T'] straight\n",
      "['s', 't', 'r', 'ay', 't']\n",
      "['S', 'T', 'R', 'EY1', 'T'] strait\n",
      "['s', 't', 'r', 'ay', 't']\n",
      "['S', 'W', 'EY1', 'D'] suede\n",
      "['s', 'w', 'ay', 'd']\n",
      "['S', 'W', 'IY1', 'T', 'S'] suites\n",
      "['s', 'w', 'ee', 't', 's']\n",
      "['S', 'AH1', 'N'] sun\n",
      "['s', 'uh+', 'n']\n",
      "['S', 'AH1', 'N', 'Z'] suns\n",
      "['s', 'uh+', 'n', 'z']\n",
      "['S', 'W', 'EY1', 'D'] swayed\n",
      "['s', 'w', 'ay', 'd']\n",
      "['S', 'W', 'IY1', 'T', 'S'] sweets\n",
      "['s', 'w', 'ee', 't', 's']\n",
      "['S', 'IH1', 'NG', 'K'] sync\n",
      "['s', 'ih', 'ng']\n",
      "['T', 'AE1', 'K', 'S'] tacks\n",
      "['t', 'ae', ['ks', ['k', 's']]]\n",
      "['T', 'EY1', 'L'] tail\n",
      "['t', 'ay', 'l']\n",
      "['T', 'EY1', 'L', 'Z'] tails\n",
      "['t', 'ay', 'l', 'z']\n",
      "['T', 'EY1', 'L'] tale\n",
      "['t', 'ay', 'l']\n",
      "['T', 'EY1', 'L', 'Z'] tales\n",
      "['t', 'ay', 'l', 'z']\n",
      "['T', 'AO1', 'T'] taught\n",
      "['t', 'aw', 't']\n",
      "['T', 'AE1', 'K', 'S'] tax\n",
      "['t', 'ae', ['ks', ['k', 's']]]\n",
      "['T', 'IY1'] tea\n",
      "['t', 'ee']\n",
      "['T', 'IY1', 'Z'] teas\n",
      "['t', 'ee', 'z']\n",
      "['T', 'IY1', 'Z'] tease\n",
      "['t', 'ee', 'z']\n",
      "['T', 'EH1', 'K'] tec\n",
      "['t', 'eh']\n",
      "['T', 'EH1', 'K'] tech\n",
      "['t', 'eh']\n",
      "['T', 'IY1'] tee\n",
      "['t', 'ee']\n",
      "['T', 'AY1'] thai\n",
      "['t', 'ai']\n",
      "['T', 'AY1', 'Z'] thais\n",
      "['t', 'ai', 'z']\n",
      "['TH', 'R', 'OW1', 'Z'] throes\n",
      "['th-', 'r', 'o', 'z']\n",
      "['TH', 'R', 'OW1', 'Z'] throws\n",
      "['th-', 'r', 'o', 'z']\n",
      "['TH', 'AY1', 'M'] thyme\n",
      "['th-', 'ai', 'm']\n",
      "['T', 'IH1', 'K'] tic\n",
      "['t', 'ih']\n",
      "['T', 'IH1', 'K'] tick\n",
      "['t', 'ih']\n",
      "['T', 'AY1', 'D'] tide\n",
      "['t', 'ai', 'd']\n",
      "['T', 'AY1'] tie\n",
      "['t', 'ai']\n",
      "['T', 'AY1', 'D'] tied\n",
      "['t', 'ai', 'd']\n",
      "['T', 'AY1', 'Z'] ties\n",
      "['t', 'ai', 'z']\n",
      "['T', 'AY1', 'M'] time\n",
      "['t', 'ai', 'm']\n",
      "['T', 'OW1'] toe\n",
      "['t', 'o']\n",
      "['T', 'OW1'] tow\n",
      "['t', 'o']\n",
      "['T', 'R', 'AE1', 'K', 'T'] tracked\n",
      "['t', 'r', 'ae', 'k', 't']\n",
      "['T', 'R', 'AE1', 'K', 'T'] tract\n",
      "['t', 'r', 'ae', 'k', 't']\n",
      "['W', 'EY1', 'D'] wade\n",
      "['w', 'ay', 'd']\n",
      "['W', 'EY1', 'S', 'T'] waist\n",
      "['w', 'ay', 's', 't']\n",
      "['W', 'EY1', 'T'] wait\n",
      "['w', 'ay', 't']\n",
      "['W', 'EY1', 'T', 'IH0', 'NG'] waiting\n",
      "['w', 'ay', 't', 'ih', 'ng']\n",
      "['W', 'EY1', 'T', 'S'] waits\n",
      "['w', 'ay', 't', 's']\n",
      "['W', 'EY1', 'V'] waive\n",
      "['w', 'ay', 'v']\n",
      "['W', 'AO1', 'R'] war\n",
      "['w', 'aw', 'r']\n",
      "['W', 'AO1', 'R', 'N'] warn\n",
      "['w', 'aw', 'r', 'n']\n",
      "['W', 'EY1', 'S', 'T'] waste\n",
      "['w', 'ay', 's', 't']\n",
      "['W', 'EY1', 'V'] wave\n",
      "['w', 'ay', 'v']\n",
      "['W', 'AE1', 'K', 'S'] wax\n",
      "['w', 'ae', ['ks', ['k', 's']]]\n",
      "['W', 'EY1'] way\n",
      "['w', 'ay']\n",
      "['W', 'EY1', 'Z'] ways\n",
      "['w', 'ay', 'z']\n",
      "['W', 'IY1', 'K'] weak\n",
      "['w', 'ee']\n",
      "['W', 'IY1', 'K'] week\n",
      "['w', 'ee']\n",
      "['W', 'EY1'] weigh\n",
      "['w', 'ay']\n",
      "['W', 'EY1', 'D'] weighed\n",
      "['w', 'ay', 'd']\n",
      "['W', 'EY1', 'Z'] weighs\n",
      "['w', 'ay', 'z']\n",
      "['W', 'EY1', 'T'] weight\n",
      "['w', 'ay', 't']\n",
      "['W', 'EY1', 'T', 'IH0', 'NG'] weighting\n",
      "['w', 'ay', 't', 'ih', 'ng']\n",
      "['W', 'EY1', 'T', 'S'] weights\n",
      "['w', 'ay', 't', 's']\n",
      "['W', 'AE1', 'K', 'S'] whacks\n",
      "['w', 'ae', ['ks', ['k', 's']]]\n",
      "['W', 'AY1', 'N'] whine\n",
      "['w', 'ai', 'n']\n",
      "['W', 'IH1', 'T'] whit\n",
      "['w', 'ih', 't']\n",
      "['HH', 'OW1', 'L'] whole\n",
      "['h', 'o', 'l']\n",
      "['W', 'AY1', 'N'] wine\n",
      "['w', 'ai', 'n']\n",
      "['W', 'IH1', 'T'] wit\n",
      "['w', 'ih', 't']\n",
      "['W', 'AO1', 'R'] wore\n",
      "['w', 'aw', 'r']\n",
      "['W', 'AO1', 'R', 'N'] worn\n",
      "['w', 'aw', 'r', 'n']\n",
      "['R', 'AE1', 'K'] wrack\n",
      "['r', 'ae']\n",
      "['R', 'AE1', 'P'] wrap\n",
      "['r', 'ae', 'p']\n",
      "['R', 'IY1', 'K', 'S'] wreaks\n",
      "['r', 'ee', ['ks', ['k', 's']]]\n",
      "['R', 'IH1', 'NG'] wring\n",
      "['r', 'ih', 'ng']\n",
      "['R', 'IH1', 'NG', 'IH0', 'NG'] wringing\n",
      "['r', 'ih', 'ng', 'ih', 'ng']\n",
      "['R', 'AY1', 'T'] write\n",
      "['r', 'ai', 't']\n",
      "['R', 'AY1', 'T', 'S'] writes\n",
      "['r', 'ai', 't', 's']\n",
      "['R', 'OW1', 'T'] wrote\n",
      "['r', 'o', 't']\n"
     ]
    }
   ],
   "source": [
    "test_words = []\n",
    "for i,word in enumerate(hom_phon_words):\n",
    "    print(word,unique_homophones[i])\n",
    "    print(get_keyboard_phonetic_symbols(word, berndt_arpabbet_dict))\n",
    "    test_words.append((unique_homophones[i],get_keyboard_phonetic_symbols(word, berndt_arpabbet_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ad', ['ae', 'd']),\n",
       " ('add', ['ae', 'd']),\n",
       " ('adds', ['ae', 'd', 'z']),\n",
       " ('ads', ['ae', 'd', 'z']),\n",
       " ('aid', ['ay', 'd']),\n",
       " ('aide', ['ay', 'd']),\n",
       " ('aides', ['ay', 'd', 'z']),\n",
       " ('aids', ['ay', 'd', 'z']),\n",
       " ('airs', ['eh', 'r', 'z']),\n",
       " ('allowed', [['ul', ['uh-', 'l']], 'au', 'd'])]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad ['ae', 'd']\n",
      "add ['ae', 'd']\n",
      "adds ['ae', 'd', 'z']\n",
      "ads ['ae', 'd', 'z']\n",
      "aid ['ay', 'd']\n",
      "aide ['ay', 'd']\n",
      "aides ['ay', 'd', 'z']\n",
      "aids ['ay', 'd', 'z']\n",
      "airs ['eh', 'r', 'z']\n",
      "allowed [['ul', ['uh-', 'l']], 'au', 'd']\n",
      "aloud [['ul', ['uh-', 'l']], 'au', 'd']\n",
      "bail ['b', 'ay', 'l']\n",
      "baits ['b', 'ay', 't', 's']\n",
      "bald ['b', 'aw', 'l', 'd']\n",
      "bale ['b', 'ay', 'l']\n",
      "band ['b', 'ae', 'n', 'd']\n",
      "banned ['b', 'ae', 'n', 'd']\n",
      "bare ['b', 'eh', 'r']\n",
      "bates ['b', 'ay', 't', 's']\n",
      "bawled ['b', 'aw', 'l', 'd']\n",
      "bear ['b', 'eh', 'r']\n",
      "beats ['b', 'ee', 't', 's']\n",
      "beets ['b', 'ee', 't', 's']\n",
      "bell ['b', 'eh', 'l']\n",
      "belle ['b', 'eh', 'l']\n",
      "berry ['b', 'eh', 'r', 'ee']\n",
      "billed ['b', 'ih', 'l', 'd']\n",
      "blew ['b', 'l', 'oo']\n",
      "blue ['b', 'l', 'oo']\n",
      "boar ['b', 'aw', 'r']\n",
      "board ['b', 'aw', 'r', 'd']\n",
      "bold ['b', 'o', 'l', 'd']\n",
      "bore ['b', 'aw', 'r']\n",
      "bored ['b', 'aw', 'r', 'd']\n",
      "bowled ['b', 'o', 'l', 'd']\n",
      "brakes ['b', 'r', 'ay', ['ks', ['k', 's']]]\n",
      "bread ['b', 'r', 'eh', 'd']\n",
      "breaks ['b', 'r', 'ay', ['ks', ['k', 's']]]\n",
      "bred ['b', 'r', 'eh', 'd']\n",
      "build ['b', 'ih', 'l', 'd']\n",
      "bury ['b', 'eh', 'r', 'ee']\n",
      "callous ['k', 'ae', 'l', 'uh-', 's']\n",
      "callus ['k', 'ae', 'l', 'uh-', 's']\n",
      "capital ['k', 'ae', 'p', 'uh-', 't', ['ul', ['uh-', 'l']]]\n",
      "capitol ['k', 'ae', 'p', 'ih', 't', ['ul', ['uh-', 'l']]]\n",
      "ceiling ['s', 'ee', 'l', 'ih', 'ng']\n",
      "cell ['s', 'eh', 'l']\n",
      "cellar ['s', 'eh', 'l', 'er']\n",
      "cellars ['s', 'eh', 'l', 'er', 'z']\n",
      "cells ['s', 'eh', 'l', 'z']\n",
      "cent ['s', 'eh', 'n', 't']\n",
      "cents ['s', 'eh', 'n', 't', 's']\n",
      "cereal ['s', 'ih', 'r', 'ee', ['ul', ['uh-', 'l']]]\n",
      "chews ['tch', 'oo', 'z']\n",
      "chile ['tch', 'ih', 'l', 'ee']\n",
      "chilly ['tch', 'ih', 'l', 'ee']\n",
      "choose ['tch', 'oo', 'z']\n",
      "chord ['k', 'aw', 'r', 'd']\n",
      "chords ['k', 'aw', 'r', 'd', 'z']\n",
      "chute ['sh', 'oo', 't']\n",
      "chutes ['sh', 'oo', 't', 's']\n",
      "coarse ['k', 'aw', 'r', 's']\n",
      "coco ['k', 'o', 'k', 'o']\n",
      "cocoa ['k', 'o', 'k', 'o']\n",
      "cord ['k', 'aw', 'r', 'd']\n",
      "cords ['k', 'aw', 'r', 'd', 'z']\n",
      "core ['k', 'aw', 'r']\n",
      "corps ['k', 'aw', 'r']\n",
      "council ['k', 'au', 'n', 's', ['ul', ['uh-', 'l']]]\n",
      "counsel ['k', 'au', 'n', 's', ['ul', ['uh-', 'l']]]\n",
      "course ['k', 'aw', 'r', 's']\n",
      "crews ['k', 'r', 'oo', 'z']\n",
      "cruise ['k', 'r', 'oo', 'z']\n",
      "dear ['d', 'ih', 'r']\n",
      "deer ['d', 'ih', 'r']\n",
      "dew ['d', 'oo']\n",
      "die ['d', 'ai']\n",
      "died ['d', 'ai', 'd']\n",
      "dies ['d', 'ai', 'z']\n",
      "doc ['d', 'ah']\n",
      "dock ['d', 'ah']\n",
      "doe ['d', 'o']\n",
      "dough ['d', 'o']\n",
      "drier ['d', 'r', 'ai', 'er']\n",
      "dryer ['d', 'r', 'ai', 'er']\n",
      "due ['d', 'oo']\n",
      "dye ['d', 'ai']\n",
      "dyed ['d', 'ai', 'd']\n",
      "dyes ['d', 'ai', 'z']\n",
      "elicit ['ih', 'l', 'ih', 's', 'ih', 't']\n",
      "ensure ['eh', 'n', 'sh', 'u', 'r']\n",
      "fair ['f', 'eh', 'r']\n",
      "fare ['f', 'eh', 'r']\n",
      "feat ['f', 'ee', 't']\n",
      "feet ['f', 'ee', 't']\n",
      "fiance ['f', 'ee', 'ah', 'n', 's', 'ay']\n",
      "fiancee ['f', 'ee', 'ae', 'n', 's', 'ee']\n",
      "fill ['f', 'ih', 'l']\n",
      "find ['f', 'ai', 'n', 'd']\n",
      "fined ['f', 'ai', 'n', 'd']\n",
      "flair ['f', 'l', 'eh', 'r']\n",
      "flare ['f', 'l', 'eh', 'r']\n",
      "flea ['f', 'l', 'ee']\n",
      "flee ['f', 'l', 'ee']\n",
      "flew ['f', 'l', 'oo']\n",
      "flour ['f', 'l', 'au', 'er']\n",
      "flower ['f', 'l', 'au', 'er']\n",
      "flowers ['f', 'l', 'au', 'er', 'z']\n",
      "flu ['f', 'l', 'oo']\n",
      "franc ['f', 'r', 'ae', 'ng']\n",
      "frank ['f', 'r', 'ae', 'ng']\n",
      "grate ['g', 'r', 'ay', 't']\n",
      "great ['g', 'r', 'ay', 't']\n",
      "grisly ['g', 'r', 'ih', 'z', 'l', 'ee']\n",
      "grizzly ['g', 'r', 'ih', 'z', 'l', 'ee']\n",
      "guessed ['g', 'eh', 's', 't']\n",
      "guest ['g', 'eh', 's', 't']\n",
      "guise ['g', 'ai', 'z']\n",
      "guys ['g', 'ai', 'z']\n",
      "gym ['dj', 'ih', 'm']\n",
      "hall ['h', 'aw', 'l']\n",
      "halls ['h', 'aw', 'l', 'z']\n",
      "hart ['h', 'ah', 'r', 't']\n",
      "haul ['h', 'aw', 'l']\n",
      "hauls ['h', 'aw', 'l', 'z']\n",
      "heal ['h', 'ee', 'l']\n",
      "heals ['h', 'ee', 'l', 'z']\n",
      "hear ['h', 'ee', 'r']\n",
      "heard ['h', 'er', 'd']\n",
      "heart ['h', 'ah', 'r', 't']\n",
      "heel ['h', 'ee', 'l']\n",
      "heels ['h', 'ee', 'l', 'z']\n",
      "heirs ['eh', 'r', 'z']\n",
      "herd ['h', 'er', 'd']\n",
      "here ['h', 'ee', 'r']\n",
      "hertz ['h', 'eh', 'r', 't', 's']\n",
      "higher ['h', 'ai', 'er']\n",
      "hire ['h', 'ai', 'er']\n",
      "hoarse ['h', 'aw', 'r', 's']\n",
      "hold ['h', 'o', 'l', 'd']\n",
      "hole ['h', 'o', 'l']\n",
      "holed ['h', 'o', 'l', 'd']\n",
      "holes ['h', 'o', 'l', 'z']\n",
      "horse ['h', 'aw', 'r', 's']\n",
      "hurts ['h', 'er', 't', 's']\n",
      "illicit ['ih', 'l', 'ih', 's', 'uh-', 't']\n",
      "insure ['ih', 'n', 'sh', 'u', 'r']\n",
      "jim ['dj', 'ih', 'm']\n",
      "kneading ['n', 'ee', 'd', 'ih', 'ng']\n",
      "knew ['n', 'oo']\n",
      "knight ['n', 'ai', 't']\n",
      "knights ['n', 'ai', 't', 's']\n",
      "knit ['n', 'ih', 't']\n",
      "knows ['n', 'o', 'z']\n",
      "lacks ['l', 'ae', ['ks', ['k', 's']]]\n",
      "lax ['l', 'ae', ['ks', ['k', 's']]]\n",
      "lea ['l', 'ee']\n",
      "leased ['l', 'ee', 's', 't']\n",
      "least ['l', 'ee', 's', 't']\n",
      "lee ['l', 'ee']\n",
      "lessen ['l', 'eh', 's', ['un', ['uh-', 'n']]]\n",
      "lesson ['l', 'eh', 's', ['un', ['uh-', 'n']]]\n",
      "levee ['l', 'eh', 'v', 'ee']\n",
      "levy ['l', 'eh', 'v', 'ee']\n",
      "loan ['l', 'o', 'n']\n",
      "lone ['l', 'o', 'n']\n",
      "lumbar ['l', 'uh+', 'm', 'b', 'ah', 'r']\n",
      "lumber ['l', 'uh+', 'm', 'b', 'er']\n",
      "mac ['m', 'ae']\n",
      "mach ['m', 'ah']\n",
      "made ['m', 'ay', 'd']\n",
      "maid ['m', 'ay', 'd']\n",
      "mail ['m', 'ay', 'l']\n",
      "mails ['m', 'ay', 'l', 'z']\n",
      "male ['m', 'ay', 'l']\n",
      "males ['m', 'ay', 'l', 'z']\n",
      "mall ['m', 'aw', 'l']\n",
      "manner ['m', 'ae', 'n', 'er']\n",
      "manor ['m', 'ae', 'n', 'er']\n",
      "marks ['m', 'ah', 'r', ['ks', ['k', 's']]]\n",
      "marx ['m', 'ah', 'r', ['ks', ['k', 's']]]\n",
      "maul ['m', 'aw', 'l']\n",
      "meat ['m', 'ee', 't']\n",
      "meats ['m', 'ee', 't', 's']\n",
      "meet ['m', 'ee', 't']\n",
      "meets ['m', 'ee', 't', 's']\n",
      "missed ['m', 'ih', 's', 't']\n",
      "mist ['m', 'ih', 's', 't']\n",
      "mode ['m', 'o', 'd']\n",
      "moose ['m', 'oo', 's']\n",
      "morning ['m', 'aw', 'r', 'n', 'ih', 'ng']\n",
      "mourning ['m', 'aw', 'r', 'n', 'ih', 'ng']\n",
      "mowed ['m', 'o', 'd']\n",
      "naval ['n', 'ay', 'v', ['ul', ['uh-', 'l']]]\n",
      "needing ['n', 'ee', 'd', 'ih', 'ng']\n",
      "new ['n', 'oo']\n",
      "night ['n', 'ai', 't']\n",
      "nights ['n', 'ai', 't', 's']\n",
      "nit ['n', 'ih', 't']\n",
      "nose ['n', 'o', 'z']\n",
      "paced ['p', 'ay', 's', 't']\n",
      "packed ['p', 'ae', 'k', 't']\n",
      "pact ['p', 'ae', 'k', 't']\n",
      "pain ['p', 'ay', 'n']\n",
      "pains ['p', 'ay', 'n', 'z']\n",
      "pair ['p', 'eh', 'r']\n",
      "pairs ['p', 'eh', 'r', 'z']\n",
      "pane ['p', 'ay', 'n']\n",
      "panes ['p', 'ay', 'n', 'z']\n",
      "passed ['p', 'ae', 's', 't']\n",
      "past ['p', 'ae', 's', 't']\n",
      "paste ['p', 'ay', 's', 't']\n",
      "pause ['p', 'aw', 'z']\n",
      "paws ['p', 'aw', 'z']\n",
      "pea ['p', 'ee']\n",
      "peace ['p', 'ee', 's']\n",
      "peak ['p', 'ee']\n",
      "peaked ['p', 'ee', 'k', 't']\n",
      "pear ['p', 'eh', 'r']\n",
      "pee ['p', 'ee']\n",
      "peek ['p', 'ee']\n",
      "peer ['p', 'ih', 'r']\n",
      "peers ['p', 'ih', 'r', 'z']\n",
      "phil ['f', 'ih', 'l']\n",
      "pi ['p', 'ai']\n",
      "pie ['p', 'ai']\n",
      "piece ['p', 'ee', 's']\n",
      "pier ['p', 'ih', 'r']\n",
      "piers ['p', 'ih', 'r', 'z']\n",
      "piqued ['p', 'ee', 'k', 't']\n",
      "plain ['p', 'l', 'ay', 'n']\n",
      "plains ['p', 'l', 'ay', 'n', 'z']\n",
      "plane ['p', 'l', 'ay', 'n']\n",
      "planes ['p', 'l', 'ay', 'n', 'z']\n",
      "plum ['p', 'l', 'uh+', 'm']\n",
      "plumb ['p', 'l', 'uh+', 'm']\n",
      "pole ['p', 'o', 'l']\n",
      "poles ['p', 'o', 'l', 'z']\n",
      "poll ['p', 'o', 'l']\n",
      "polls ['p', 'o', 'l', 'z']\n",
      "populace ['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "populous ['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "praise ['p', 'r', 'ay', 'z']\n",
      "pray ['p', 'r', 'ay']\n",
      "praying ['p', 'r', 'ay', 'ih', 'ng']\n",
      "prey ['p', 'r', 'ay']\n",
      "preying ['p', 'r', 'ay', 'ih', 'ng']\n",
      "preys ['p', 'r', 'ay', 'z']\n",
      "principal ['p', 'r', 'ih', 'n', 's', 'uh-', 'p', ['ul', ['uh-', 'l']]]\n",
      "principle ['p', 'r', 'ih', 'n', 's', 'uh-', 'p', ['ul', ['uh-', 'l']]]\n",
      "puts ['p', 'u', 't', 's']\n",
      "putts ['p', 'uh+', 't', 's']\n",
      "rack ['r', 'ae']\n",
      "rain ['r', 'ay', 'n']\n",
      "rained ['r', 'ay', 'n', 'd']\n",
      "rains ['r', 'ay', 'n', 'z']\n",
      "raise ['r', 'ay', 'z']\n",
      "rap ['r', 'ae', 'p']\n",
      "rays ['r', 'ay', 'z']\n",
      "reeks ['r', 'ee', ['ks', ['k', 's']]]\n",
      "reigned ['r', 'ay', 'n', 'd']\n",
      "rein ['r', 'ay', 'n']\n",
      "reins ['r', 'ay', 'n', 'z']\n",
      "right ['r', 'ai', 't']\n",
      "rights ['r', 'ai', 't', 's']\n",
      "ring ['r', 'ih', 'ng']\n",
      "ringing ['r', 'ih', 'ng', 'ih', 'ng']\n",
      "road ['r', 'o', 'd']\n",
      "roam ['r', 'o', 'm']\n",
      "rode ['r', 'o', 'd']\n",
      "roles ['r', 'o', 'l', 'z']\n",
      "rolls ['r', 'o', 'l', 'z']\n",
      "rome ['r', 'o', 'm']\n",
      "rose ['r', 'o', 'z']\n",
      "rote ['r', 'o', 't']\n",
      "rough ['r', 'uh+', 'f']\n",
      "rows ['r', 'o', 'z']\n",
      "ruff ['r', 'uh+', 'f']\n",
      "sac ['s', 'ae']\n",
      "sack ['s', 'ae']\n",
      "sacks ['s', 'ae', ['ks', ['k', 's']]]\n",
      "sail ['s', 'ay', 'l']\n",
      "sails ['s', 'ay', 'l', 'z']\n",
      "sale ['s', 'ay', 'l']\n",
      "sales ['s', 'ay', 'l', 'z']\n",
      "sax ['s', 'ae', ['ks', ['k', 's']]]\n",
      "scene ['s', 'ee', 'n']\n",
      "scents ['s', 'eh', 'n', 't', 's']\n",
      "sea ['s', 'ee']\n",
      "sealing ['s', 'ee', 'l', 'ih', 'ng']\n",
      "seam ['s', 'ee', 'm']\n",
      "seams ['s', 'ee', 'm', 'z']\n",
      "seas ['s', 'ee', 'z']\n",
      "see ['s', 'ee']\n",
      "seem ['s', 'ee', 'm']\n",
      "seems ['s', 'ee', 'm', 'z']\n",
      "seen ['s', 'ee', 'n']\n",
      "sees ['s', 'ee', 'z']\n",
      "sell ['s', 'eh', 'l']\n",
      "seller ['s', 'eh', 'l', 'er']\n",
      "sellers ['s', 'eh', 'l', 'er', 'z']\n",
      "sells ['s', 'eh', 'l', 'z']\n",
      "sent ['s', 'eh', 'n', 't']\n",
      "serial ['s', 'ih', 'r', 'ee', ['ul', ['uh-', 'l']]]\n",
      "shear ['sh', 'ih', 'r']\n",
      "sheer ['sh', 'ih', 'r']\n",
      "shoot ['sh', 'oo', 't']\n",
      "shoots ['sh', 'oo', 't', 's']\n",
      "sight ['s', 'ai', 't']\n",
      "sighted ['s', 'ai', 't', 'uh-', 'd']\n",
      "sights ['s', 'ai', 't', 's']\n",
      "sink ['s', 'ih', 'ng']\n",
      "site ['s', 'ai', 't']\n",
      "sited ['s', 'ai', 't', 'ih', 'd']\n",
      "sites ['s', 'ai', 't', 's']\n",
      "slay ['s', 'l', 'ay']\n",
      "sleigh ['s', 'l', 'ay']\n",
      "sole ['s', 'o', 'l']\n",
      "soles ['s', 'o', 'l', 'z']\n",
      "son ['s', 'uh+', 'n']\n",
      "sons ['s', 'uh+', 'n', 'z']\n",
      "soul ['s', 'o', 'l']\n",
      "souls ['s', 'o', 'l', 'z']\n",
      "spade ['s', 'p', 'ay', 'd']\n",
      "spayed ['s', 'p', 'ay', 'd']\n",
      "stake ['s', 't', 'ay']\n",
      "stakes ['s', 't', 'ay', ['ks', ['k', 's']]]\n",
      "steak ['s', 't', 'ay']\n",
      "steaks ['s', 't', 'ay', ['ks', ['k', 's']]]\n",
      "steal ['s', 't', 'ee', 'l']\n",
      "steel ['s', 't', 'ee', 'l']\n",
      "straight ['s', 't', 'r', 'ay', 't']\n",
      "strait ['s', 't', 'r', 'ay', 't']\n",
      "suede ['s', 'w', 'ay', 'd']\n",
      "suites ['s', 'w', 'ee', 't', 's']\n",
      "sun ['s', 'uh+', 'n']\n",
      "suns ['s', 'uh+', 'n', 'z']\n",
      "swayed ['s', 'w', 'ay', 'd']\n",
      "sweets ['s', 'w', 'ee', 't', 's']\n",
      "sync ['s', 'ih', 'ng']\n",
      "tacks ['t', 'ae', ['ks', ['k', 's']]]\n",
      "tail ['t', 'ay', 'l']\n",
      "tails ['t', 'ay', 'l', 'z']\n",
      "tale ['t', 'ay', 'l']\n",
      "tales ['t', 'ay', 'l', 'z']\n",
      "taught ['t', 'aw', 't']\n",
      "tax ['t', 'ae', ['ks', ['k', 's']]]\n",
      "tea ['t', 'ee']\n",
      "teas ['t', 'ee', 'z']\n",
      "tease ['t', 'ee', 'z']\n",
      "tec ['t', 'eh']\n",
      "tech ['t', 'eh']\n",
      "tee ['t', 'ee']\n",
      "thai ['t', 'ai']\n",
      "thais ['t', 'ai', 'z']\n",
      "throes ['th-', 'r', 'o', 'z']\n",
      "throws ['th-', 'r', 'o', 'z']\n",
      "thyme ['th-', 'ai', 'm']\n",
      "tic ['t', 'ih']\n",
      "tick ['t', 'ih']\n",
      "tide ['t', 'ai', 'd']\n",
      "tie ['t', 'ai']\n",
      "tied ['t', 'ai', 'd']\n",
      "ties ['t', 'ai', 'z']\n",
      "time ['t', 'ai', 'm']\n",
      "toe ['t', 'o']\n",
      "tow ['t', 'o']\n",
      "tracked ['t', 'r', 'ae', 'k', 't']\n",
      "tract ['t', 'r', 'ae', 'k', 't']\n",
      "wade ['w', 'ay', 'd']\n",
      "waist ['w', 'ay', 's', 't']\n",
      "wait ['w', 'ay', 't']\n",
      "waiting ['w', 'ay', 't', 'ih', 'ng']\n",
      "waits ['w', 'ay', 't', 's']\n",
      "waive ['w', 'ay', 'v']\n",
      "war ['w', 'aw', 'r']\n",
      "warn ['w', 'aw', 'r', 'n']\n",
      "waste ['w', 'ay', 's', 't']\n",
      "wave ['w', 'ay', 'v']\n",
      "wax ['w', 'ae', ['ks', ['k', 's']]]\n",
      "way ['w', 'ay']\n",
      "ways ['w', 'ay', 'z']\n",
      "weak ['w', 'ee']\n",
      "week ['w', 'ee']\n",
      "weigh ['w', 'ay']\n",
      "weighed ['w', 'ay', 'd']\n",
      "weighs ['w', 'ay', 'z']\n",
      "weight ['w', 'ay', 't']\n",
      "weighting ['w', 'ay', 't', 'ih', 'ng']\n",
      "weights ['w', 'ay', 't', 's']\n",
      "whacks ['w', 'ae', ['ks', ['k', 's']]]\n",
      "whine ['w', 'ai', 'n']\n",
      "whit ['w', 'ih', 't']\n",
      "whole ['h', 'o', 'l']\n",
      "wine ['w', 'ai', 'n']\n",
      "wit ['w', 'ih', 't']\n",
      "wore ['w', 'aw', 'r']\n",
      "worn ['w', 'aw', 'r', 'n']\n",
      "wrack ['r', 'ae']\n",
      "wrap ['r', 'ae', 'p']\n",
      "wreaks ['r', 'ee', ['ks', ['k', 's']]]\n",
      "wring ['r', 'ih', 'ng']\n",
      "wringing ['r', 'ih', 'ng', 'ih', 'ng']\n",
      "write ['r', 'ai', 't']\n",
      "writes ['r', 'ai', 't', 's']\n",
      "wrote ['r', 'o', 't']\n"
     ]
    }
   ],
   "source": [
    "#test_words = [(\"soft\", get_keyboard_phonetic_symbols(get_ARPAbet_phonetic_transcription([\"soft\"])[0], berndt_arpabbet_dict))]\n",
    "#test_words = [(\"wreaks\", get_keyboard_phonetic_symbols(get_ARPAbet_phonetic_transcription([\"wreaks\"])[0], berndt_arpabbet_dict))]\n",
    "\n",
    "\n",
    "possible_grapheme_strings = [] # list for each word\n",
    "possible_prior_probs = [] # list for each word\n",
    "possible_cond_probs = [] # list for each word\n",
    "word_rests = [] # list for each word\n",
    "\n",
    "for i,word_pron in enumerate(test_words):\n",
    "    word = word_pron[0] # word string\n",
    "    pron = word_pron[1] # list of keyboard compatible phon characters\n",
    "    print(word,pron)\n",
    "    possible_grapheme_strings_i = [[]] # for each word a list of possible lists with grapheme given pronunciation strings \n",
    "    possible_prior_probs_i = [[]] # for each word a list of possible lists with corresponding prio probabilites \n",
    "    possible_cond_probs_i = [[]] # for each word a list of possible lists possible corresponding conditional probabilities\n",
    "    word_rests_i = [word.upper()] # for each word a list of remaining word characters after having splitted it into a list of possible graphemes  \n",
    "    \n",
    "    for j,p in enumerate(pron):  \n",
    "        new_word_rests_i = [] # new rest of the word after looking at the current encoded syllable pronunciation\n",
    "        new_possible_grapheme_strings_i = [] # new possible grapheme strings given the current syllable pronunciation\n",
    "        new_possible_prior_probs_i = []\n",
    "        new_possible_cond_probs_i = []\n",
    "        if isinstance(p,list):\n",
    "            for p_i in p:   \n",
    "                if isinstance(p_i,list):\n",
    "                    for p_ij in p_i:\n",
    "                        for possible_grapheme in berndt_computer_phonem_graph_prob_dict[p_ij]: # all possible corresponding graphemes\n",
    "                            grapheme = possible_grapheme[0].split(\"-\") # account for silent e encoded by e.g. A-E\n",
    "                            prior = possible_grapheme[1] # prior prob\n",
    "                            cond = possible_grapheme[2] # cond prop\n",
    "                            for k,word_rest in enumerate(word_rests_i): # for each possible combination we get a different word rest e.g. APPLE can have [A,P], [A,PP], [A-E,P], [A-E,PP] --> [\"PLE\", LE, PL, L]\n",
    "                                if len(grapheme)>1: #silent E \n",
    "                                    if word_rest.startswith(grapheme[0]) and word_rest.endswith(grapheme[1]): # check whether the grapheme fits to the rest of the word\n",
    "                                        new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]]) # add the grapheme to the grapheme list which corresponds to the word ret we are currently looking at\n",
    "                                        new_possible_prior_probs_i.append(possible_prior_probs_i[k] + [prior])\n",
    "                                        new_possible_cond_probs_i.append(possible_cond_probs_i[k] + [cond])\n",
    "                                        new_word_rests_i.append(word_rest[len(grapheme[0]):-1]) # new word_rests \n",
    "\n",
    "                                else:\n",
    "                                    if word_rest.startswith(grapheme[0]): #no silent E\n",
    "                                        new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]])\n",
    "                                        new_possible_prior_probs_i.append(possible_prior_probs_i[k] + [prior])\n",
    "                                        new_possible_cond_probs_i.append(possible_cond_probs_i[k] + [cond])\n",
    "                                        new_word_rests_i.append(word_rest[len(grapheme[0]):])\n",
    "                            \n",
    "                        word_rests_i = new_word_rests_i #update word rests \n",
    "                        possible_grapheme_strings_i = new_possible_grapheme_strings_i #update possible grapheme strings \n",
    "                        possible_prior_probs_i = new_possible_prior_probs_i\n",
    "                        possible_cond_probs_i = new_possible_cond_probs_i\n",
    "\n",
    "                    \n",
    "                else: # proceed like normal but without updating the words_rests\n",
    "                    for possible_grapheme in berndt_computer_phonem_graph_prob_dict[p_i]: # all possible corresponding graphemes\n",
    "                        grapheme = possible_grapheme[0].split(\"-\") # account for silent e encoded by e.g. A-E\n",
    "                        prior = possible_grapheme[1] # prior prob\n",
    "                        cond = possible_grapheme[2] # cond prop\n",
    "\n",
    "                        for k,word_rest in enumerate(word_rests_i): # for each possible combination we get a different word rest e.g. APPLE can have [A,P], [A,PP], [A-E,P], [A-E,PP] --> [\"PLE\", LE, PL, L]\n",
    "                            if len(grapheme)>1: #silent E \n",
    "                                if word_rest.startswith(grapheme[0]) and word_rest.endswith(grapheme[1]): # check whether the grapheme fits to the rest of the word\n",
    "                                    new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]]) # add the grapheme to the grapheme list which corresponds to the word ret we are currently looking at\n",
    "                                    new_possible_prior_probs_i.append(possible_prior_probs_i[k] + [prior])\n",
    "                                    new_possible_cond_probs_i.append(possible_cond_probs_i[k] + [cond])\n",
    "                                    new_word_rests_i.append(word_rest[len(grapheme[0]):-1]) # new word_rests \n",
    "\n",
    "                            else:\n",
    "                                if word_rest.startswith(grapheme[0]): #no silent E\n",
    "                                    new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]])\n",
    "                                    new_possible_prior_probs_i.append(possible_prior_probs_i[k] + [prior])\n",
    "                                    new_possible_cond_probs_i.append(possible_cond_probs_i[k] + [cond])\n",
    "                                    new_word_rests_i.append(word_rest[len(grapheme[0]):])\n",
    "\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            for possible_grapheme in berndt_computer_phonem_graph_prob_dict[p]: # all possible corresponding graphemes\n",
    "                grapheme = possible_grapheme[0].split(\"-\") # account for silent e encoded by e.g. A-E\n",
    "                prior = possible_grapheme[1] # prior prob\n",
    "                cond = possible_grapheme[2] # cond prop\n",
    "                for k,word_rest in enumerate(word_rests_i): # for each possible combination we get a different word rest e.g. APPLE can have [A,P], [A,PP], [A-E,P], [A-E,PP] --> [\"PLE\", LE, PL, L]\n",
    "                    if len(grapheme)>1: #silent E \n",
    "                        if word_rest.startswith(grapheme[0]) and word_rest.endswith(grapheme[1]): # check whether the grapheme fits to the rest of the word\n",
    "                            new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]]) # add the grapheme to the grapheme list which corresponds to the word ret we are currently looking at\n",
    "                            new_possible_prior_probs_i.append(possible_prior_probs_i[k] + [prior])\n",
    "                            new_possible_cond_probs_i.append(possible_cond_probs_i[k] + [cond])\n",
    "                            new_word_rests_i.append(word_rest[len(grapheme[0]):-1]) # new word_rests \n",
    "\n",
    "                    else:\n",
    "                        if word_rest.startswith(grapheme[0]): #no silent E\n",
    "                            new_possible_grapheme_strings_i.append(possible_grapheme_strings_i[k] + [possible_grapheme[0]])\n",
    "                            new_possible_prior_probs_i.append(possible_prior_probs_i[k] + [prior])\n",
    "                            new_possible_cond_probs_i.append(possible_cond_probs_i[k] + [cond])\n",
    "                            new_word_rests_i.append(word_rest[len(grapheme[0]):])\n",
    "\n",
    "\n",
    "            word_rests_i = new_word_rests_i #update word rests \n",
    "            possible_grapheme_strings_i = new_possible_grapheme_strings_i #update possible grapheme strings \n",
    "            possible_prior_probs_i = new_possible_prior_probs_i\n",
    "            possible_cond_probs_i = new_possible_cond_probs_i\n",
    "    \n",
    "        #print(possible_grapheme_strings_i,word_rests_i)\n",
    "    possible_grapheme_strings.append(possible_grapheme_strings_i)\n",
    "    possible_prior_probs.append(possible_prior_probs_i)\n",
    "    possible_cond_probs.append(possible_cond_probs_i)\n",
    "    word_rests.append(word_rests_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['WR', 'EA', 'K'], ['WR', 'EA', 'K', 'S']]]\n",
      "[['S', '']]\n"
     ]
    }
   ],
   "source": [
    "print(possible_grapheme_strings)\n",
    "print(word_rests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CS', 0.0002, 1.0), ('X', 0.0033, 0.885)]\n"
     ]
    }
   ],
   "source": [
    "#print(get_ARPAbet_phonetic_transcription([\"aid\"]))\n",
    "#print(berndt_arpabbet_dict)\n",
    "print(berndt_computer_phonem_graph_prob_dict[\"ks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allowed [['ul', ['uh-', 'l']], 'au', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "banned ['b', 'ae', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bates ['b', 'ay', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bawled ['b', 'aw', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "billed ['b', 'ih', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bored ['b', 'aw', 'r', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bowled ['b', 'o', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "cellars ['s', 'eh', 'l', 'er', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "chutes ['sh', 'oo', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "course ['k', 'aw', 'r', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "dear ['d', 'ih', 'r']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "dyed ['d', 'ai', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "fined ['f', 'ai', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "flour ['f', 'l', 'au', 'er']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "flower ['f', 'l', 'au', 'er']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "flowers ['f', 'l', 'au', 'er', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "guessed ['g', 'eh', 's', 't']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "guest ['g', 'eh', 's', 't']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "guise ['g', 'ai', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "heard ['h', 'er', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "heirs ['eh', 'r', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "herd ['h', 'er', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "hire ['h', 'ai', 'er']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "holed ['h', 'o', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "hurts ['h', 'er', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "mourning ['m', 'aw', 'r', 'n', 'ih', 'ng']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "mowed ['m', 'o', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "populace ['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "populous ['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "rained ['r', 'ay', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "reigned ['r', 'ay', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "sellers ['s', 'eh', 'l', 'er', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "shear ['sh', 'ih', 'r']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "sites ['s', 'ai', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "spayed ['s', 'p', 'ay', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "suites ['s', 'w', 'ee', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "swayed ['s', 'w', 'ay', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "thai ['t', 'ai']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "thais ['t', 'ai', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "weighed ['w', 'ay', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "writes ['r', 'ai', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "counter = 0 \n",
    "for i,word_pron in enumerate(test_words):\n",
    "    word = word_pron[0] # word string\n",
    "    pron = word_pron[1] # list of keyboard compatible phon characters\n",
    "    if len(possible_grapheme_strings[i]) == 0:\n",
    "        counter+=1\n",
    "        print(word,pron)\n",
    "        print(possible_grapheme_strings[i])\n",
    "        print(possible_prior_probs[i])\n",
    "        print(possible_cond_probs[i])\n",
    "        print(word_rests[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allowed [['ul', ['uh-', 'l']], 'au', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "banned ['b', 'ae', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bates ['b', 'ay', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bawled ['b', 'aw', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "billed ['b', 'ih', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bored ['b', 'aw', 'r', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "bowled ['b', 'o', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "brakes ['b', 'r', 'ay', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "cellars ['s', 'eh', 'l', 'er', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "chutes ['sh', 'oo', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "course ['k', 'aw', 'r', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "dear ['d', 'ih', 'r']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "dyed ['d', 'ai', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "fined ['f', 'ai', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "flour ['f', 'l', 'au', 'er']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "flower ['f', 'l', 'au', 'er']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "flowers ['f', 'l', 'au', 'er', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "guessed ['g', 'eh', 's', 't']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "guest ['g', 'eh', 's', 't']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "guise ['g', 'ai', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "heard ['h', 'er', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "heirs ['eh', 'r', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "herd ['h', 'er', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "hire ['h', 'ai', 'er']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "holed ['h', 'o', 'l', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "hurts ['h', 'er', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "lax ['l', 'ae', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "marx ['m', 'ah', 'r', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "mourning ['m', 'aw', 'r', 'n', 'ih', 'ng']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "mowed ['m', 'o', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "populace ['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "populous ['p', 'ah', 'p', 'y', ['ul', ['uh-', 'l']], 'uh-', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "rained ['r', 'ay', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "reigned ['r', 'ay', 'n', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "sax ['s', 'ae', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "sellers ['s', 'eh', 'l', 'er', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "shear ['sh', 'ih', 'r']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "sites ['s', 'ai', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "spayed ['s', 'p', 'ay', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "stakes ['s', 't', 'ay', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "suites ['s', 'w', 'ee', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "swayed ['s', 'w', 'ay', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "tax ['t', 'ae', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "thai ['t', 'ai']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "thais ['t', 'ai', 'z']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "wax ['w', 'ae', 'k', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "weighed ['w', 'ay', 'd']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "writes ['r', 'ai', 't', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "counter = 0 \n",
    "for i,word_pron in enumerate(test_words):\n",
    "    word = word_pron[0] # word string\n",
    "    pron = word_pron[1] # list of keyboard compatible phon characters\n",
    "    if len(possible_grapheme_strings[i]) == 0:\n",
    "        counter+=1\n",
    "        print(word,pron)\n",
    "        print(possible_grapheme_strings[i])\n",
    "        print(possible_prior_probs[i])\n",
    "        print(possible_cond_probs[i])\n",
    "        print(word_rests[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'AE1', 'N', 'D']]\n",
      "[['B', 'EY1', 'T', 'S']]\n",
      "[['B', 'IH1', 'L', 'D']]\n",
      "[['S', 'IY1', 'L', 'IH0', 'NG']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"banned\"])) #ed not as d encoded\n",
    "print(get_ARPAbet_phonetic_transcription([\"bayts\"])) #tes not as ts encoded \n",
    "print(get_ARPAbet_phonetic_transcription([\"billed\"])) #\n",
    "\n",
    "print(get_ARPAbet_phonetic_transcription([\"ceiling\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['W', 'AE1', 'K', 'S']]\n",
      "['w', 'ae', 'k', 's']\n",
      "[('C', 0.042, 0.757), ('CCH', 0.0007, 1.0), ('CCH', 9e-06, 1.0), ('CH', 0.0045, 0.29), ('CK', 0.0026, 1.0), ('CQ', 2e-05, 1.0), ('K', 0.0055, 1.0), ('KH', 2e-05, 1.0), ('Lk', 0.0001, 1.0), ('Q', 0.0001, 1.0), ('QU', 0.002, 0.12300000000000001), ('SC', 0.0008, 0.033)]\n"
     ]
    }
   ],
   "source": [
    "print(get_ARPAbet_phonetic_transcription([\"wax\"])) \n",
    "print(get_keyboard_phonetic_symbols(get_ARPAbet_phonetic_transcription([\"wax\"])[0], berndt_arpabbet_dict))\n",
    "print(berndt_computer_phonem_graph_prob_dict[\"k\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
